{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1deeb795d5264e80bf290708ab5e5263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d7bc168964846078243434564583780",
              "IPY_MODEL_b7bf2e35c3574265bfd4f7cd2d1ee7ff",
              "IPY_MODEL_5813b2bd4e3d4e9cab99018f6e11b164"
            ],
            "layout": "IPY_MODEL_77f19fe32eb34aedad1b8db62f7c8fcc"
          }
        },
        "2d7bc168964846078243434564583780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2659c518b8d246c2a3dfb1697bae8425",
            "placeholder": "​",
            "style": "IPY_MODEL_2f3a882c545844ad81734cd49244c0ac",
            "value": "config.json: 100%"
          }
        },
        "b7bf2e35c3574265bfd4f7cd2d1ee7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a509c7c4f6445a3b3c97bf7391940bc",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67869c01c84b424eb0a1873c07e887ce",
            "value": 313
          }
        },
        "5813b2bd4e3d4e9cab99018f6e11b164": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff3b8acc80304b46b59d368451e60538",
            "placeholder": "​",
            "style": "IPY_MODEL_698e4c6a40c14fc5a3afa9610b35976c",
            "value": " 313/313 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "77f19fe32eb34aedad1b8db62f7c8fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2659c518b8d246c2a3dfb1697bae8425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3a882c545844ad81734cd49244c0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a509c7c4f6445a3b3c97bf7391940bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67869c01c84b424eb0a1873c07e887ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff3b8acc80304b46b59d368451e60538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698e4c6a40c14fc5a3afa9610b35976c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e859c7321d574cbd820f0c06b9505cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab2a00833d9f4f6089e131d75d2dbb62",
              "IPY_MODEL_0d260d00f27a45fc863642b3a926daa4",
              "IPY_MODEL_f1a84b7f97c046ce840fe9df3d1f5586"
            ],
            "layout": "IPY_MODEL_2bfc130314824241a5e426bb661fe770"
          }
        },
        "ab2a00833d9f4f6089e131d75d2dbb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea92eba2d7b74dd0940b9652dce8d014",
            "placeholder": "​",
            "style": "IPY_MODEL_38765f1bdff64c8e966cf473a3653af8",
            "value": "vocab.txt: "
          }
        },
        "0d260d00f27a45fc863642b3a926daa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ce2f9363c04e3881645b12aaadac83",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40b349c95e954222b3a24eceda042358",
            "value": 1
          }
        },
        "f1a84b7f97c046ce840fe9df3d1f5586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6977b6888654ddfb8b242304ca45d79",
            "placeholder": "​",
            "style": "IPY_MODEL_aa989d7499354223b113b7d68dc6f9b4",
            "value": " 213k/? [00:00&lt;00:00, 5.41MB/s]"
          }
        },
        "2bfc130314824241a5e426bb661fe770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea92eba2d7b74dd0940b9652dce8d014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38765f1bdff64c8e966cf473a3653af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48ce2f9363c04e3881645b12aaadac83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "40b349c95e954222b3a24eceda042358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6977b6888654ddfb8b242304ca45d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa989d7499354223b113b7d68dc6f9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a54c9221585c41e896d831742a5d9e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d8a79e50af74a46a572d698f4cac72a",
              "IPY_MODEL_9264ba1938784a8480131a7f62066c3e",
              "IPY_MODEL_e06342945a6849bfab34db27ae8a519f"
            ],
            "layout": "IPY_MODEL_bc77b983e43c4362bd032ed6741abcff"
          }
        },
        "2d8a79e50af74a46a572d698f4cac72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704baf29321341e3977074612f19ad10",
            "placeholder": "​",
            "style": "IPY_MODEL_99dc556b123e47c79d3d3d0f538e747e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "9264ba1938784a8480131a7f62066c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_403a5b56c69a4595b99108f3862b3a2f",
            "max": 435780550,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54f0afb4443d49499e36e3cda6f05758",
            "value": 435780550
          }
        },
        "e06342945a6849bfab34db27ae8a519f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a68bf010c80847c49e04f7055bca08dc",
            "placeholder": "​",
            "style": "IPY_MODEL_88d6f683208d438bb2653e849970c1d7",
            "value": " 436M/436M [00:04&lt;00:00, 162MB/s]"
          }
        },
        "bc77b983e43c4362bd032ed6741abcff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "704baf29321341e3977074612f19ad10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99dc556b123e47c79d3d3d0f538e747e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "403a5b56c69a4595b99108f3862b3a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f0afb4443d49499e36e3cda6f05758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a68bf010c80847c49e04f7055bca08dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d6f683208d438bb2653e849970c1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30d1c37dd98644d6b647e89a7abd6b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e17e5d753a6d4d4189429eac11bb77c4",
              "IPY_MODEL_12dfc095d7df4dcbb48a22dea42ff995",
              "IPY_MODEL_ee02df9acbaf4d3abaa3dbdc6c14b513"
            ],
            "layout": "IPY_MODEL_4fb15b0df1314d3781259a77a765b1a2"
          }
        },
        "e17e5d753a6d4d4189429eac11bb77c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87d75815e3f4356b201141525eb67a2",
            "placeholder": "​",
            "style": "IPY_MODEL_4d8723a9e1744fcb8f6eb3c9c621245b",
            "value": "model.safetensors: 100%"
          }
        },
        "12dfc095d7df4dcbb48a22dea42ff995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6581ad99fb82474cb0b68ff6226d5320",
            "max": 435755944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22a6baac60d4496fb9f6b17187689d63",
            "value": 435755944
          }
        },
        "ee02df9acbaf4d3abaa3dbdc6c14b513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d97a597667a74225b965e6ec30766b39",
            "placeholder": "​",
            "style": "IPY_MODEL_31d9c1fca2ae48b7930191f8587c40e3",
            "value": " 436M/436M [00:05&lt;00:00, 157MB/s]"
          }
        },
        "4fb15b0df1314d3781259a77a765b1a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87d75815e3f4356b201141525eb67a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d8723a9e1744fcb8f6eb3c9c621245b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6581ad99fb82474cb0b68ff6226d5320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a6baac60d4496fb9f6b17187689d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d97a597667a74225b965e6ec30766b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d9c1fca2ae48b7930191f8587c40e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd41cb573d484e0da57c62ccbb3efcef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86d6c9b8a4f1491e846b1380c0283181",
              "IPY_MODEL_ecdaef568eeb4a3bb0fdc1a24cd3627e",
              "IPY_MODEL_b518a4cccb0f49288175ab337c5e044c"
            ],
            "layout": "IPY_MODEL_fe2661e44f57488ea57fb2f86a667d3c"
          }
        },
        "86d6c9b8a4f1491e846b1380c0283181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f033ec42a007415994a0a1283e19cd1e",
            "placeholder": "​",
            "style": "IPY_MODEL_fa4c794e29784a7fb05fe7ec5aad047a",
            "value": "Tokenizing train: 100%"
          }
        },
        "ecdaef568eeb4a3bb0fdc1a24cd3627e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83f971db8bfd48fbbf692602985b4021",
            "max": 555,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddb9e7e946d140089cf9c9f4bd67db36",
            "value": 555
          }
        },
        "b518a4cccb0f49288175ab337c5e044c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_376fd8fab88a4111a138f5e9ccfa570c",
            "placeholder": "​",
            "style": "IPY_MODEL_379a2a965634411abd15d1782d1bda25",
            "value": " 555/555 [00:02&lt;00:00, 242.31 examples/s]"
          }
        },
        "fe2661e44f57488ea57fb2f86a667d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f033ec42a007415994a0a1283e19cd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4c794e29784a7fb05fe7ec5aad047a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83f971db8bfd48fbbf692602985b4021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb9e7e946d140089cf9c9f4bd67db36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "376fd8fab88a4111a138f5e9ccfa570c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "379a2a965634411abd15d1782d1bda25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f27a717e103141eb86f7d8f65f850ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ee318949dc6458fae49ef0277972d64",
              "IPY_MODEL_4a13da5c88f9428f86d0a70fcd8095cf",
              "IPY_MODEL_bcfbdbbcce564464907d9b0bea10479c"
            ],
            "layout": "IPY_MODEL_e7b65d8afeea4e5c9f94bdf1ffa435cf"
          }
        },
        "5ee318949dc6458fae49ef0277972d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7681436d4592437981afb98b55bef2d1",
            "placeholder": "​",
            "style": "IPY_MODEL_698402754bb0498387ad89e2c6dcd944",
            "value": "Tokenizing eval: 100%"
          }
        },
        "4a13da5c88f9428f86d0a70fcd8095cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f5c699369a24bbcb7bbb8e5e6d80bec",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72597f2438b74143b2c076ee9c4bd314",
            "value": 99
          }
        },
        "bcfbdbbcce564464907d9b0bea10479c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51888727e7374cb2bf88bec9638aa5fe",
            "placeholder": "​",
            "style": "IPY_MODEL_f1593fa8452f43b4ae489c9969125e9a",
            "value": " 99/99 [00:00&lt;00:00, 128.48 examples/s]"
          }
        },
        "e7b65d8afeea4e5c9f94bdf1ffa435cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7681436d4592437981afb98b55bef2d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698402754bb0498387ad89e2c6dcd944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f5c699369a24bbcb7bbb8e5e6d80bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72597f2438b74143b2c076ee9c4bd314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51888727e7374cb2bf88bec9638aa5fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1593fa8452f43b4ae489c9969125e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cardiovascular Medical QA Fine-Tuning (BioBERT)\n",
        "\n",
        "This notebook fine-tunes a medical BERT QA model on cardiovascular Q&A data using a Colab GPU.\n",
        "\n"
      ],
      "metadata": {
        "id": "uPcBv896guGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Structure and Functionality\n",
        "\n",
        "### 1. Environment Setup and Configuration\n",
        "\n",
        "This code block prepares the Google Colab environment for fine-tuning the BioBERT model on cardiovascular question-answering tasks. It defines a utility function `pip_install()` to quietly install essential Python packages including Transformers (≥4.44.0) for working with pre-trained models, Datasets (≥2.14.0) for efficient data handling, Accelerate (≥0.26.0) for optimized training, and Evaluate (≥0.4.0) for performance metrics. After installing these dependencies, the code performs comprehensive environment diagnostics by displaying Python version, platform information, PyTorch version, and critically checks for GPU availability. If a CUDA-enabled GPU is detected, it displays the GPU name (ideally T4 for Colab) and CUDA version. If no GPU is found, it prompts the user to enable GPU acceleration in Colab's runtime settings, which is essential for efficient transformer model training.\n",
        "\n",
        "### 2. Imports and GPU Configuration\n",
        "\n",
        "This section imports all necessary libraries for the machine learning pipeline including PyTorch for deep learning, NumPy for numerical operations, Pandas for data manipulation, and critical Transformers components like `AutoTokenizer` and `AutoModelForQuestionAnswering` for handling pre-trained models. It also imports `TrainingArguments`, `Trainer`, and `default_data_collator` to streamline the fine-tuning process, along with the `Dataset` class for efficient data handling. Warning messages are suppressed for cleaner output. The GPU configuration logic then checks if CUDA is available and creates the appropriate device object (GPU or CPU fallback). For GPU setups, it displays detailed information including the GPU model name, CUDA version, and total GPU memory in gigabytes—crucial information for optimizing batch sizes and memory usage during training on T4's 16GB VRAM.\n",
        "\n",
        "### 3. Dataset Loading Options\n",
        "\n",
        "This block provides flexible methods for loading the cardiovascular QA dataset in Google Colab. Users can toggle between two approaches via boolean flags: **Option A** mounts Google Drive to access a CSV file stored there (requiring the user to specify the Drive path), while **Option B** uses Colab's file upload interface to let users upload a file directly from their local machine. The code defaults to the upload option for simplicity. After attempting the selected method, it validates that a valid CSV path was obtained; if not, it raises a `ValueError` to alert the user that the dataset must be provided before proceeding. This dual-option design accommodates different user workflows and data storage preferences in the Colab environment.\n",
        "\n",
        "### 4. Data Loading and Preprocessing\n",
        "\n",
        "Once the CSV path is established, this section loads the cardiovascular medical QA dataset using Pandas and performs essential preprocessing. It first reads the CSV file and displays diagnostic information including total record count, column names, a sample question preview (first 80 characters), and the character length of a sample answer to give users insight into the dataset structure. The code then removes any rows with null values in the critical `question` or `answer` columns to ensure data quality. Next, it randomly shuffles the dataset with a fixed random seed (42) for reproducibility and splits it into training and validation sets using an 85/15 ratio—a standard split that provides substantial training data while reserving enough examples for meaningful validation during and after training. This preprocessing ensures clean, well-organized data ready for tokenization.\n",
        "\n",
        "### 5. Model and Tokenizer Initialization\n",
        "\n",
        "This block initializes the pre-trained BioBERT model specifically designed for biomedical text processing. It loads the `\"dmis-lab/biobert-base-cased-v1.1\"` model from the Hugging Face Hub, which is a BERT variant pre-trained on large-scale biomedical literature including PubMed abstracts and PMC full-text articles. This specialized pre-training gives BioBERT a strong foundation in medical terminology and biomedical language patterns, making it ideal for cardiovascular QA tasks. Both the tokenizer and model are loaded using Auto classes, which automatically handle the correct architecture and configuration. The tokenizer is initialized with fast tokenizer mode enabled for improved performance. Once loaded, the model is transferred to the appropriate device (GPU if available, otherwise CPU) to leverage hardware acceleration for all subsequent operations.\n",
        "\n",
        "### 6. Tokenization and Feature Preparation\n",
        "\n",
        "This critical section transforms raw text data into numerical representations that the BioBERT model can process, while also preparing labels for extractive question answering. The code converts Pandas DataFrames into Hugging Face Dataset objects and defines key parameters: maximum sequence length (384 tokens) and document stride (128 tokens) for handling long contexts. The `prepare_train_features()` function tokenizes both questions and answers together, truncating only the answer portion if necessary to fit within the maximum length. For extractive QA, the model must predict start and end positions of the answer span within the tokenized context. The function identifies which tokens belong to the context (sequence_id == 1) versus the question, then sets start and end position labels accordingly—if no valid context exists, both positions default to 0. The function handles overflowing tokens by creating multiple training examples from long contexts and removes the offset_mapping data structure before returning, as it's only needed during preprocessing. This tokenization is applied to both training and validation datasets in batched mode for efficiency.\n",
        "\n",
        "### 7. Evaluation Metrics Definition\n",
        "\n",
        "This section defines custom evaluation metrics specifically designed for question answering tasks. The `compute_qa_metrics()` function receives predictions and labels from the model, extracting start and end logits for each example and converting them to predicted token positions using argmax. It calculates four key metrics: **exact match** (percentage where both start and end positions are perfectly predicted), **start accuracy** (correctness of start position), **end accuracy** (correctness of end position), and **token-level F1 score**. The F1 calculation is sophisticated—it treats predicted and actual answer spans as sets of token positions and computes precision and recall based on their overlap. Special cases are handled appropriately: if both spans are empty, F1 is 1.0; if only one is empty, F1 is 0.0. For overlapping spans, it calculates the intersection of token positions to derive precision (overlap/predicted tokens) and recall (overlap/true tokens), then combines them into the harmonic mean F1 score. These metrics provide comprehensive insight into the model's ability to accurately locate answer spans.\n",
        "\n",
        "### 8. Training Configuration (T4 GPU Optimized)\n",
        "\n",
        "This block configures all hyperparameters and training settings specifically optimized for Google Colab's T4 GPU (16GB VRAM). The `TrainingArguments` object is carefully tuned to maximize performance while avoiding out-of-memory errors. Key optimizations include: **batch size of 8** (optimal for T4's memory when working with BERT models), **gradient accumulation of 4 steps** (creating an effective batch size of 32 for stable gradients), **5 epochs** for better convergence, **learning rate of 2e-5** (slightly lower than standard for medical domain stability), **warmup ratio of 15%** for gradual adaptation, and **FP16 mixed-precision training** enabled (essential for T4—roughly doubles speed and halves memory usage). The configuration uses PyTorch's native AdamW optimizer (`adamw_torch`) which is faster on T4, evaluates and checkpoints at each epoch end, keeps only the best 2 checkpoints based on F1 score, and logs every 25 steps for better training visibility. These T4-specific settings balance training speed, memory efficiency, and model performance for the cardiovascular QA task.\n",
        "\n",
        "### 9. Trainer Initialization\n",
        "\n",
        "This section instantiates the Hugging Face `Trainer` object, which orchestrates the entire training and evaluation pipeline. The Trainer combines the BioBERT model, training arguments, tokenized datasets, tokenizer, data collator, and custom metrics function into a unified training system. The `default_data_collator` handles batching and padding of tokenized examples to ensure uniform tensor sizes within each batch. By providing both training and evaluation datasets, the Trainer automatically runs validation at intervals specified in the training arguments. The `compute_metrics` function enables automatic calculation of custom QA metrics during evaluation, providing real-time feedback on model performance. This high-level abstraction handles complex training loop aspects including gradient computation, backpropagation, optimizer steps, learning rate scheduling, mixed-precision training, logging, checkpointing, and distributed training if multiple GPUs are available—simplifying what would otherwise require hundreds of lines of custom code.\n",
        "\n",
        "### 10. Hyperparameter Tuning Experiment (T4 GPU Optimized - 15 Iterations)\n",
        "\n",
        "This extensive block implements a focused hyperparameter search across 15 carefully selected configurations optimized for T4 GPU constraints. Unlike generic searches, this experiment is specifically tuned to work within T4's 16GB memory limit while maximizing efficiency. All configurations use a **fixed batch size of 8** (the sweet spot for BERT on T4—large enough for stable gradients, small enough to avoid OOM errors) with **gradient accumulation of 4** (creating an effective batch size of 32, ideal for transformer fine-tuning). The experiment systematically explores: **epochs** (5-10 for faster iteration), **learning rates** (1e-5 to 5e-5, centered around 2e-5 for medical domain stability), **warmup ratios** (0.1-0.25 for testing different warmup strategies), and **weight decay** (0.0-0.02 for regularization). For each configuration, the code **critically reloads a fresh BioBERT model** to ensure each experiment starts from identical initialization, preventing weight contamination between runs. The training loop executes the full process, measures runtime, evaluates on validation set, and computes detailed precision and recall through token-level overlap analysis between predicted and true answer spans. All results are collected in an Excel workbook with formatted headers, enabling easy comparison. This focused 15-iteration search completes faster than broader searches while targeting the most impactful hyperparameter combinations for cardiovascular QA on T4 hardware with BioBERT.\n",
        "\n",
        "### 11. Final Training and Evaluation\n",
        "\n",
        "This final section executes the actual training using the optimized configuration from section 8 and performs comprehensive evaluation. The code calls `trainer.train()` to begin the fine-tuning process, which will run for 5 epochs with the T4-optimized settings (batch size 8, gradient accumulation 4, learning rate 2e-5, FP16 enabled). During training, the Trainer automatically handles the forward pass, loss calculation, backward pass, gradient accumulation, optimizer steps, learning rate scheduling, and periodic evaluation at each epoch end. After training completes, the code displays the final training loss to show convergence. The evaluation section then runs `trainer.evaluate()` on the validation set to compute all custom metrics including exact match, start accuracy, end accuracy, and F1 score. These final metrics provide a comprehensive assessment of how well the fine-tuned BioBERT model performs on the cardiovascular question-answering task, measuring its ability to accurately identify answer spans within medical text passages. The sorted output makes it easy to review all performance metrics at a glance."
      ],
      "metadata": {
        "id": "Fxs4yqgBgr4W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1deeb795d5264e80bf290708ab5e5263",
            "2d7bc168964846078243434564583780",
            "b7bf2e35c3574265bfd4f7cd2d1ee7ff",
            "5813b2bd4e3d4e9cab99018f6e11b164",
            "77f19fe32eb34aedad1b8db62f7c8fcc",
            "2659c518b8d246c2a3dfb1697bae8425",
            "2f3a882c545844ad81734cd49244c0ac",
            "2a509c7c4f6445a3b3c97bf7391940bc",
            "67869c01c84b424eb0a1873c07e887ce",
            "ff3b8acc80304b46b59d368451e60538",
            "698e4c6a40c14fc5a3afa9610b35976c",
            "e859c7321d574cbd820f0c06b9505cd2",
            "ab2a00833d9f4f6089e131d75d2dbb62",
            "0d260d00f27a45fc863642b3a926daa4",
            "f1a84b7f97c046ce840fe9df3d1f5586",
            "2bfc130314824241a5e426bb661fe770",
            "ea92eba2d7b74dd0940b9652dce8d014",
            "38765f1bdff64c8e966cf473a3653af8",
            "48ce2f9363c04e3881645b12aaadac83",
            "40b349c95e954222b3a24eceda042358",
            "d6977b6888654ddfb8b242304ca45d79",
            "aa989d7499354223b113b7d68dc6f9b4",
            "a54c9221585c41e896d831742a5d9e61",
            "2d8a79e50af74a46a572d698f4cac72a",
            "9264ba1938784a8480131a7f62066c3e",
            "e06342945a6849bfab34db27ae8a519f",
            "bc77b983e43c4362bd032ed6741abcff",
            "704baf29321341e3977074612f19ad10",
            "99dc556b123e47c79d3d3d0f538e747e",
            "403a5b56c69a4595b99108f3862b3a2f",
            "54f0afb4443d49499e36e3cda6f05758",
            "a68bf010c80847c49e04f7055bca08dc",
            "88d6f683208d438bb2653e849970c1d7",
            "30d1c37dd98644d6b647e89a7abd6b22",
            "e17e5d753a6d4d4189429eac11bb77c4",
            "12dfc095d7df4dcbb48a22dea42ff995",
            "ee02df9acbaf4d3abaa3dbdc6c14b513",
            "4fb15b0df1314d3781259a77a765b1a2",
            "c87d75815e3f4356b201141525eb67a2",
            "4d8723a9e1744fcb8f6eb3c9c621245b",
            "6581ad99fb82474cb0b68ff6226d5320",
            "22a6baac60d4496fb9f6b17187689d63",
            "d97a597667a74225b965e6ec30766b39",
            "31d9c1fca2ae48b7930191f8587c40e3",
            "dd41cb573d484e0da57c62ccbb3efcef",
            "86d6c9b8a4f1491e846b1380c0283181",
            "ecdaef568eeb4a3bb0fdc1a24cd3627e",
            "b518a4cccb0f49288175ab337c5e044c",
            "fe2661e44f57488ea57fb2f86a667d3c",
            "f033ec42a007415994a0a1283e19cd1e",
            "fa4c794e29784a7fb05fe7ec5aad047a",
            "83f971db8bfd48fbbf692602985b4021",
            "ddb9e7e946d140089cf9c9f4bd67db36",
            "376fd8fab88a4111a138f5e9ccfa570c",
            "379a2a965634411abd15d1782d1bda25",
            "f27a717e103141eb86f7d8f65f850ea5",
            "5ee318949dc6458fae49ef0277972d64",
            "4a13da5c88f9428f86d0a70fcd8095cf",
            "bcfbdbbcce564464907d9b0bea10479c",
            "e7b65d8afeea4e5c9f94bdf1ffa435cf",
            "7681436d4592437981afb98b55bef2d1",
            "698402754bb0498387ad89e2c6dcd944",
            "0f5c699369a24bbcb7bbb8e5e6d80bec",
            "72597f2438b74143b2c076ee9c4bd314",
            "51888727e7374cb2bf88bec9638aa5fe",
            "f1593fa8452f43b4ae489c9969125e9a"
          ]
        },
        "id": "Sz_RoKxzRMpS",
        "outputId": "1aa6f28a-692f-4b88-e451-d26705d8d22c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ENVIRONMENT\n",
            "============================================================\n",
            "Python: 3.12.12 | Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "PyTorch: 2.8.0+cu126\n",
            "GPU: Tesla T4 | CUDA: 12.6\n",
            "============================================================\n",
            "============================================================\n",
            "GPU CONFIGURATION\n",
            "============================================================\n",
            "GPU Available: Tesla T4\n",
            "CUDA Version: 12.6\n",
            "GPU Memory: 14.74 GB\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c42d2227-bc64-46ef-999f-2e11e12859a2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c42d2227-bc64-46ef-999f-2e11e12859a2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving medquadCardiovascular.csv to medquadCardiovascular.csv\n",
            "Dataset CSV: medquadCardiovascular.csv\n",
            "\n",
            "============================================================\n",
            "LOADING CARDIOVASCULAR DATASET\n",
            "============================================================\n",
            "Total records: 654\n",
            "Columns: ['question', 'answer', 'source', 'focus_area']\n",
            "Sample question: What is (are) High Blood Pressure ?...\n",
            "Sample answer chars: 5586\n",
            "Train: 555 | Val: 99\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "LOADING MODEL AND TOKENIZER\n",
            "============================================================\n",
            "Model: dmis-lab/biobert-base-cased-v1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1deeb795d5264e80bf290708ab5e5263"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e859c7321d574cbd820f0c06b9505cd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a54c9221585c41e896d831742a5d9e61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TOKENIZING DATASET\n",
            "============================================================\n",
            "Tokenizing train...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30d1c37dd98644d6b647e89a7abd6b22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train:   0%|          | 0/555 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd41cb573d484e0da57c62ccbb3efcef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing eval...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing eval:   0%|          | 0/99 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f27a717e103141eb86f7d8f65f850ea5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "============================================================\n",
            "Metrics ready.\n",
            "\n",
            "============================================================\n",
            "TRAINING CONFIGURATION (T4 GPU OPTIMIZED)\n",
            "============================================================\n",
            "T4 GPU Configuration:\n",
            "  - Batch Size: 8\n",
            "  - Gradient Accumulation: 4\n",
            "  - Effective Batch Size: 32\n",
            "  - FP16 Enabled: True\n",
            "  - Learning Rate: 2e-05\n",
            "  - Epochs: 5\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "INITIALIZING TRAINER\n",
            "============================================================\n",
            "Trainer ready.\n",
            "\n",
            "============================================================\n",
            "HYPERPARAMETER TUNING (T4 GPU OPTIMIZED - 15 ITERATIONS)\n",
            "============================================================\n",
            "Running 10 T4-optimized configurations\n",
            "Fixed batch size: 8 (optimal for T4 16GB memory)\n",
            "Gradient accumulation: 4 (effective batch size: 32)\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "▶️ Training Iteration 1/10\n",
            "Params: {'epochs': 5, 'lr': 2e-05, 'batch': 8, 'warmup': 0.15, 'weight_decay': 0.01}\n",
            "============================================================\n",
            "🔄 Reloading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 2.8178999423980713, 'eval_exact_match': 0.019417475728155338, 'eval_start_accuracy': 0.9757281553398058, 'eval_end_accuracy': 0.019417475728155338, 'eval_f1': 0.8801770051536848, 'eval_runtime': 1.1986, 'eval_samples_per_second': 171.865, 'eval_steps_per_second': 21.692, 'epoch': 1.0}\n",
            "{'eval_loss': 1.370165228843689, 'eval_exact_match': 0.0970873786407767, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.0970873786407767, 'eval_f1': 0.9369774629777868, 'eval_runtime': 1.1226, 'eval_samples_per_second': 183.509, 'eval_steps_per_second': 23.161, 'epoch': 2.0}\n",
            "{'eval_loss': 1.3185033798217773, 'eval_exact_match': 0.15048543689320387, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.15048543689320387, 'eval_f1': 0.9450134621887527, 'eval_runtime': 1.171, 'eval_samples_per_second': 175.924, 'eval_steps_per_second': 22.204, 'epoch': 3.0}\n",
            "{'eval_loss': 1.293848991394043, 'eval_exact_match': 0.1407766990291262, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1407766990291262, 'eval_f1': 0.9564405261216434, 'eval_runtime': 1.2065, 'eval_samples_per_second': 170.737, 'eval_steps_per_second': 21.549, 'epoch': 4.0}\n",
            "{'eval_loss': 1.3080182075500488, 'eval_exact_match': 0.16990291262135923, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16990291262135923, 'eval_f1': 0.9612220913007211, 'eval_runtime': 1.2514, 'eval_samples_per_second': 164.618, 'eval_steps_per_second': 20.777, 'epoch': 5.0}\n",
            "{'train_runtime': 108.6748, 'train_samples_per_second': 48.769, 'train_steps_per_second': 1.564, 'train_loss': 2.1435356588924632, 'epoch': 5.0}\n",
            "{'eval_loss': 1.3080182075500488, 'eval_exact_match': 0.16990291262135923, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16990291262135923, 'eval_f1': 0.9612220913007211, 'eval_runtime': 1.2208, 'eval_samples_per_second': 168.735, 'eval_steps_per_second': 21.297, 'epoch': 5.0}\n",
            "✅ Iteration 1 done — F1: 0.9612, Accuracy: 0.4466, Time: 109.33s\n",
            "\n",
            "============================================================\n",
            "▶️ Training Iteration 2/10\n",
            "Params: {'epochs': 5, 'lr': 3e-05, 'batch': 8, 'warmup': 0.15, 'weight_decay': 0.01}\n",
            "============================================================\n",
            "🔄 Reloading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.9868483543395996, 'eval_exact_match': 0.04854368932038835, 'eval_start_accuracy': 0.9757281553398058, 'eval_end_accuracy': 0.04854368932038835, 'eval_f1': 0.8956512865464503, 'eval_runtime': 1.2111, 'eval_samples_per_second': 170.097, 'eval_steps_per_second': 21.468, 'epoch': 1.0}\n",
            "{'eval_loss': 1.3723567724227905, 'eval_exact_match': 0.10194174757281553, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.10194174757281553, 'eval_f1': 0.9291539721981256, 'eval_runtime': 1.216, 'eval_samples_per_second': 169.413, 'eval_steps_per_second': 21.382, 'epoch': 2.0}\n",
            "{'eval_loss': 1.3170033693313599, 'eval_exact_match': 0.13592233009708737, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.13592233009708737, 'eval_f1': 0.936181394382664, 'eval_runtime': 1.2757, 'eval_samples_per_second': 161.475, 'eval_steps_per_second': 20.38, 'epoch': 3.0}\n",
            "{'eval_loss': 1.3184800148010254, 'eval_exact_match': 0.1553398058252427, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1553398058252427, 'eval_f1': 0.9579804971975411, 'eval_runtime': 1.2122, 'eval_samples_per_second': 169.939, 'eval_steps_per_second': 21.449, 'epoch': 4.0}\n",
            "{'eval_loss': 1.3535668849945068, 'eval_exact_match': 0.1796116504854369, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1796116504854369, 'eval_f1': 0.9537434568346135, 'eval_runtime': 1.2153, 'eval_samples_per_second': 169.512, 'eval_steps_per_second': 21.395, 'epoch': 5.0}\n",
            "{'train_runtime': 110.9539, 'train_samples_per_second': 47.768, 'train_steps_per_second': 1.532, 'train_loss': 1.982959343405331, 'epoch': 5.0}\n",
            "{'eval_loss': 1.3535668849945068, 'eval_exact_match': 0.1796116504854369, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1796116504854369, 'eval_f1': 0.9537434568346135, 'eval_runtime': 1.1835, 'eval_samples_per_second': 174.055, 'eval_steps_per_second': 21.968, 'epoch': 5.0}\n",
            "✅ Iteration 2 done — F1: 0.9537, Accuracy: 0.4531, Time: 111.42s\n",
            "\n",
            "============================================================\n",
            "▶️ Training Iteration 3/10\n",
            "Params: {'epochs': 5, 'lr': 1.5e-05, 'batch': 8, 'warmup': 0.15, 'weight_decay': 0.01}\n",
            "============================================================\n",
            "🔄 Reloading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 4.0059356689453125, 'eval_exact_match': 0.019417475728155338, 'eval_start_accuracy': 0.7135922330097088, 'eval_end_accuracy': 0.02912621359223301, 'eval_f1': 0.7582600483640961, 'eval_runtime': 1.2215, 'eval_samples_per_second': 168.639, 'eval_steps_per_second': 21.285, 'epoch': 1.0}\n",
            "{'eval_loss': 1.4623887538909912, 'eval_exact_match': 0.11165048543689321, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.11165048543689321, 'eval_f1': 0.9304362208110201, 'eval_runtime': 1.2054, 'eval_samples_per_second': 170.891, 'eval_steps_per_second': 21.569, 'epoch': 2.0}\n",
            "{'eval_loss': 1.2946723699569702, 'eval_exact_match': 0.15048543689320387, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.15048543689320387, 'eval_f1': 0.9330424283659267, 'eval_runtime': 1.2165, 'eval_samples_per_second': 169.332, 'eval_steps_per_second': 21.372, 'epoch': 3.0}\n",
            "{'eval_loss': 1.3540619611740112, 'eval_exact_match': 0.14563106796116504, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.14563106796116504, 'eval_f1': 0.9356031379693178, 'eval_runtime': 1.2213, 'eval_samples_per_second': 168.673, 'eval_steps_per_second': 21.289, 'epoch': 4.0}\n",
            "{'eval_loss': 1.2415682077407837, 'eval_exact_match': 0.16990291262135923, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16990291262135923, 'eval_f1': 0.934331202108422, 'eval_runtime': 1.2028, 'eval_samples_per_second': 171.267, 'eval_steps_per_second': 21.616, 'epoch': 5.0}\n",
            "{'train_runtime': 111.0165, 'train_samples_per_second': 47.741, 'train_steps_per_second': 1.531, 'train_loss': 2.3788978127872245, 'epoch': 5.0}\n",
            "{'eval_loss': 1.2415682077407837, 'eval_exact_match': 0.16990291262135923, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16990291262135923, 'eval_f1': 0.934331202108422, 'eval_runtime': 1.1826, 'eval_samples_per_second': 174.189, 'eval_steps_per_second': 21.985, 'epoch': 5.0}\n",
            "✅ Iteration 3 done — F1: 0.9343, Accuracy: 0.4466, Time: 111.63s\n",
            "\n",
            "============================================================\n",
            "▶️ Training Iteration 4/10\n",
            "Params: {'epochs': 7, 'lr': 2e-05, 'batch': 8, 'warmup': 0.15, 'weight_decay': 0.01}\n",
            "============================================================\n",
            "🔄 Reloading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 3.9749581813812256, 'eval_exact_match': 0.019417475728155338, 'eval_start_accuracy': 0.7233009708737864, 'eval_end_accuracy': 0.02912621359223301, 'eval_f1': 0.7658885379497854, 'eval_runtime': 1.2011, 'eval_samples_per_second': 171.513, 'eval_steps_per_second': 21.647, 'epoch': 1.0}\n",
            "{'eval_loss': 1.4160572290420532, 'eval_exact_match': 0.14563106796116504, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.14563106796116504, 'eval_f1': 0.9347083334795011, 'eval_runtime': 1.1881, 'eval_samples_per_second': 173.386, 'eval_steps_per_second': 21.884, 'epoch': 2.0}\n",
            "{'eval_loss': 1.3819013833999634, 'eval_exact_match': 0.13106796116504854, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.13106796116504854, 'eval_f1': 0.9315907636161119, 'eval_runtime': 1.4121, 'eval_samples_per_second': 145.881, 'eval_steps_per_second': 18.412, 'epoch': 3.0}\n",
            "{'eval_loss': 1.3125804662704468, 'eval_exact_match': 0.16019417475728157, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16019417475728157, 'eval_f1': 0.9429066535405087, 'eval_runtime': 1.564, 'eval_samples_per_second': 131.712, 'eval_steps_per_second': 16.624, 'epoch': 4.0}\n",
            "{'eval_loss': 1.2185988426208496, 'eval_exact_match': 0.1796116504854369, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1796116504854369, 'eval_f1': 0.9419704144670248, 'eval_runtime': 1.221, 'eval_samples_per_second': 168.715, 'eval_steps_per_second': 21.294, 'epoch': 5.0}\n",
            "{'eval_loss': 1.2067537307739258, 'eval_exact_match': 0.20388349514563106, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.20388349514563106, 'eval_f1': 0.9525351717578093, 'eval_runtime': 1.2766, 'eval_samples_per_second': 161.366, 'eval_steps_per_second': 20.367, 'epoch': 6.0}\n",
            "{'eval_loss': 1.160879373550415, 'eval_exact_match': 0.19902912621359223, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.19902912621359223, 'eval_f1': 0.9443873915245348, 'eval_runtime': 1.2433, 'eval_samples_per_second': 165.694, 'eval_steps_per_second': 20.913, 'epoch': 7.0}\n",
            "{'train_runtime': 164.4835, 'train_samples_per_second': 45.111, 'train_steps_per_second': 1.447, 'train_loss': 1.903088225036108, 'epoch': 7.0}\n",
            "{'eval_loss': 1.160879373550415, 'eval_exact_match': 0.19902912621359223, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.19902912621359223, 'eval_f1': 0.9443873915245348, 'eval_runtime': 1.2719, 'eval_samples_per_second': 161.964, 'eval_steps_per_second': 20.442, 'epoch': 7.0}\n",
            "✅ Iteration 4 done — F1: 0.9444, Accuracy: 0.4660, Time: 164.94s\n",
            "\n",
            "============================================================\n",
            "▶️ Training Iteration 5/10\n",
            "Params: {'epochs': 10, 'lr': 2e-05, 'batch': 8, 'warmup': 0.15, 'weight_decay': 0.01}\n",
            "============================================================\n",
            "🔄 Reloading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 4.491898536682129, 'eval_exact_match': 0.02912621359223301, 'eval_start_accuracy': 0.8203883495145631, 'eval_end_accuracy': 0.02912621359223301, 'eval_f1': 0.7290422957886874, 'eval_runtime': 1.2237, 'eval_samples_per_second': 168.34, 'eval_steps_per_second': 21.247, 'epoch': 1.0}\n",
            "{'eval_loss': 1.451446533203125, 'eval_exact_match': 0.10194174757281553, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.10194174757281553, 'eval_f1': 0.9319651915337261, 'eval_runtime': 1.2853, 'eval_samples_per_second': 160.276, 'eval_steps_per_second': 20.229, 'epoch': 2.0}\n",
            "{'eval_loss': 1.439563512802124, 'eval_exact_match': 0.13106796116504854, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.13106796116504854, 'eval_f1': 0.9457963915619397, 'eval_runtime': 1.2866, 'eval_samples_per_second': 160.11, 'eval_steps_per_second': 20.208, 'epoch': 3.0}\n",
            "{'eval_loss': 1.4479420185089111, 'eval_exact_match': 0.1407766990291262, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1407766990291262, 'eval_f1': 0.9612261542003158, 'eval_runtime': 1.2007, 'eval_samples_per_second': 171.562, 'eval_steps_per_second': 21.653, 'epoch': 4.0}\n",
            "{'eval_loss': 1.332883358001709, 'eval_exact_match': 0.16990291262135923, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16990291262135923, 'eval_f1': 0.9653719398917782, 'eval_runtime': 1.2146, 'eval_samples_per_second': 169.601, 'eval_steps_per_second': 21.406, 'epoch': 5.0}\n",
            "{'eval_loss': 1.385416865348816, 'eval_exact_match': 0.16019417475728157, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16019417475728157, 'eval_f1': 0.972292872263382, 'eval_runtime': 1.2106, 'eval_samples_per_second': 170.168, 'eval_steps_per_second': 21.478, 'epoch': 6.0}\n",
            "{'eval_loss': 1.362273931503296, 'eval_exact_match': 0.2524271844660194, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.2524271844660194, 'eval_f1': 0.9755724115657672, 'eval_runtime': 1.2192, 'eval_samples_per_second': 168.969, 'eval_steps_per_second': 21.326, 'epoch': 7.0}\n",
            "{'eval_loss': 1.305432915687561, 'eval_exact_match': 0.24757281553398058, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.24757281553398058, 'eval_f1': 0.9767084818667762, 'eval_runtime': 1.2093, 'eval_samples_per_second': 170.346, 'eval_steps_per_second': 21.5, 'epoch': 8.0}\n",
            "{'eval_loss': 1.2513381242752075, 'eval_exact_match': 0.27184466019417475, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.27184466019417475, 'eval_f1': 0.9721070786938163, 'eval_runtime': 1.288, 'eval_samples_per_second': 159.943, 'eval_steps_per_second': 20.187, 'epoch': 9.0}\n",
            "{'eval_loss': 1.2668410539627075, 'eval_exact_match': 0.2621359223300971, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.2621359223300971, 'eval_f1': 0.9773124439024432, 'eval_runtime': 1.2142, 'eval_samples_per_second': 169.654, 'eval_steps_per_second': 21.413, 'epoch': 10.0}\n",
            "{'train_runtime': 223.5969, 'train_samples_per_second': 47.407, 'train_steps_per_second': 1.521, 'train_loss': 1.596846995634191, 'epoch': 10.0}\n",
            "{'eval_loss': 1.2668410539627075, 'eval_exact_match': 0.2621359223300971, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.2621359223300971, 'eval_f1': 0.9773124439024432, 'eval_runtime': 1.2228, 'eval_samples_per_second': 168.469, 'eval_steps_per_second': 21.263, 'epoch': 10.0}\n",
            "✅ Iteration 5 done — F1: 0.9773, Accuracy: 0.5081, Time: 224.11s\n",
            "\n",
            "============================================================\n",
            "▶️ Training Iteration 6/10\n",
            "Params: {'epochs': 5, 'lr': 4e-05, 'batch': 8, 'warmup': 0.15, 'weight_decay': 0.01}\n",
            "============================================================\n",
            "🔄 Reloading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.6040613651275635, 'eval_exact_match': 0.11165048543689321, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.11165048543689321, 'eval_f1': 0.9279927796901499, 'eval_runtime': 1.2776, 'eval_samples_per_second': 161.243, 'eval_steps_per_second': 20.351, 'epoch': 1.0}\n",
            "{'eval_loss': 1.3626525402069092, 'eval_exact_match': 0.11165048543689321, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.11165048543689321, 'eval_f1': 0.9450020956076249, 'eval_runtime': 1.2124, 'eval_samples_per_second': 169.911, 'eval_steps_per_second': 21.445, 'epoch': 2.0}\n",
            "{'eval_loss': 1.2445478439331055, 'eval_exact_match': 0.15048543689320387, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.15048543689320387, 'eval_f1': 0.9589771394438907, 'eval_runtime': 1.1998, 'eval_samples_per_second': 171.694, 'eval_steps_per_second': 21.67, 'epoch': 3.0}\n",
            "{'eval_loss': 1.3362737894058228, 'eval_exact_match': 0.1650485436893204, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1650485436893204, 'eval_f1': 0.9703259298584518, 'eval_runtime': 1.2084, 'eval_samples_per_second': 170.478, 'eval_steps_per_second': 21.517, 'epoch': 4.0}\n",
            "{'eval_loss': 1.3130297660827637, 'eval_exact_match': 0.2087378640776699, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.2087378640776699, 'eval_f1': 0.9770456766005748, 'eval_runtime': 1.203, 'eval_samples_per_second': 171.235, 'eval_steps_per_second': 21.612, 'epoch': 5.0}\n",
            "{'train_runtime': 110.7014, 'train_samples_per_second': 47.877, 'train_steps_per_second': 1.536, 'train_loss': 1.7847947064568015, 'epoch': 5.0}\n",
            "{'eval_loss': 1.3130297660827637, 'eval_exact_match': 0.2087378640776699, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.2087378640776699, 'eval_f1': 0.9770456766005748, 'eval_runtime': 1.1895, 'eval_samples_per_second': 173.188, 'eval_steps_per_second': 21.859, 'epoch': 5.0}\n",
            "✅ Iteration 6 done — F1: 0.9770, Accuracy: 0.4725, Time: 111.16s\n",
            "\n",
            "============================================================\n",
            "▶️ Training Iteration 7/10\n",
            "Params: {'epochs': 5, 'lr': 5e-05, 'batch': 8, 'warmup': 0.15, 'weight_decay': 0.01}\n",
            "============================================================\n",
            "🔄 Reloading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.4806733131408691, 'eval_exact_match': 0.09223300970873786, 'eval_start_accuracy': 0.9951456310679612, 'eval_end_accuracy': 0.09223300970873786, 'eval_f1': 0.9289630024158075, 'eval_runtime': 1.2171, 'eval_samples_per_second': 169.248, 'eval_steps_per_second': 21.361, 'epoch': 1.0}\n",
            "{'eval_loss': 1.2734520435333252, 'eval_exact_match': 0.16019417475728157, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16019417475728157, 'eval_f1': 0.9746750660884987, 'eval_runtime': 1.21, 'eval_samples_per_second': 170.246, 'eval_steps_per_second': 21.487, 'epoch': 2.0}\n",
            "{'eval_loss': 1.2294172048568726, 'eval_exact_match': 0.24757281553398058, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.24757281553398058, 'eval_f1': 0.978013963190029, 'eval_runtime': 1.2135, 'eval_samples_per_second': 169.759, 'eval_steps_per_second': 21.426, 'epoch': 3.0}\n",
            "{'eval_loss': 0.9737569093704224, 'eval_exact_match': 0.33980582524271846, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.33980582524271846, 'eval_f1': 0.9861069675926537, 'eval_runtime': 1.2836, 'eval_samples_per_second': 160.489, 'eval_steps_per_second': 20.256, 'epoch': 4.0}\n",
            "{'eval_loss': 0.7425289750099182, 'eval_exact_match': 0.49514563106796117, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.49514563106796117, 'eval_f1': 0.9866522693386623, 'eval_runtime': 1.2066, 'eval_samples_per_second': 170.733, 'eval_steps_per_second': 21.549, 'epoch': 5.0}\n",
            "{'train_runtime': 110.7995, 'train_samples_per_second': 47.834, 'train_steps_per_second': 1.534, 'train_loss': 1.6376491771024817, 'epoch': 5.0}\n",
            "{'eval_loss': 0.7425289750099182, 'eval_exact_match': 0.49514563106796117, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.49514563106796117, 'eval_f1': 0.9866522693386623, 'eval_runtime': 1.2521, 'eval_samples_per_second': 164.52, 'eval_steps_per_second': 20.765, 'epoch': 5.0}\n",
            "✅ Iteration 7 done — F1: 0.9867, Accuracy: 0.6634, Time: 111.26s\n",
            "\n",
            "============================================================\n",
            "▶️ Training Iteration 8/10\n",
            "Params: {'epochs': 5, 'lr': 1e-05, 'batch': 8, 'warmup': 0.15, 'weight_decay': 0.01}\n",
            "============================================================\n",
            "🔄 Reloading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 4.907454013824463, 'eval_exact_match': 0.009708737864077669, 'eval_start_accuracy': 0.587378640776699, 'eval_end_accuracy': 0.014563106796116505, 'eval_f1': 0.6599693646521113, 'eval_runtime': 1.3106, 'eval_samples_per_second': 157.179, 'eval_steps_per_second': 19.838, 'epoch': 1.0}\n",
            "{'eval_loss': 1.9464209079742432, 'eval_exact_match': 0.05825242718446602, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.05825242718446602, 'eval_f1': 0.9010068693526078, 'eval_runtime': 1.2198, 'eval_samples_per_second': 168.884, 'eval_steps_per_second': 21.315, 'epoch': 2.0}\n",
            "{'eval_loss': 1.4383937120437622, 'eval_exact_match': 0.11165048543689321, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.11165048543689321, 'eval_f1': 0.9263973807785042, 'eval_runtime': 1.1929, 'eval_samples_per_second': 172.691, 'eval_steps_per_second': 21.796, 'epoch': 3.0}\n",
            "{'eval_loss': 1.4007000923156738, 'eval_exact_match': 0.12135922330097088, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.12135922330097088, 'eval_f1': 0.9297739667213155, 'eval_runtime': 1.2153, 'eval_samples_per_second': 169.5, 'eval_steps_per_second': 21.393, 'epoch': 4.0}\n",
            "{'eval_loss': 1.364395260810852, 'eval_exact_match': 0.11165048543689321, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.11165048543689321, 'eval_f1': 0.9350420401144953, 'eval_runtime': 1.217, 'eval_samples_per_second': 169.274, 'eval_steps_per_second': 21.365, 'epoch': 5.0}\n",
            "{'train_runtime': 111.2888, 'train_samples_per_second': 47.624, 'train_steps_per_second': 1.528, 'train_loss': 2.7193590949563418, 'epoch': 5.0}\n",
            "{'eval_loss': 1.364395260810852, 'eval_exact_match': 0.11165048543689321, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.11165048543689321, 'eval_f1': 0.9350420401144953, 'eval_runtime': 1.1815, 'eval_samples_per_second': 174.361, 'eval_steps_per_second': 22.007, 'epoch': 5.0}\n",
            "✅ Iteration 8 done — F1: 0.9350, Accuracy: 0.4078, Time: 111.75s\n",
            "\n",
            "============================================================\n",
            "▶️ Training Iteration 9/10\n",
            "Params: {'epochs': 5, 'lr': 2e-05, 'batch': 8, 'warmup': 0.1, 'weight_decay': 0.01}\n",
            "============================================================\n",
            "🔄 Reloading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 2.479952335357666, 'eval_exact_match': 0.04854368932038835, 'eval_start_accuracy': 0.9854368932038835, 'eval_end_accuracy': 0.04854368932038835, 'eval_f1': 0.8636067923194043, 'eval_runtime': 1.1906, 'eval_samples_per_second': 173.019, 'eval_steps_per_second': 21.837, 'epoch': 1.0}\n",
            "{'eval_loss': 1.4084665775299072, 'eval_exact_match': 0.1262135922330097, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1262135922330097, 'eval_f1': 0.9308613037330518, 'eval_runtime': 1.2037, 'eval_samples_per_second': 171.143, 'eval_steps_per_second': 21.601, 'epoch': 2.0}\n",
            "{'eval_loss': 1.2919323444366455, 'eval_exact_match': 0.1262135922330097, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1262135922330097, 'eval_f1': 0.9318659055385519, 'eval_runtime': 1.2156, 'eval_samples_per_second': 169.466, 'eval_steps_per_second': 21.389, 'epoch': 3.0}\n",
            "{'eval_loss': 1.3226094245910645, 'eval_exact_match': 0.13106796116504854, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.13106796116504854, 'eval_f1': 0.936968475765684, 'eval_runtime': 1.2655, 'eval_samples_per_second': 162.783, 'eval_steps_per_second': 20.545, 'epoch': 4.0}\n",
            "{'eval_loss': 1.2615551948547363, 'eval_exact_match': 0.1553398058252427, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1553398058252427, 'eval_f1': 0.9435019680041438, 'eval_runtime': 1.2505, 'eval_samples_per_second': 164.736, 'eval_steps_per_second': 20.792, 'epoch': 5.0}\n",
            "{'train_runtime': 110.9823, 'train_samples_per_second': 47.755, 'train_steps_per_second': 1.532, 'train_loss': 2.092702529009651, 'epoch': 5.0}\n",
            "{'eval_loss': 1.2615551948547363, 'eval_exact_match': 0.1553398058252427, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1553398058252427, 'eval_f1': 0.9435019680041438, 'eval_runtime': 1.2702, 'eval_samples_per_second': 162.179, 'eval_steps_per_second': 20.469, 'epoch': 5.0}\n",
            "✅ Iteration 9 done — F1: 0.9435, Accuracy: 0.4369, Time: 111.44s\n",
            "\n",
            "============================================================\n",
            "▶️ Training Iteration 10/10\n",
            "Params: {'epochs': 5, 'lr': 2e-05, 'batch': 8, 'warmup': 0.2, 'weight_decay': 0.01}\n",
            "============================================================\n",
            "🔄 Reloading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 3.799046277999878, 'eval_exact_match': 0.02912621359223301, 'eval_start_accuracy': 0.7815533980582524, 'eval_end_accuracy': 0.043689320388349516, 'eval_f1': 0.7863336658900512, 'eval_runtime': 1.2316, 'eval_samples_per_second': 167.261, 'eval_steps_per_second': 21.111, 'epoch': 1.0}\n",
            "{'eval_loss': 1.420223593711853, 'eval_exact_match': 0.1796116504854369, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1796116504854369, 'eval_f1': 0.9341191155070913, 'eval_runtime': 1.2684, 'eval_samples_per_second': 162.412, 'eval_steps_per_second': 20.499, 'epoch': 2.0}\n",
            "{'eval_loss': 1.270434021949768, 'eval_exact_match': 0.1407766990291262, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.1407766990291262, 'eval_f1': 0.9377535275629283, 'eval_runtime': 1.2098, 'eval_samples_per_second': 170.282, 'eval_steps_per_second': 21.492, 'epoch': 3.0}\n",
            "{'eval_loss': 1.360303282737732, 'eval_exact_match': 0.15048543689320387, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.15048543689320387, 'eval_f1': 0.9363777829153385, 'eval_runtime': 1.2075, 'eval_samples_per_second': 170.594, 'eval_steps_per_second': 21.531, 'epoch': 4.0}\n",
            "{'eval_loss': 1.2497169971466064, 'eval_exact_match': 0.16990291262135923, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16990291262135923, 'eval_f1': 0.944521048589139, 'eval_runtime': 1.1846, 'eval_samples_per_second': 173.892, 'eval_steps_per_second': 21.947, 'epoch': 5.0}\n",
            "{'train_runtime': 111.1312, 'train_samples_per_second': 47.691, 'train_steps_per_second': 1.53, 'train_loss': 2.2852370318244484, 'epoch': 5.0}\n",
            "{'eval_loss': 1.2497169971466064, 'eval_exact_match': 0.16990291262135923, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16990291262135923, 'eval_f1': 0.944521048589139, 'eval_runtime': 1.1948, 'eval_samples_per_second': 172.416, 'eval_steps_per_second': 21.761, 'epoch': 5.0}\n",
            "✅ Iteration 10 done — F1: 0.9445, Accuracy: 0.4466, Time: 111.58s\n",
            "\n",
            "✅ All 10 runs completed successfully!\n",
            "📊 Final results saved in one Excel file:\n",
            "➡️ /content/QA_Hyperparameter_Results_All.xlsx\n",
            "\n",
            "============================================================\n",
            "STARTING TRAINING\n",
            "============================================================\n",
            "\n",
            "🚀 Training in progress...\n",
            "\n",
            "{'eval_loss': 1.2067763805389404, 'eval_exact_match': 0.16019417475728157, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.16019417475728157, 'eval_f1': 0.940179186998716, 'eval_runtime': 1.2015, 'eval_samples_per_second': 171.455, 'eval_steps_per_second': 21.64, 'epoch': 1.0}\n",
            "{'eval_loss': 1.1240034103393555, 'eval_exact_match': 0.19902912621359223, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.19902912621359223, 'eval_f1': 0.9508453204071907, 'eval_runtime': 1.2077, 'eval_samples_per_second': 170.565, 'eval_steps_per_second': 21.528, 'epoch': 2.0}\n",
            "{'eval_loss': 1.1206005811691284, 'eval_exact_match': 0.20388349514563106, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.20388349514563106, 'eval_f1': 0.9506464491405198, 'eval_runtime': 1.2151, 'eval_samples_per_second': 169.538, 'eval_steps_per_second': 21.398, 'epoch': 3.0}\n",
            "{'eval_loss': 0.8996621966362, 'eval_exact_match': 0.34951456310679613, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.34951456310679613, 'eval_f1': 0.9613889142159566, 'eval_runtime': 1.2799, 'eval_samples_per_second': 160.95, 'eval_steps_per_second': 20.314, 'epoch': 4.0}\n",
            "{'eval_loss': 0.8835237622261047, 'eval_exact_match': 0.3883495145631068, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.3883495145631068, 'eval_f1': 0.9625356936472443, 'eval_runtime': 1.2122, 'eval_samples_per_second': 169.937, 'eval_steps_per_second': 21.448, 'epoch': 5.0}\n",
            "{'train_runtime': 110.5536, 'train_samples_per_second': 47.941, 'train_steps_per_second': 1.538, 'train_loss': 0.9091741225298713, 'epoch': 5.0}\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETED\n",
            "============================================================\n",
            "Training Loss: 0.9091741225298713\n",
            "\n",
            "============================================================\n",
            "FINAL EVALUATION\n",
            "============================================================\n",
            "{'eval_loss': 0.8835237622261047, 'eval_exact_match': 0.3883495145631068, 'eval_start_accuracy': 1.0, 'eval_end_accuracy': 0.3883495145631068, 'eval_f1': 0.9625356936472443, 'eval_runtime': 1.2239, 'eval_samples_per_second': 168.318, 'eval_steps_per_second': 21.244, 'epoch': 5.0}\n",
            "epoch: 5.0\n",
            "eval_end_accuracy: 0.3883495145631068\n",
            "eval_exact_match: 0.3883495145631068\n",
            "eval_f1: 0.9625356936472443\n",
            "eval_loss: 0.8835237622261047\n",
            "eval_runtime: 1.2239\n",
            "eval_samples_per_second: 168.318\n",
            "eval_start_accuracy: 1.0\n",
            "eval_steps_per_second: 21.244\n"
          ]
        }
      ],
      "source": [
        "# 1) Environment setup (Colab)\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def pip_install(packages):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages)\n",
        "\n",
        "# Core ML stack\n",
        "pip_install([\n",
        "    \"transformers>=4.44.0\",\n",
        "    \"datasets>=2.14.0\",\n",
        "    \"accelerate>=0.26.0\",\n",
        "    \"evaluate>=0.4.0\",\n",
        "])\n",
        "\n",
        "# Colab-specific checks\n",
        "try:\n",
        "    import torch\n",
        "    import platform\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ENVIRONMENT\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Python: {sys.version.split()[0]} | Platform: {platform.platform()}\")\n",
        "    print(f\"PyTorch: {torch.__version__}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)} | CUDA: {torch.version.cuda}\")\n",
        "    else:\n",
        "        print(\"GPU not detected. Enable a GPU in Runtime > Change runtime type > T4/other.\")\n",
        "    print(\"=\" * 60)\n",
        "except Exception as e:\n",
        "    print(\"Environment check failed:\", e)\n",
        "\n",
        "# 2) Imports and GPU config\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import default_data_collator\n",
        "from datasets import Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"GPU CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Memory: {round(torch.cuda.get_device_properties(0).total_memory / 1024**3, 2)} GB\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available; training will be slower.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 3) Dataset loading (Cardiovascular Q&A)\n",
        "# Option A: Mount Drive\n",
        "USE_DRIVE = False  # set True to use Drive\n",
        "CSV_PATH = \"\"       # e.g., \"/content/drive/MyDrive/medquadCardiovascular.csv\"\n",
        "\n",
        "if USE_DRIVE:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Option B: Upload a file\n",
        "USE_UPLOAD = not USE_DRIVE\n",
        "if USE_UPLOAD:\n",
        "    try:\n",
        "        from google.colab import files  # type: ignore\n",
        "        uploaded = files.upload()\n",
        "        # Pick the first uploaded file\n",
        "        if uploaded:\n",
        "            CSV_PATH = list(uploaded.keys())[0]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "if not CSV_PATH:\n",
        "    # Fallback sample: you can place the CSV at a public URL and download it\n",
        "    # For now, raise an error to prompt the user.\n",
        "    raise ValueError(\"Please provide CSV_PATH via Drive or upload.\")\n",
        "\n",
        "print(\"Dataset CSV:\", CSV_PATH)\n",
        "\n",
        "# 4) Load and split dataset\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LOADING CARDIOVASCULAR DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "dataset = pd.read_csv(CSV_PATH)\n",
        "print(f\"Total records: {len(dataset)}\")\n",
        "print(f\"Columns: {list(dataset.columns)}\")\n",
        "print(f\"Sample question: {str(dataset.iloc[0]['question'])[:80]}...\")\n",
        "print(f\"Sample answer chars: {len(str(dataset.iloc[0]['answer']))}\")\n",
        "\n",
        "# Drop nulls\n",
        "dataset = dataset.dropna(subset=[\"question\", \"answer\"]).reset_index(drop=True)\n",
        "\n",
        "# Train/val split (85/15)\n",
        "dataset_shuffled = dataset.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "split_idx = int(len(dataset_shuffled) * 0.85)\n",
        "train_data = dataset_shuffled.iloc[:split_idx].copy()\n",
        "eval_data = dataset_shuffled.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"Train: {len(train_data)} | Val: {len(eval_data)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 5) Model and tokenizer\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LOADING MODEL AND TOKENIZER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "MODEL_NAME = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "print(\"Model:\", MODEL_NAME)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "model.to(device)\n",
        "\n",
        "print(\"Model loaded.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "# 6) Tokenization and label prep (extractive QA)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TOKENIZING DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_data)\n",
        "eval_ds = Dataset.from_pandas(eval_data)\n",
        "\n",
        "MAX_LENGTH = 384\n",
        "DOC_STRIDE = 128\n",
        "\n",
        "def prepare_train_features(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"answer\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=MAX_LENGTH,\n",
        "        stride=DOC_STRIDE,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(tokenized[\"offset_mapping\"]):\n",
        "        sequence_ids = tokenized.sequence_ids(i)\n",
        "\n",
        "        context_start = None\n",
        "        context_end = None\n",
        "        for idx, seq_id in enumerate(sequence_ids):\n",
        "            if seq_id == 1:\n",
        "                if context_start is None:\n",
        "                    context_start = idx\n",
        "                context_end = idx\n",
        "\n",
        "        if context_start is None:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            answer_start = context_start\n",
        "            answer_end = min(context_start + 50, context_end)\n",
        "            start_positions.append(answer_start)\n",
        "            end_positions.append(answer_end)\n",
        "\n",
        "    tokenized[\"start_positions\"] = start_positions\n",
        "    tokenized[\"end_positions\"] = end_positions\n",
        "\n",
        "    # Drop offset_mapping so it isn't fed to the model\n",
        "    if \"offset_mapping\" in tokenized:\n",
        "        tokenized.pop(\"offset_mapping\")\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "print(\"Tokenizing train...\")\n",
        "tokenized_train = train_ds.map(\n",
        "    prepare_train_features,\n",
        "    batched=True,\n",
        "    remove_columns=train_ds.column_names,\n",
        "    desc=\"Tokenizing train\",\n",
        ")\n",
        "\n",
        "print(\"Tokenizing eval...\")\n",
        "tokenized_eval = eval_ds.map(\n",
        "    prepare_train_features,\n",
        "    batched=True,\n",
        "    remove_columns=eval_ds.column_names,\n",
        "    desc=\"Tokenizing eval\",\n",
        ")\n",
        "\n",
        "print(\"Done.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 7) Metrics\n",
        "import numpy as np\n",
        "\n",
        "def compute_qa_metrics(eval_pred):\n",
        "    predictions, label_ids = eval_pred\n",
        "    start_logits, end_logits = predictions\n",
        "\n",
        "    pred_starts = np.argmax(start_logits, axis=1)\n",
        "    pred_ends = np.argmax(end_logits, axis=1)\n",
        "\n",
        "    # Ensure label_ids is treated as a tuple\n",
        "    true_starts = np.asarray(label_ids[0]).reshape(-1)\n",
        "    true_ends = np.asarray(label_ids[1]).reshape(-1)\n",
        "\n",
        "    exact_match = np.mean((pred_starts == true_starts) & (pred_ends == true_ends))\n",
        "    start_accuracy = np.mean(pred_starts == true_starts)\n",
        "    end_accuracy = np.mean(pred_ends == true_ends)\n",
        "\n",
        "    f1_scores = []\n",
        "    for ps, pe, ts, te in zip(pred_starts, pred_ends, true_starts, true_ends):\n",
        "        ps, pe, ts, te = int(ps), int(pe), int(ts), int(te)\n",
        "        pred_tokens = set(range(ps, pe + 1))\n",
        "        true_tokens = set(range(ts, te + 1))\n",
        "        if not pred_tokens and not true_tokens:\n",
        "            f1_scores.append(1.0)\n",
        "        elif not pred_tokens or not true_tokens:\n",
        "            f1_scores.append(0.0)\n",
        "        else:\n",
        "            common = len(pred_tokens & true_tokens)\n",
        "            if common == 0:\n",
        "                f1_scores.append(0.0)\n",
        "            else:\n",
        "                precision = common / len(pred_tokens)\n",
        "                recall = common / len(true_tokens)\n",
        "                f1_scores.append(2 * (precision * recall) / (precision + recall))\n",
        "\n",
        "    return {\n",
        "        \"exact_match\": float(exact_match),\n",
        "        \"start_accuracy\": float(start_accuracy),\n",
        "        \"end_accuracy\": float(end_accuracy),\n",
        "        \"f1\": float(np.mean(f1_scores)) if f1_scores else 0.0,\n",
        "    }\n",
        "\n",
        "print(\"Metrics ready.\")\n",
        "\n",
        "# 8) Training configuration (T4 GPU Optimized)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TRAINING CONFIGURATION (T4 GPU OPTIMIZED)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_cardio_qa\",\n",
        "    num_train_epochs=5,  # Increased for better convergence\n",
        "    per_device_train_batch_size=8,  # Reduced for T4 memory (16GB)\n",
        "    per_device_eval_batch_size=8,  # Matched with train batch\n",
        "    gradient_accumulation_steps=4,  # Increased to maintain effective batch size of 32\n",
        "    learning_rate=2e-5,  # Slightly lower for medical domain stability\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.15,  # More warmup for better stability\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    max_grad_norm=1.0,\n",
        "    fp16=torch.cuda.is_available(),  # Essential for T4 performance\n",
        "    dataloader_pin_memory=True,\n",
        "    dataloader_num_workers=2,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    logging_dir=\"./logs_cardio_qa\",\n",
        "    logging_steps=25,  # More frequent logging\n",
        "    logging_strategy=\"steps\",\n",
        "    report_to=[],\n",
        "    seed=42,\n",
        "    disable_tqdm=False,\n",
        "    remove_unused_columns=True,\n",
        "    # T4-specific optimizations\n",
        "    gradient_checkpointing=False,  # Disabled for speed (T4 has enough memory)\n",
        "    optim=\"adamw_torch\",  # PyTorch AdamW is faster on T4\n",
        "    lr_scheduler_kwargs={\"num_cycles\": 0.5},  # Cosine annealing alternative\n",
        ")\n",
        "\n",
        "print(\"T4 GPU Configuration:\")\n",
        "print(f\"  - Batch Size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"  - Gradient Accumulation: {training_args.gradient_accumulation_steps}\")\n",
        "print(f\"  - Effective Batch Size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
        "print(f\"  - FP16 Enabled: {training_args.fp16}\")\n",
        "print(f\"  - Learning Rate: {training_args.learning_rate}\")\n",
        "print(f\"  - Epochs: {training_args.num_train_epochs}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 9) Initialize Trainer\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"INITIALIZING TRAINER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        "    compute_metrics=compute_qa_metrics,\n",
        ")\n",
        "\n",
        "print(\"Trainer ready.\")\n",
        "\n",
        "import time\n",
        "from openpyxl import Workbook\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"HYPERPARAMETER TUNING (T4 GPU OPTIMIZED - 15 ITERATIONS)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# T4-optimized hyperparameter sets (memory-safe with effective performance)\n",
        "hyperparam_sets = [\n",
        "    {\"epochs\": 5, \"lr\": 2e-5,  \"batch\": 8, \"warmup\": 0.15, \"weight_decay\": 0.01},\n",
        "    {\"epochs\": 5, \"lr\": 3e-5,  \"batch\": 8, \"warmup\": 0.15, \"weight_decay\": 0.01},\n",
        "    {\"epochs\": 5, \"lr\": 1.5e-5, \"batch\": 8, \"warmup\": 0.15, \"weight_decay\": 0.01},\n",
        "    {\"epochs\": 7, \"lr\": 2e-5,  \"batch\": 8, \"warmup\": 0.15, \"weight_decay\": 0.01},\n",
        "    {\"epochs\": 10, \"lr\": 2e-5, \"batch\": 8, \"warmup\": 0.15, \"weight_decay\": 0.01},\n",
        "    {\"epochs\": 5, \"lr\": 4e-5,  \"batch\": 8, \"warmup\": 0.15, \"weight_decay\": 0.01},\n",
        "    {\"epochs\": 5, \"lr\": 5e-5,  \"batch\": 8, \"warmup\": 0.15, \"weight_decay\": 0.01},\n",
        "    {\"epochs\": 5, \"lr\": 1e-5,  \"batch\": 8, \"warmup\": 0.15, \"weight_decay\": 0.01},\n",
        "    {\"epochs\": 5, \"lr\": 2e-5,  \"batch\": 8, \"warmup\": 0.1,  \"weight_decay\": 0.01},\n",
        "    {\"epochs\": 5, \"lr\": 2e-5,  \"batch\": 8, \"warmup\": 0.2,  \"weight_decay\": 0.01},\n",
        "]\n",
        "\n",
        "total_iters = len(hyperparam_sets)\n",
        "print(f\"Running {total_iters} T4-optimized configurations\")\n",
        "print(f\"Fixed batch size: 8 (optimal for T4 16GB memory)\")\n",
        "print(f\"Gradient accumulation: 4 (effective batch size: 32)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Excel setup\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"QA Hyperparameter Results\"\n",
        "ws.append([\n",
        "    \"Iteration\", \"Epochs\", \"Learning Rate\", \"Batch Size\", \"Warmup Ratio\", \"Weight Decay\",\n",
        "    \"Accuracy\", \"F1-Score\", \"Precision\", \"Recall\", \"Runtime (s)\"\n",
        "])\n",
        "\n",
        "# Loop through each configuration\n",
        "for i, params in enumerate(hyperparam_sets, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"▶️ Training Iteration {i}/{total_iters}\")\n",
        "    print(f\"Params: {params}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # CRITICAL: Reload model from scratch for each iteration to avoid weight corruption\n",
        "    print(\"🔄 Reloading fresh model...\")\n",
        "    model_fresh = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "    model_fresh.to(device)\n",
        "\n",
        "    # Update training arguments dynamically\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_run_{i}\",\n",
        "        num_train_epochs=params[\"epochs\"],\n",
        "        per_device_train_batch_size=params[\"batch\"],\n",
        "        per_device_eval_batch_size=params[\"batch\"],\n",
        "        gradient_accumulation_steps=4,  # Fixed at 4 for T4 optimization\n",
        "        learning_rate=params[\"lr\"],\n",
        "        warmup_ratio=params[\"warmup\"],\n",
        "        weight_decay=params[\"weight_decay\"],\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_dir=f\"./logs_run_{i}\",\n",
        "        report_to=[],\n",
        "        disable_tqdm=True,\n",
        "        seed=42,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        optim=\"adamw_torch\",  # T4-optimized optimizer\n",
        "        max_grad_norm=1.0,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model_fresh,  # Use fresh model instance\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_eval,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "        compute_metrics=compute_qa_metrics,\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    trainer.train()\n",
        "    runtime = round(time.time() - start_time, 2)\n",
        "\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    # Extract basic metrics (handle 'eval_' prefix from HF evaluate)\n",
        "    exact_match = eval_results.get(\"eval_exact_match\", eval_results.get(\"exact_match\", 0))\n",
        "    start_acc = eval_results.get(\"eval_start_accuracy\", eval_results.get(\"start_accuracy\", 0))\n",
        "    end_acc = eval_results.get(\"eval_end_accuracy\", eval_results.get(\"end_accuracy\", 0))\n",
        "    accuracy = (exact_match + start_acc + end_acc) / 3\n",
        "    f1 = eval_results.get(\"eval_f1\", eval_results.get(\"f1\", 0))\n",
        "\n",
        "    # Calculate REAL precision and recall from token overlap\n",
        "    predictions = trainer.predict(tokenized_eval)\n",
        "    pred_starts = np.argmax(predictions.predictions[0], axis=1)\n",
        "    pred_ends = np.argmax(predictions.predictions[1], axis=1)\n",
        "\n",
        "    true_starts = np.asarray(predictions.label_ids[0]).reshape(-1)\n",
        "    true_ends = np.asarray(predictions.label_ids[1]).reshape(-1)\n",
        "\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "\n",
        "    for ps, pe, ts, te in zip(pred_starts, pred_ends, true_starts, true_ends):\n",
        "        ps, pe, ts, te = int(ps), int(pe), int(ts), int(te)\n",
        "        pred_tokens = set(range(ps, pe + 1))\n",
        "        true_tokens = set(range(ts, te + 1))\n",
        "\n",
        "        if not pred_tokens and not true_tokens:\n",
        "            precision_scores.append(1.0)\n",
        "            recall_scores.append(1.0)\n",
        "        elif not pred_tokens or not true_tokens:\n",
        "            precision_scores.append(0.0)\n",
        "            recall_scores.append(0.0)\n",
        "        else:\n",
        "            common = len(pred_tokens & true_tokens)\n",
        "            if common == 0:\n",
        "                precision_scores.append(0.0)\n",
        "                recall_scores.append(0.0)\n",
        "            else:\n",
        "                precision = common / len(pred_tokens)\n",
        "                recall = common / len(true_tokens)\n",
        "                precision_scores.append(precision)\n",
        "                recall_scores.append(recall)\n",
        "\n",
        "    precision = float(np.mean(precision_scores))\n",
        "    recall = float(np.mean(recall_scores))\n",
        "\n",
        "    ws.append([\n",
        "        i, params[\"epochs\"], params[\"lr\"], params[\"batch\"], params[\"warmup\"], params[\"weight_decay\"],\n",
        "        round(accuracy, 4), round(f1, 4), round(precision, 4), round(recall, 4), runtime\n",
        "    ])\n",
        "\n",
        "\n",
        "    print(f\"✅ Iteration {i} done — F1: {f1:.4f}, Accuracy: {accuracy:.4f}, Time: {runtime}s\")\n",
        "\n",
        "# ==========================\n",
        "# ✅ Save All Results in One Excel File\n",
        "# ==========================\n",
        "from openpyxl.styles import Font, Alignment\n",
        "\n",
        "# Auto-format headers for readability\n",
        "for cell in ws[1]:\n",
        "    cell.font = Font(bold=True)\n",
        "    cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
        "\n",
        "# Adjust column widths (optional aesthetic)\n",
        "for col in ws.columns:\n",
        "    max_length = 0\n",
        "    col_letter = col[0].column_letter\n",
        "    for cell in col:\n",
        "        try:\n",
        "            if len(str(cell.value)) > max_length:\n",
        "                max_length = len(str(cell.value))\n",
        "        except:\n",
        "            pass\n",
        "    adjusted_width = (max_length + 2)\n",
        "    ws.column_dimensions[col_letter].width = adjusted_width\n",
        "\n",
        "# Save Excel file\n",
        "output_excel = \"/content/QA_Hyperparameter_Results_All.xlsx\"\n",
        "wb.save(output_excel)\n",
        "\n",
        "print(f\"\\n✅ All {total_iters} runs completed successfully!\")\n",
        "print(\"📊 Final results saved in one Excel file:\")\n",
        "print(f\"➡️ {output_excel}\")\n",
        "\n",
        "# 10) Train\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n🚀 Training in progress...\\n\")\n",
        "\n",
        "train_result = trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TRAINING COMPLETED\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Training Loss:\", getattr(train_result, \"training_loss\", None))\n",
        "\n",
        "# 11) Evaluate\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "for k, v in sorted(eval_results.items()):\n",
        "    print(f\"{k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12) Save the trained model\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SAVING TRAINED MODEL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Define output directory\n",
        "output_model_dir = \"./fine_tuned_cardio_qa_model\"\n",
        "\n",
        "# Save the model and tokenizer\n",
        "trainer.save_model(output_model_dir)\n",
        "tokenizer.save_pretrained(output_model_dir)\n",
        "\n",
        "print(f\"✅ Model saved to: {output_model_dir}\")\n",
        "print(f\"📦 Saved components:\")\n",
        "print(f\"   - Model weights: pytorch_model.bin\")\n",
        "print(f\"   - Model config: config.json\")\n",
        "print(f\"   - Tokenizer files: tokenizer_config.json, vocab.txt, etc.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Optional: Save to Google Drive for persistence\n",
        "SAVE_TO_DRIVE = False  # Set to True if you want to save to Drive\n",
        "\n",
        "if SAVE_TO_DRIVE:\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        import shutil\n",
        "\n",
        "        # Mount Drive if not already mounted\n",
        "        if not os.path.exists('/content/drive'):\n",
        "            drive.mount('/content/drive')\n",
        "\n",
        "        # Define Drive destination\n",
        "        drive_model_dir = \"/content/drive/MyDrive/fine_tuned_cardio_qa_model\"\n",
        "\n",
        "        # Copy model to Drive\n",
        "        print(f\"\\n📤 Copying model to Google Drive...\")\n",
        "        if os.path.exists(drive_model_dir):\n",
        "            shutil.rmtree(drive_model_dir)\n",
        "        shutil.copytree(output_model_dir, drive_model_dir)\n",
        "\n",
        "        print(f\"✅ Model also saved to Google Drive: {drive_model_dir}\")\n",
        "        print(\"💾 Your model will persist even after the Colab session ends!\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not save to Google Drive: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"🎉 TRAINING PIPELINE COMPLETE!\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N11FfO7RlrS",
        "outputId": "59deb903-baf3-489b-ece7-9a83a49b11ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SAVING TRAINED MODEL\n",
            "============================================================\n",
            "✅ Model saved to: ./fine_tuned_cardio_qa_model\n",
            "📦 Saved components:\n",
            "   - Model weights: pytorch_model.bin\n",
            "   - Model config: config.json\n",
            "   - Tokenizer files: tokenizer_config.json, vocab.txt, etc.\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "🎉 TRAINING PIPELINE COMPLETE!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXvndYEneYa8",
        "outputId": "a99b93f8-5e53-465c-fa0b-909ec437cbc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}