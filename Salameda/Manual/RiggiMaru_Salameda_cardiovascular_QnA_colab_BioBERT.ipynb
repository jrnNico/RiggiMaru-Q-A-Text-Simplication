{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Context\n",
        "\n",
        "This dataset focuses exclusively on cardiovascular-related health issues, offering a specialized resource for exploring how language models can enhance medical understanding and patient care in this domain. Built on MedQuAD the Medical Question Answering Dataset it provides a rich collection of text data suitable for tasks such as summarization, question answering, token labeling, and text classification. With support for large language models, healthcare-specific transformers, and LayoutLM models for semi-structured documents, the dataset is particularly well-suited for developing NLP applications that simplify complex cardiovascular information, improve accessibility for patients, and assist healthcare professionals in decision-making.\n",
        "\n",
        "The file itself is a CSV version of MedQuAD converted from XML source files, excluding MedLinePlus data due to licensing restrictions. MedQuAD contains 47,457 medical question-answer pairs from 12 NIH websites, covering 37 question types such as treatment, diagnosis, and side effects, with additional annotations like question type, focus, synonyms, UMLS identifiers, and semantic categories. While some subsets had answers removed to respect copyright, metadata and URLs remain available for further exploration. The dataset also includes a QA test collection with 2,479 judged answers from the TREC-2017 LiveQA medical task, enabling evaluation of IR and QA systems. Together, these resources provide a comprehensive foundation for cardiovascular-focused NLP research and experimentation.\n"
      ],
      "metadata": {
        "id": "VJaTg0X7vDkG"
      },
      "id": "VJaTg0X7vDkG"
    },
    {
      "cell_type": "markdown",
      "id": "294cce7b",
      "metadata": {
        "id": "294cce7b"
      },
      "source": [
        "# BioBERT Cardiovascular QA - Code Structure and Functionality\n",
        "\n",
        "This document explains the code structure for fine-tuning BioBERT on cardiovascular question answering tasks using Google Colab.\n",
        "\n",
        "## 1. Environment Setup and Configuration\n",
        "\n",
        "This section sets up everything needed to run the machine learning code in Google Colab.\n",
        "\n",
        "\n",
        "* Creates a helper function to install Python packages quietly without cluttering the output\n",
        "* Installs the core libraries needed for the project:\n",
        "  * Transformers (version 4.44.0 or higher) - works with pre-trained BERT models\n",
        "  * Datasets (version 2.14.0 or higher) - handles data efficiently\n",
        "  * Accelerate (version 0.26.0 or higher) - speeds up training\n",
        "  * Evaluate (version 0.4.0 or higher) - calculates performance metrics\n",
        "* Checks the Python version and operating system details\n",
        "* Verifies that PyTorch is installed correctly\n",
        "* Detects if a GPU is available for training\n",
        "* Shows GPU information like model name and CUDA version\n",
        "* Warns users if no GPU is found and reminds them to enable it in Colab settings\n",
        "\n",
        "GPU acceleration is essential for training transformer models. Without it, training would take hours or days instead of minutes. This section makes sure everything is configured properly before starting the actual work.\n",
        "\n",
        "## 2. Imports and GPU Configuration\n",
        "\n",
        "This section imports all the necessary Python libraries and confirms GPU availability.\n",
        "\n",
        "* Imports PyTorch for deep learning operations\n",
        "* Imports NumPy for numerical calculations\n",
        "* Imports Pandas for working with data tables\n",
        "* Imports specific tools from Transformers library:\n",
        "  * AutoTokenizer - converts text to numbers the model understands\n",
        "  * AutoModelForQuestionAnswering - loads pre-trained QA models\n",
        "  * TrainingArguments - sets up training parameters\n",
        "  * Trainer - handles the training process\n",
        "  * default_data_collator - organizes batches of data\n",
        "* Imports Dataset from the datasets library for efficient data handling\n",
        "* Turns off warning messages to keep output clean\n",
        "* Creates a CUDA device object if GPU is available\n",
        "* Displays detailed GPU information including memory size\n",
        "\n",
        "**Important code sections:**\n",
        "* `device = torch.device(\"cuda\")` - tells PyTorch to use the GPU\n",
        "* `torch.cuda.get_device_name(0)` - gets the GPU model name (like Tesla T4)\n",
        "* `torch.cuda.get_device_properties(0).total_memory` - shows how much GPU memory is available\n",
        "\n",
        "## 3. Dataset Loading Options\n",
        "\n",
        "This section provides flexible ways to load the cardiovascular dataset in Colab.\n",
        "* Uses boolean flags (USE_DRIVE and USE_UPLOAD) to switch between methods\n",
        "* Defaults to the upload option for simplicity\n",
        "* For Google Drive: requires you to specify the file path\n",
        "* For upload: uses Colab's file picker interface\n",
        "* Raises an error if no valid CSV path is provided\n",
        "\n",
        "* `from google.colab import drive` - enables Google Drive mounting\n",
        "* `drive.mount('/content/drive')` - connects your Google Drive\n",
        "* `from google.colab import files` - enables file upload\n",
        "* `files.upload()` - opens the file picker dialog\n",
        "\n",
        "\n",
        "\n",
        "## 4. Data Loading and Preprocessing\n",
        "\n",
        "This section loads the cardiovascular medical questions and answers, then prepares them for training.\n",
        "\n",
        "* Reads the CSV file using Pandas\n",
        "* Shows diagnostic information:\n",
        "  * Total number of question-answer pairs\n",
        "  * Column names in the dataset\n",
        "  * Sample question preview\n",
        "  * Length of a sample answer\n",
        "* Removes any rows with missing questions or answers (null values)\n",
        "* Shuffles the dataset randomly using a fixed random seed (42) for reproducibility\n",
        "* Splits data into training set (80%) and test set (20%)\n",
        "* Displays the size of each set\n",
        "\n",
        "* `dataset.dropna(subset=[\"question\", \"answer\"])` - removes incomplete data\n",
        "* `dataset.sample(frac=1.0, random_state=42)` - shuffles with fixed seed\n",
        "* `split_idx = int(len(dataset_shuffled) * 0.80)` - calculates 80/20 split point\n",
        "\n",
        "Clean data is crucial. Null values would cause errors during training. The 80/20 split ensures we have plenty of data for training while keeping enough aside to test how well the model generalizes to new questions.\n",
        "\n",
        "## 5. Model and Tokenizer Initialization\n",
        "\n",
        "This section loads the pre-trained BioBERT model and its tokenizer.\n",
        "\n",
        "* Sets the model name to \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "* Downloads the BioBERT tokenizer from Hugging Face\n",
        "* Enables the fast tokenizer option for better performance\n",
        "* Downloads the BioBERT model pre-trained for question answering\n",
        "* Moves the model to the GPU (or CPU if no GPU available)\n",
        "\n",
        "* `AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)` - loads tokenizer\n",
        "* `AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)` - loads model\n",
        "* `model.to(device)` - transfers model to GPU for faster computation\n",
        "\n",
        "BioBERT is not just regular BERT. It has been pre-trained on millions of biomedical research papers from PubMed and PMC. This gives it deep knowledge of medical terminology, diseases, treatments, and healthcare concepts. When you fine-tune it on cardiovascular questions, it already understands medical language, so it learns faster and performs better than general-purpose models.\n",
        "\n",
        "## 6. Tokenization and Feature Preparation\n",
        "\n",
        "This is one of the most complex sections. It converts text into numbers and prepares labels for training.\n",
        "\n",
        "* Converts Pandas dataframes into Hugging Face Dataset objects\n",
        "* Sets maximum sequence length to 384 tokens (BERT's typical limit)\n",
        "* Sets document stride to 128 tokens for handling long texts\n",
        "* Creates a function called `prepare_train_features` that:\n",
        "  * Tokenizes questions and answers together\n",
        "  * Truncates only the answer part if text is too long\n",
        "  * Identifies which tokens belong to the question vs the answer\n",
        "  * Sets start and end positions for where the answer begins and ends\n",
        "  * Handles cases where context might overflow into multiple examples\n",
        "  * Removes temporary data structures not needed by the model\n",
        "* Applies this tokenization to both training and test datasets in batches\n",
        "\n",
        "* `tokenizer(examples[\"question\"], examples[\"answer\"], truncation=\"only_second\")` - tokenizes both question and answer, only cutting the answer if needed\n",
        "* `sequence_ids = tokenized.sequence_ids(i)` - identifies which tokens are question (0) and which are answer (1)\n",
        "* `start_positions.append(answer_start)` - marks where the answer starts\n",
        "* `end_positions.append(answer_end)` - marks where the answer ends\n",
        "\n",
        "Question answering is different from simple classification. The model doesn't just predict yes/no or choose a category. Instead, it must predict exactly which tokens in the text contain the answer. This requires careful position labeling so the model learns to point at the correct span of text.\n",
        "\n",
        "## 7. Evaluation Metrics Definition\n",
        "\n",
        "This section defines how to measure model performance with multiple metrics.\n",
        "\n",
        "* Creates a function `calculate_detailed_metrics` that:\n",
        "  * Extracts predicted start and end positions from model output\n",
        "  * Compares predictions to true answer positions\n",
        "  * Calculates exact match (when both start and end are correct)\n",
        "  * Calculates start accuracy (correct start position)\n",
        "  * Calculates end accuracy (correct end position)\n",
        "  * Calculates overall accuracy as average of the three above\n",
        "  * Computes F1 score based on token overlap\n",
        "  * Computes precision (what percent of predicted tokens are correct)\n",
        "  * Computes recall (what percent of correct tokens were found)\n",
        "* Creates `evaluate_dataset` function to evaluate any dataset efficiently\n",
        "* Creates `compute_qa_metrics` for compatibility with Trainer API\n",
        "\n",
        "* `pred_starts = np.argmax(predictions.predictions[0], axis=1)` - finds most likely start position\n",
        "* `pred_ends = np.argmax(predictions.predictions[1], axis=1)` - finds most likely end position\n",
        "* `exact_match = np.mean((pred_starts == true_starts) & (pred_ends == true_ends))` - checks perfect predictions\n",
        "* F1 calculation treats answer spans as sets of token positions and measures overlap\n",
        "\n",
        "Different metrics tell different stories. Accuracy shows overall correctness. F1 balances precision and recall. Precision shows if predictions are reliable. Recall shows if the model finds all correct answers. Looking at all these together gives a complete picture of model performance.\n",
        "\n",
        "## 8. Training Configuration\n",
        "\n",
        "This section sets up all the hyperparameters and training options optimized for Colab's T4 GPU.\n",
        "\n",
        "* Creates a TrainingArguments object with settings:\n",
        "  * **num_train_epochs=3** - trains for 3 complete passes through the data\n",
        "  * **per_device_train_batch_size=16** - processes 16 examples at once\n",
        "  * **gradient_accumulation_steps=2** - simulates batch size of 32 (16 x 2)\n",
        "  * **learning_rate=0.00003** - controls how fast the model updates (3e-5)\n",
        "  * **weight_decay=0.01** - adds regularization to prevent overfitting\n",
        "  * **warmup_ratio=0.1** - gradually increases learning rate for first 10% of training\n",
        "  * **max_grad_norm=1.0** - prevents gradient explosion\n",
        "  * **fp16=True** - uses mixed precision for 2x faster training on GPU\n",
        "  * **eval_strategy=\"epoch\"** - evaluates after each epoch\n",
        "  * **save_strategy=\"epoch\"** - saves checkpoint after each epoch\n",
        "  * **save_total_limit=2** - keeps only best 2 checkpoints to save space\n",
        "  * **metric_for_best_model=\"f1\"** - uses F1 score to determine best model\n",
        "  * **seed=42** - fixes random seed for reproducibility\n",
        "\n",
        "* `fp16=torch.cuda.is_available()` - enables mixed precision only if GPU exists\n",
        "* `dataloader_num_workers=0` - optimized for T4 GPU with limited CPU cores\n",
        "* `load_best_model_at_end=True` - automatically loads best checkpoint when done\n",
        "\n",
        "These values are carefully chosen based on what works well for BERT models and Colab's T4 GPU limitations. The batch size balances speed and memory usage. The learning rate is standard for fine-tuning. Mixed precision (fp16) dramatically speeds up training without hurting accuracy.\n",
        "\n",
        "## 9. Trainer Initialization\n",
        "\n",
        "This section creates the Trainer object that handles all the training complexity.\n",
        "\n",
        "* Combines everything into one Trainer object:\n",
        "  * The BioBERT model\n",
        "  * Training arguments from previous section\n",
        "  * Training dataset (tokenized)\n",
        "  * Evaluation dataset (tokenized test set)\n",
        "  * Tokenizer\n",
        "  * Data collator (handles batching and padding)\n",
        "  * Metrics function for evaluation\n",
        "\n",
        "* `Trainer(model=model, args=training_args, ...)` - creates the trainer\n",
        "* `train_dataset=tokenized_train` - provides training data\n",
        "* `eval_dataset=tokenized_test` - provides test data for evaluation\n",
        "* `compute_metrics=compute_qa_metrics` - enables custom metrics calculation\n",
        "\n",
        "* Handles the training loop (forward pass, loss calculation, backward pass)\n",
        "* Manages gradient computation and backpropagation\n",
        "* Updates model weights using the optimizer\n",
        "* Adjusts learning rate according to schedule\n",
        "* Handles mixed precision training\n",
        "* Runs evaluation at specified intervals\n",
        "* Saves checkpoints\n",
        "* Logs metrics to track progress\n",
        "* Supports distributed training across multiple GPUs\n",
        "\n",
        "Without the Trainer, you would need to write hundreds of lines of code to handle all these aspects manually. The Trainer API makes it simple while still offering extensive customization options.\n",
        "\n",
        "## 10. Hyperparameter Tuning Experiment with Train-Test Metrics\n",
        "\n",
        "This section runs 10 different training experiments to find the best hyperparameter combination.\n",
        "\n",
        "* Defines 10 different configurations varying:\n",
        "  * Number of epochs (5 to 14)\n",
        "  * Learning rate (0.00003 to 0.00007)\n",
        "  * Batch size (8, 12, or 16)\n",
        "  * Gradient accumulation (1, 4, or 6)\n",
        "  * Warmup ratio (0.06 to 0.18)\n",
        "  * Weight decay (0.006 to 0.022)\n",
        "* Creates an Excel workbook to store results\n",
        "* For each configuration:\n",
        "  * Reloads a fresh BioBERT model (ensures fair comparison)\n",
        "  * Configures training arguments with specific hyperparameters\n",
        "  * Creates a new Trainer\n",
        "  * Trains the model and times how long it takes\n",
        "  * Evaluates on training set (to check if model learned)\n",
        "  * Evaluates on test set (to check if model generalizes)\n",
        "  * Saves all results to Excel with columns:\n",
        "    * Hyperparameter values\n",
        "    * Train-Accuracy, Test-Accuracy\n",
        "    * Train-F1, Test-F1\n",
        "    * Train-Precision, Test-Precision\n",
        "    * Train-Recall, Test-Recall\n",
        "    * Runtime in seconds\n",
        "  * Clears GPU memory before next iteration\n",
        "* Formats the Excel file with bold headers and adjusted column widths\n",
        "* Saves the file to Colab's content folder\n",
        "\n",
        "* `model_fresh = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)` - reloads fresh model each time\n",
        "* `trainer.train()` - runs the training\n",
        "* `train_metrics = evaluate_dataset(trainer, tokenized_train, \"TRAIN\")` - evaluates training performance\n",
        "* `test_metrics = evaluate_dataset(trainer, tokenized_test, \"TEST\")` - evaluates test performance\n",
        "* `torch.cuda.empty_cache()` - clears GPU memory between experiments\n",
        "* `wb.save(output_excel)` - saves Excel file with all results\n",
        "\n",
        "By testing 10 carefully chosen configurations, you can identify which hyperparameters work best for this specific task. The side-by-side train-test metrics make it easy to spot overfitting (when training performance is much better than test performance). Starting fresh for each experiment ensures fair comparison without any carryover effects from previous training.\n",
        "\n",
        "* Configurations where test accuracy is close to training accuracy (good generalization)\n",
        "* High F1 scores on test set (model finds correct answers)\n",
        "* Reasonable training time (under 3-4 minutes per experiment)\n",
        "* Avoid configurations where training accuracy is perfect (1.0) but test accuracy drops significantly (overfitting)\n",
        "\n",
        "* Uses `dataloader_num_workers=0` because T4 has limited CPU cores\n",
        "* Enables `fp16` mixed precision for 2x speed boost\n",
        "* Clears GPU cache between iterations to prevent memory issues\n",
        "* Uses efficient batch sizes (8, 12, 16) that fit in T4's memory\n",
        "* Gradient accumulation simulates larger batches without exceeding memory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "KoZtQtbjcUGk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "12467de2c7ae4224856a94676be020fc",
            "bee7a50cdd37482faffe0acc43057a65",
            "c48c68feee7a4e2781cefe8337089d93",
            "43b47879b6bd4d67aa7f7dbaf04f826b",
            "caefe684428c46d89d9a185bc05bc6f9",
            "26fc5b95833a4df89ca7f64a03c6f6ec",
            "430dd36a066247a9a6e104923bdd82d9",
            "a51f021c93194e0cba577341b61978e0",
            "a617d636c3c74f36821cd7eb6e80e1ff",
            "79350f588f914e729b55f6b84ed386b0",
            "2f237564307346e7b1b49d215290cc3e",
            "868846bf93c24afa8297c688b4d9b9a8",
            "5540c8c1840b4b2db2e3dc8ac28707c0",
            "b6015afe49734f5895b0def3b163fb55",
            "2c894981f85647198d3371861d9a425a",
            "8bdd0783deae422ca0a5f4ae403bb12b",
            "0bc035553b284c69a58af021479c75cb",
            "17d5a914a376476ba970aa5f0772360a",
            "c9ae8a417155454abca11019893a65bc",
            "0b2e8d1b99c7401ba109b0d00af8ffe7",
            "b91115dcf8ea45afbe872cf1da920117",
            "357007e0240241d685d0ed12dbd31aa9"
          ]
        },
        "id": "KoZtQtbjcUGk",
        "outputId": "9166aa6a-1b81-4d8e-b247-0c5672aa9298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ENVIRONMENT\n",
            "============================================================\n",
            "Python: 3.12.12 | Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "PyTorch: 2.8.0+cu126\n",
            "GPU: Tesla T4 | CUDA: 12.6\n",
            "============================================================\n",
            "============================================================\n",
            "GPU CONFIGURATION\n",
            "============================================================\n",
            "GPU Available: Tesla T4\n",
            "CUDA Version: 12.6\n",
            "GPU Memory: 14.74 GB\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0fa13c0d-1a90-4cbb-9935-e51dd1a6cb35\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0fa13c0d-1a90-4cbb-9935-e51dd1a6cb35\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving medquadCardiovascular.csv to medquadCardiovascular (2).csv\n",
            "Dataset CSV: medquadCardiovascular (2).csv\n",
            "\n",
            "============================================================\n",
            "LOADING CARDIOVASCULAR DATASET\n",
            "============================================================\n",
            "Total records: 654\n",
            "Columns: ['question', 'answer', 'source', 'focus_area']\n",
            "Sample question: What is (are) High Blood Pressure ?...\n",
            "Sample answer chars: 5586\n",
            "Train: 523 | Test: 131\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "LOADING MODEL AND TOKENIZER\n",
            "============================================================\n",
            "Model: dmis-lab/biobert-base-cased-v1.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TOKENIZING DATASET\n",
            "============================================================\n",
            "Tokenizing train...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train:   0%|          | 0/523 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12467de2c7ae4224856a94676be020fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing test...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing test:   0%|          | 0/131 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "868846bf93c24afa8297c688b4d9b9a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "============================================================\n",
            "Metrics functions ready.\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TRAINING CONFIGURATION\n",
            "============================================================\n",
            "Configured. FP16: True\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "INITIALIZING TRAINER\n",
            "============================================================\n",
            "Trainer ready.\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "HYPERPARAMETER TUNING (10 CONFIGURATIONS)\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            " Iteration 1/10\n",
            "Params: Epochs=5, LR=4e-05, Batch=16, GradAccum=1\n",
            "============================================================\n",
            " Loading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [315/315 01:45, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Iteration 1 complete!\n",
            "   Train - F1: 0.9995, Acc: 0.9832\n",
            "   Test  - F1: 0.9944, Acc: 0.8824\n",
            "   Runtime: 106.95s\n",
            "\n",
            "============================================================\n",
            " Iteration 2/10\n",
            "Params: Epochs=6, LR=5e-05, Batch=16, GradAccum=1\n",
            "============================================================\n",
            " Loading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [378/378 01:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Iteration 2 complete!\n",
            "   Train - F1: 0.9998, Acc: 0.9940\n",
            "   Test  - F1: 0.9996, Acc: 0.9730\n",
            "   Runtime: 116.54s\n",
            "\n",
            "============================================================\n",
            " Iteration 3/10\n",
            "Params: Epochs=6, LR=3.5e-05, Batch=12, GradAccum=1\n",
            "============================================================\n",
            " Loading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='498' max='498' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [498/498 01:59, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Iteration 3 complete!\n",
            "   Train - F1: 0.9925, Acc: 0.9142\n",
            "   Test  - F1: 0.9816, Acc: 0.7966\n",
            "   Runtime: 120.62s\n",
            "\n",
            "============================================================\n",
            " Iteration 4/10\n",
            "Params: Epochs=8, LR=6e-05, Batch=8, GradAccum=4\n",
            "============================================================\n",
            " Loading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='256' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [256/256 02:32, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Iteration 4 complete!\n",
            "   Train - F1: 0.9993, Acc: 0.9537\n",
            "   Test  - F1: 0.9954, Acc: 0.9363\n",
            "   Runtime: 153.42s\n",
            "\n",
            "============================================================\n",
            " Iteration 5/10\n",
            "Params: Epochs=8, LR=4.5e-05, Batch=16, GradAccum=1\n",
            "============================================================\n",
            " Loading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [504/504 02:31, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.972900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Iteration 5 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 0.9997, Acc: 0.9951\n",
            "   Runtime: 151.93s\n",
            "\n",
            "============================================================\n",
            " Iteration 6/10\n",
            "Params: Epochs=10, LR=4e-05, Batch=16, GradAccum=1\n",
            "============================================================\n",
            " Loading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [630/630 03:08, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.851900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Iteration 6 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 1.0000, Acc: 0.9975\n",
            "   Runtime: 189.31s\n",
            "\n",
            "============================================================\n",
            " Iteration 7/10\n",
            "Params: Epochs=10, LR=7e-05, Batch=8, GradAccum=6\n",
            "============================================================\n",
            " Loading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [210/210 03:06, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Iteration 7 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 0.9999, Acc: 0.9951\n",
            "   Runtime: 187.99s\n",
            "\n",
            "============================================================\n",
            " Iteration 8/10\n",
            "Params: Epochs=12, LR=3.5e-05, Batch=12, GradAccum=1\n",
            "============================================================\n",
            " Loading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='996' max='996' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [996/996 03:55, Epoch 12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.310300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Iteration 8 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 1.0000, Acc: 0.9975\n",
            "   Runtime: 236.19s\n",
            "\n",
            "============================================================\n",
            " Iteration 9/10\n",
            "Params: Epochs=12, LR=3e-05, Batch=16, GradAccum=1\n",
            "============================================================\n",
            " Loading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='756' max='756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [756/756 03:47, Epoch 12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.083600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Iteration 9 complete!\n",
            "   Train - F1: 1.0000, Acc: 0.9987\n",
            "   Test  - F1: 0.9993, Acc: 0.9681\n",
            "   Runtime: 228.68s\n",
            "\n",
            "============================================================\n",
            " Iteration 10/10\n",
            "Params: Epochs=14, LR=5e-05, Batch=8, GradAccum=4\n",
            "============================================================\n",
            " Loading fresh model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='448' max='448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [448/448 04:27, Epoch 14/14]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Iteration 10 complete!\n",
            "   Train - F1: 1.0000, Acc: 0.9966\n",
            "   Test  - F1: 0.9950, Acc: 0.9044\n",
            "   Runtime: 268.47s\n",
            "\n",
            "============================================================\n",
            "FORMATTING EXCEL FILE\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 1) Environment setup (Colab)\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def pip_install(packages):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages)\n",
        "\n",
        "# Core ML stack\n",
        "pip_install([\n",
        "    \"transformers>=4.44.0\",\n",
        "    \"datasets>=2.14.0\",\n",
        "    \"accelerate>=0.26.0\",\n",
        "    \"evaluate>=0.4.0\",\n",
        "])\n",
        "\n",
        "# Colab-specific checks\n",
        "try:\n",
        "    import torch\n",
        "    import platform\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ENVIRONMENT\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Python: {sys.version.split()[0]} | Platform: {platform.platform()}\")\n",
        "    print(f\"PyTorch: {torch.__version__}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)} | CUDA: {torch.version.cuda}\")\n",
        "    else:\n",
        "        print(\"GPU not detected. Enable a GPU in Runtime > Change runtime type > T4/other.\")\n",
        "    print(\"=\" * 60)\n",
        "except Exception as e:\n",
        "    print(\"Environment check failed:\", e)\n",
        "\n",
        "# 2) Imports and GPU config\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import default_data_collator\n",
        "from datasets import Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"GPU CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Memory: {round(torch.cuda.get_device_properties(0).total_memory / 1024**3, 2)} GB\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available; training will be slower.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "USE_UPLOAD = not USE_DRIVE\n",
        "if USE_UPLOAD:\n",
        "    try:\n",
        "        from google.colab import files  # type: ignore\n",
        "        uploaded = files.upload()\n",
        "        # Pick the first uploaded file\n",
        "        if uploaded:\n",
        "            CSV_PATH = list(uploaded.keys())[0]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "if not CSV_PATH:\n",
        "\n",
        "    raise ValueError(\"provide CSV_PATH\")\n",
        "\n",
        "print(\"Dataset CSV:\", CSV_PATH)\n",
        "\n",
        "# 4) Load and split dataset\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LOADING CARDIOVASCULAR DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "dataset = pd.read_csv(CSV_PATH)\n",
        "print(f\"Total records: {len(dataset)}\")\n",
        "print(f\"Columns: {list(dataset.columns)}\")\n",
        "print(f\"Sample question: {str(dataset.iloc[0]['question'])[:80]}...\")\n",
        "print(f\"Sample answer chars: {len(str(dataset.iloc[0]['answer']))}\")\n",
        "\n",
        "# Drop nulls\n",
        "dataset = dataset.dropna(subset=[\"question\", \"answer\"]).reset_index(drop=True)\n",
        "\n",
        "# Train/test split (80/20)\n",
        "dataset_shuffled = dataset.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "split_idx = int(len(dataset_shuffled) * 0.80)\n",
        "train_data = dataset_shuffled.iloc[:split_idx].copy()\n",
        "test_data = dataset_shuffled.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"Train: {len(train_data)} | Test: {len(test_data)}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 5) Model and tokenizer\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LOADING MODEL AND TOKENIZER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "MODEL_NAME = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "print(\"Model:\", MODEL_NAME)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "model.to(device)\n",
        "\n",
        "print(\"Model loaded.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "# 6) Tokenization and label prep (extractive QA)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TOKENIZING DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_data)\n",
        "test_ds = Dataset.from_pandas(test_data)\n",
        "\n",
        "MAX_LENGTH = 384\n",
        "DOC_STRIDE = 128\n",
        "\n",
        "def prepare_train_features(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"answer\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=MAX_LENGTH,\n",
        "        stride=DOC_STRIDE,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(tokenized[\"offset_mapping\"]):\n",
        "        sequence_ids = tokenized.sequence_ids(i)\n",
        "\n",
        "        context_start = None\n",
        "        context_end = None\n",
        "        for idx, seq_id in enumerate(sequence_ids):\n",
        "            if seq_id == 1:\n",
        "                if context_start is None:\n",
        "                    context_start = idx\n",
        "                context_end = idx\n",
        "\n",
        "        if context_start is None:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            answer_start = context_start\n",
        "            answer_end = min(context_start + 50, context_end)\n",
        "            start_positions.append(answer_start)\n",
        "            end_positions.append(answer_end)\n",
        "\n",
        "    tokenized[\"start_positions\"] = start_positions\n",
        "    tokenized[\"end_positions\"] = end_positions\n",
        "\n",
        "    # Drop offset_mapping so it isn't fed to the model\n",
        "    if \"offset_mapping\" in tokenized:\n",
        "        tokenized.pop(\"offset_mapping\")\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "print(\"Tokenizing train...\")\n",
        "tokenized_train = train_ds.map(\n",
        "    prepare_train_features,\n",
        "    batched=True,\n",
        "    remove_columns=train_ds.column_names,\n",
        "    desc=\"Tokenizing train\",\n",
        ")\n",
        "\n",
        "print(\"Tokenizing test...\")\n",
        "tokenized_test = test_ds.map(\n",
        "    prepare_train_features,\n",
        "    batched=True,\n",
        "    remove_columns=test_ds.column_names,\n",
        "    desc=\"Tokenizing test\",\n",
        ")\n",
        "\n",
        "print(\"Done.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 7) Evaluation Metrics - Modular Helper Functions\n",
        "import numpy as np\n",
        "\n",
        "def calculate_detailed_metrics(predictions):\n",
        "    \"\"\"\n",
        "    Calculate accuracy, F1, precision, and recall from model predictions.\n",
        "    This function processes predictions in a single pass for efficiency.\n",
        "    \"\"\"\n",
        "    pred_starts = np.argmax(predictions.predictions[0], axis=1)\n",
        "    pred_ends = np.argmax(predictions.predictions[1], axis=1)\n",
        "\n",
        "    true_starts = np.asarray(predictions.label_ids[0]).reshape(-1)\n",
        "    true_ends = np.asarray(predictions.label_ids[1]).reshape(-1)\n",
        "\n",
        "    # Calculate exact match and accuracy metrics\n",
        "    exact_match = np.mean((pred_starts == true_starts) & (pred_ends == true_ends))\n",
        "    start_accuracy = np.mean(pred_starts == true_starts)\n",
        "    end_accuracy = np.mean(pred_ends == true_ends)\n",
        "    accuracy = (exact_match + start_accuracy + end_accuracy) / 3\n",
        "\n",
        "    # Calculate F1, precision, and recall from token overlap\n",
        "    f1_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "\n",
        "    for ps, pe, ts, te in zip(pred_starts, pred_ends, true_starts, true_ends):\n",
        "        ps, pe, ts, te = int(ps), int(pe), int(ts), int(te)\n",
        "        pred_tokens = set(range(ps, pe + 1))\n",
        "        true_tokens = set(range(ts, te + 1))\n",
        "\n",
        "        if not pred_tokens and not true_tokens:\n",
        "            f1_scores.append(1.0)\n",
        "            precision_scores.append(1.0)\n",
        "            recall_scores.append(1.0)\n",
        "        elif not pred_tokens or not true_tokens:\n",
        "            f1_scores.append(0.0)\n",
        "            precision_scores.append(0.0)\n",
        "            recall_scores.append(0.0)\n",
        "        else:\n",
        "            common = len(pred_tokens & true_tokens)\n",
        "            if common == 0:\n",
        "                f1_scores.append(0.0)\n",
        "                precision_scores.append(0.0)\n",
        "                recall_scores.append(0.0)\n",
        "            else:\n",
        "                precision = common / len(pred_tokens)\n",
        "                recall = common / len(true_tokens)\n",
        "                f1 = 2 * (precision * recall) / (precision + recall)\n",
        "                f1_scores.append(f1)\n",
        "                precision_scores.append(precision)\n",
        "                recall_scores.append(recall)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": float(accuracy),\n",
        "        \"f1\": float(np.mean(f1_scores)) if f1_scores else 0.0,\n",
        "        \"precision\": float(np.mean(precision_scores)) if precision_scores else 0.0,\n",
        "        \"recall\": float(np.mean(recall_scores)) if recall_scores else 0.0,\n",
        "    }\n",
        "\n",
        "def evaluate_dataset(trainer, tokenized_data, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate model on a given dataset and return all metrics.\n",
        "    Makes a single prediction call for efficiency.\n",
        "    \"\"\"\n",
        "    predictions = trainer.predict(tokenized_data)\n",
        "    metrics = calculate_detailed_metrics(predictions)\n",
        "    return metrics\n",
        "\n",
        "def compute_qa_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Compute metrics for Trainer's evaluation during training.\n",
        "    Kept for compatibility with Trainer API.\n",
        "    \"\"\"\n",
        "    predictions, label_ids = eval_pred\n",
        "    start_logits, end_logits = predictions\n",
        "\n",
        "    pred_starts = np.argmax(start_logits, axis=1)\n",
        "    pred_ends = np.argmax(end_logits, axis=1)\n",
        "\n",
        "    true_starts = np.asarray(label_ids[0]).reshape(-1)\n",
        "    true_ends = np.asarray(label_ids[1]).reshape(-1)\n",
        "\n",
        "    exact_match = np.mean((pred_starts == true_starts) & (pred_ends == true_ends))\n",
        "    start_accuracy = np.mean(pred_starts == true_starts)\n",
        "    end_accuracy = np.mean(pred_ends == true_ends)\n",
        "\n",
        "    f1_scores = []\n",
        "    for ps, pe, ts, te in zip(pred_starts, pred_ends, true_starts, true_ends):\n",
        "        ps, pe, ts, te = int(ps), int(pe), int(ts), int(te)\n",
        "        pred_tokens = set(range(ps, pe + 1))\n",
        "        true_tokens = set(range(ts, te + 1))\n",
        "        if not pred_tokens and not true_tokens:\n",
        "            f1_scores.append(1.0)\n",
        "        elif not pred_tokens or not true_tokens:\n",
        "            f1_scores.append(0.0)\n",
        "        else:\n",
        "            common = len(pred_tokens & true_tokens)\n",
        "            if common == 0:\n",
        "                f1_scores.append(0.0)\n",
        "            else:\n",
        "                precision = common / len(pred_tokens)\n",
        "                recall = common / len(true_tokens)\n",
        "                f1_scores.append(2 * (precision * recall) / (precision + recall))\n",
        "\n",
        "    return {\n",
        "        \"exact_match\": float(exact_match),\n",
        "        \"start_accuracy\": float(start_accuracy),\n",
        "        \"end_accuracy\": float(end_accuracy),\n",
        "        \"f1\": float(np.mean(f1_scores)) if f1_scores else 0.0,\n",
        "    }\n",
        "\n",
        "print(\"Metrics functions ready.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 8) Training configuration (Colab-friendly)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_cardio_qa\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=0.00003,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    max_grad_norm=1.0,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_pin_memory=True,\n",
        "    dataloader_num_workers=0,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    logging_dir=\"./logs_cardio_qa\",\n",
        "    logging_steps=50,\n",
        "    logging_strategy=\"steps\",\n",
        "    report_to=[],\n",
        "    seed=42,\n",
        "    disable_tqdm=False,\n",
        "    remove_unused_columns=True,\n",
        ")\n",
        "\n",
        "print(\"Configured. FP16:\", training_args.fp16)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 9) Initialize Trainer\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"INITIALIZING TRAINER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        "    compute_metrics=compute_qa_metrics,\n",
        ")\n",
        "\n",
        "print(\"Trainer ready.\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 10) Hyperparameter Tuning with Train-Test Metrics\n",
        "import time\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, Alignment\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"HYPERPARAMETER TUNING (10 CONFIGURATIONS)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Define hyperparameter configurations (T4 GPU optimized for cardiovascular dataset)\n",
        "# Avoiding: grad_accum=2, warmup=0.1, weight_decay=0.01\n",
        "hyperparam_sets = [\n",
        "    {\"epochs\": 5,  \"lr\": 0.00004,  \"batch\": 16, \"grad_accum\": 1, \"warmup\": 0.07, \"weight_decay\": 0.008},\n",
        "    {\"epochs\": 6,  \"lr\": 0.00005,  \"batch\": 16, \"grad_accum\": 1, \"warmup\": 0.09, \"weight_decay\": 0.015},\n",
        "    {\"epochs\": 6,  \"lr\": 0.000035, \"batch\": 12, \"grad_accum\": 1, \"warmup\": 0.12, \"weight_decay\": 0.018},\n",
        "    {\"epochs\": 8,  \"lr\": 0.00006,  \"batch\": 8,  \"grad_accum\": 4, \"warmup\": 0.15, \"weight_decay\": 0.006},\n",
        "    {\"epochs\": 8,  \"lr\": 0.000045, \"batch\": 16, \"grad_accum\": 1, \"warmup\": 0.18, \"weight_decay\": 0.012},\n",
        "    {\"epochs\": 10, \"lr\": 0.00004,  \"batch\": 16, \"grad_accum\": 1, \"warmup\": 0.06, \"weight_decay\": 0.022},\n",
        "    {\"epochs\": 10, \"lr\": 0.00007,  \"batch\": 8,  \"grad_accum\": 6, \"warmup\": 0.12, \"weight_decay\": 0.007},\n",
        "    {\"epochs\": 12, \"lr\": 0.000035, \"batch\": 12, \"grad_accum\": 1, \"warmup\": 0.15, \"weight_decay\": 0.016},\n",
        "    {\"epochs\": 12, \"lr\": 0.00003,  \"batch\": 16, \"grad_accum\": 1, \"warmup\": 0.08, \"weight_decay\": 0.02},\n",
        "    {\"epochs\": 14, \"lr\": 0.00005,  \"batch\": 8,  \"grad_accum\": 4, \"warmup\": 0.18, \"weight_decay\": 0.009},\n",
        "]\n",
        "\n",
        "total_iters = len(hyperparam_sets)\n",
        "\n",
        "# Excel setup with gradient accumulation column\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"QA Hyperparameter Results\"\n",
        "ws.append([\n",
        "    \"Iteration\", \"Epochs\", \"Learning Rate\", \"Batch Size\", \"Grad Accum\", \"Warmup Ratio\", \"Weight Decay\",\n",
        "    \"Train-Accuracy\", \"Test-Accuracy\",\n",
        "    \"Train-F1\", \"Test-F1\",\n",
        "    \"Train-Precision\", \"Test-Precision\",\n",
        "    \"Train-Recall\", \"Test-Recall\",\n",
        "    \"Runtime (s)\"\n",
        "])\n",
        "\n",
        "# Main hyperparameter tuning loop\n",
        "for i, params in enumerate(hyperparam_sets, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\" Iteration {i}/{total_iters}\")\n",
        "    print(f\"Params: Epochs={params['epochs']}, LR={params['lr']}, Batch={params['batch']}, GradAccum={params['grad_accum']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Reload fresh model for each iteration\n",
        "    print(\" Loading fresh model...\")\n",
        "    model_fresh = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "    model_fresh.to(device)\n",
        "\n",
        "    # Configure training arguments (T4 optimized)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_run_{i}\",\n",
        "        num_train_epochs=params[\"epochs\"],\n",
        "        per_device_train_batch_size=params[\"batch\"],\n",
        "        per_device_eval_batch_size=params[\"batch\"],\n",
        "        gradient_accumulation_steps=params[\"grad_accum\"],\n",
        "        learning_rate=params[\"lr\"],\n",
        "        warmup_ratio=params[\"warmup\"],\n",
        "        weight_decay=params[\"weight_decay\"],\n",
        "        eval_strategy=\"no\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_dir=f\"./logs_run_{i}\",\n",
        "        report_to=[],\n",
        "        disable_tqdm=False,\n",
        "        seed=42,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        dataloader_num_workers=0,  # T4 optimization (limited CPU cores)\n",
        "        dataloader_pin_memory=True,\n",
        "    )\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = Trainer(\n",
        "        model=model_fresh,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_test,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    print(\" Training...\")\n",
        "    start_time = time.time()\n",
        "    trainer.train()\n",
        "    runtime = round(time.time() - start_time, 2)\n",
        "\n",
        "    # Evaluate on BOTH train and test sets\n",
        "    print(\" Evaluating on training set...\")\n",
        "    train_metrics = evaluate_dataset(trainer, tokenized_train, \"TRAIN\")\n",
        "\n",
        "    print(\" Evaluating on test set...\")\n",
        "    test_metrics = evaluate_dataset(trainer, tokenized_test, \"TEST\")\n",
        "\n",
        "    # Append results to Excel\n",
        "    ws.append([\n",
        "        i,\n",
        "        params[\"epochs\"],\n",
        "        params[\"lr\"],\n",
        "        params[\"batch\"],\n",
        "        params[\"grad_accum\"],\n",
        "        params[\"warmup\"],\n",
        "        params[\"weight_decay\"],\n",
        "        round(train_metrics[\"accuracy\"], 4),\n",
        "        round(test_metrics[\"accuracy\"], 4),\n",
        "        round(train_metrics[\"f1\"], 4),\n",
        "        round(test_metrics[\"f1\"], 4),\n",
        "        round(train_metrics[\"precision\"], 4),\n",
        "        round(test_metrics[\"precision\"], 4),\n",
        "        round(train_metrics[\"recall\"], 4),\n",
        "        round(test_metrics[\"recall\"], 4),\n",
        "        runtime\n",
        "    ])\n",
        "\n",
        "    print(f\"✅ Iteration {i} complete!\")\n",
        "    print(f\"   Train - F1: {train_metrics['f1']:.4f}, Acc: {train_metrics['accuracy']:.4f}\")\n",
        "    print(f\"   Test  - F1: {test_metrics['f1']:.4f}, Acc: {test_metrics['accuracy']:.4f}\")\n",
        "    print(f\"   Runtime: {runtime}s\")\n",
        "    del model_fresh, trainer\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FORMATTING EXCEL FILE\")\n",
        "print(\"=\" * 60)\n",
        "for cell in ws[1]:\n",
        "    cell.font = Font(bold=True)\n",
        "    cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
        "for col in ws.columns:\n",
        "    max_length = 0\n",
        "    col_letter = col[0].column_letter\n",
        "    for cell in col:\n",
        "        try:\n",
        "            if len(str(cell.value)) > max_length:\n",
        "                max_length = len(str(cell.value))\n",
        "        except:\n",
        "            pass\n",
        "    adjusted_width = min((max_length + 2), 20)\n",
        "    ws.column_dimensions[col_letter].width = adjusted_width\n",
        "\n",
        "# Save Excel file\n",
        "output_excel = \"/content/Salameda_QA_Hyperparameter_Results_TrainTest.xlsx\"\n",
        "wb.save(output_excel)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12467de2c7ae4224856a94676be020fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bee7a50cdd37482faffe0acc43057a65",
              "IPY_MODEL_c48c68feee7a4e2781cefe8337089d93",
              "IPY_MODEL_43b47879b6bd4d67aa7f7dbaf04f826b"
            ],
            "layout": "IPY_MODEL_caefe684428c46d89d9a185bc05bc6f9"
          }
        },
        "bee7a50cdd37482faffe0acc43057a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26fc5b95833a4df89ca7f64a03c6f6ec",
            "placeholder": "​",
            "style": "IPY_MODEL_430dd36a066247a9a6e104923bdd82d9",
            "value": "Tokenizing train: 100%"
          }
        },
        "c48c68feee7a4e2781cefe8337089d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a51f021c93194e0cba577341b61978e0",
            "max": 523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a617d636c3c74f36821cd7eb6e80e1ff",
            "value": 523
          }
        },
        "43b47879b6bd4d67aa7f7dbaf04f826b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79350f588f914e729b55f6b84ed386b0",
            "placeholder": "​",
            "style": "IPY_MODEL_2f237564307346e7b1b49d215290cc3e",
            "value": " 523/523 [00:03&lt;00:00, 150.22 examples/s]"
          }
        },
        "caefe684428c46d89d9a185bc05bc6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26fc5b95833a4df89ca7f64a03c6f6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "430dd36a066247a9a6e104923bdd82d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a51f021c93194e0cba577341b61978e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a617d636c3c74f36821cd7eb6e80e1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79350f588f914e729b55f6b84ed386b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f237564307346e7b1b49d215290cc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "868846bf93c24afa8297c688b4d9b9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5540c8c1840b4b2db2e3dc8ac28707c0",
              "IPY_MODEL_b6015afe49734f5895b0def3b163fb55",
              "IPY_MODEL_2c894981f85647198d3371861d9a425a"
            ],
            "layout": "IPY_MODEL_8bdd0783deae422ca0a5f4ae403bb12b"
          }
        },
        "5540c8c1840b4b2db2e3dc8ac28707c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bc035553b284c69a58af021479c75cb",
            "placeholder": "​",
            "style": "IPY_MODEL_17d5a914a376476ba970aa5f0772360a",
            "value": "Tokenizing test: 100%"
          }
        },
        "b6015afe49734f5895b0def3b163fb55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9ae8a417155454abca11019893a65bc",
            "max": 131,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b2e8d1b99c7401ba109b0d00af8ffe7",
            "value": 131
          }
        },
        "2c894981f85647198d3371861d9a425a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b91115dcf8ea45afbe872cf1da920117",
            "placeholder": "​",
            "style": "IPY_MODEL_357007e0240241d685d0ed12dbd31aa9",
            "value": " 131/131 [00:00&lt;00:00, 184.36 examples/s]"
          }
        },
        "8bdd0783deae422ca0a5f4ae403bb12b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bc035553b284c69a58af021479c75cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d5a914a376476ba970aa5f0772360a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9ae8a417155454abca11019893a65bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2e8d1b99c7401ba109b0d00af8ffe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b91115dcf8ea45afbe872cf1da920117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "357007e0240241d685d0ed12dbd31aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}