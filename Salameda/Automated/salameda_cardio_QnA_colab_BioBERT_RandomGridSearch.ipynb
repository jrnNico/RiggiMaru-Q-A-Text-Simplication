{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a64fd32d",
      "metadata": {
        "id": "a64fd32d"
      },
      "source": [
        "# Cardiovascular Medical QA Fine-Tuning (BioBERT) - Random Grid Search\n",
        "\n",
        "This notebook fine-tunes a medical BERT QA model on cardiovascular Q&A data using Random Grid Search for hyperparameter optimization on a Colab GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba0e581a",
      "metadata": {
        "id": "ba0e581a"
      },
      "source": [
        "### 1. Environment Setup and Configuration\n",
        "\n",
        "This section prepares the computational environment for fine-tuning the cardiovascular QA model. The setup process begins by defining a utility function to install essential Python packages using pip, including the Transformers library (version 4.44.0 or higher) for working with pre-trained models, Datasets for efficient data handling, Accelerate for optimized training, and Evaluate for model performance metrics. After installing these core dependencies, the code performs comprehensive environment checks to verify the Python version, platform details, and PyTorch installation. Most importantly, it detects whether a GPU is available for training and displays relevant information such as the GPU model name and CUDA version. If no GPU is detected, the system alerts the user to enable GPU acceleration in Google Colab's runtime settings, as GPU support is crucial for efficient training of transformer models. This initial setup ensures that all necessary dependencies are in place and that the hardware configuration is optimal for the computationally intensive task of fine-tuning a BERT-based question answering model on medical data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a8c0cdfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8c0cdfb",
        "outputId": "bbb7cdf1-add7-4a77-9b57-637b27d483e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ENVIRONMENT\n",
            "============================================================\n",
            "Python: 3.12.12 | Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "PyTorch: 2.8.0+cu126\n",
            "GPU: Tesla T4 | CUDA: 12.6\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 1) Environment setup (Colab)\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def pip_install(packages):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages)\n",
        "\n",
        "# Core ML stack\n",
        "pip_install([\n",
        "    \"transformers>=4.44.0\",\n",
        "    \"datasets>=2.14.0\",\n",
        "    \"accelerate>=0.26.0\",\n",
        "    \"evaluate>=0.4.0\",\n",
        "])\n",
        "\n",
        "# Colab-specific checks\n",
        "try:\n",
        "    import torch\n",
        "    import platform\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ENVIRONMENT\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Python: {sys.version.split()[0]} | Platform: {platform.platform()}\")\n",
        "    print(f\"PyTorch: {torch.__version__}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)} | CUDA: {torch.version.cuda}\")\n",
        "    else:\n",
        "        print(\"GPU not detected. Enable a GPU in Runtime > Change runtime type > T4/other.\")\n",
        "    print(\"=\" * 60)\n",
        "except Exception as e:\n",
        "    print(\"Environment check failed:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OpzvQAmdCe1j",
      "metadata": {
        "id": "OpzvQAmdCe1j"
      },
      "source": [
        "### 2. Imports and GPU Configuration\n",
        "\n",
        "Following the initial setup, the code imports all necessary libraries for the machine learning pipeline, including PyTorch for deep learning operations, NumPy for numerical computations, Pandas for data manipulation, and specific modules from the Transformers library such as AutoTokenizer and AutoModelForQuestionAnswering for handling pre-trained models. The code also imports training utilities like TrainingArguments, Trainer, and default_data_collator to streamline the fine-tuning process, along with the Datasets library for efficient data handling. Warning messages are suppressed to keep the output clean. The GPU configuration section then performs a detailed check to determine if CUDA-enabled GPU hardware is available. If a GPU is detected, the code creates a CUDA device object and displays comprehensive information including the GPU model name, CUDA version, and total available GPU memory in gigabytes. This information is critical for understanding the computational resources available and for optimizing batch sizes and memory usage during training. If no GPU is found, the system falls back to CPU mode and warns the user that training will be significantly slower, emphasizing the importance of GPU acceleration for transformer model fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "053bba90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "053bba90",
        "outputId": "c9396b6c-b9e7-4273-f33c-173eb368ba06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "GPU CONFIGURATION\n",
            "============================================================\n",
            "GPU Available: Tesla T4\n",
            "CUDA Version: 12.6\n",
            "GPU Memory: 14.74 GB\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 2) Imports and GPU config\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import default_data_collator\n",
        "from datasets import Dataset\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, Alignment\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"GPU CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Memory: {round(torch.cuda.get_device_properties(0).total_memory / 1024**3, 2)} GB\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available; training will be slower.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4GqEh--dCfXK",
      "metadata": {
        "id": "4GqEh--dCfXK"
      },
      "source": [
        "### 3. Dataset Loading Options\n",
        "\n",
        "This section provides flexible options for loading the cardiovascular QA dataset in Google Colab. User can directly upload a file from their local machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d155eaed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "d155eaed",
        "outputId": "2e7a4d05-b181-47d9-ade6-1ab86b4db663"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4e013e92-6ebd-45c1-bce4-6f8f78190951\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4e013e92-6ebd-45c1-bce4-6f8f78190951\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving medquadCardiovascular.csv to medquadCardiovascular (1).csv\n",
            "Dataset CSV: medquadCardiovascular (1).csv\n"
          ]
        }
      ],
      "source": [
        "# 3) Dataset loading (Cardiovascular Q&A)\n",
        "USE_DRIVE = False\n",
        "USE_UPLOAD = not USE_DRIVE\n",
        "if USE_UPLOAD:\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            CSV_PATH = list(uploaded.keys())[0]\n",
        "    except Exception:\n",
        "        pass\n",
        "if not CSV_PATH:\n",
        "    raise ValueError(\"Please provide CSV_PATH via Drive or upload.\")\n",
        "\n",
        "print(\"Dataset CSV:\", CSV_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AYMUGkYKCfrx",
      "metadata": {
        "id": "AYMUGkYKCfrx"
      },
      "source": [
        "### 4. Data Loading and Preprocessing\n",
        "\n",
        "Once the dataset path is established, this section loads the cardiovascular medical QA data from the CSV file using Pandas and performs essential preprocessing steps. The code first reads the CSV and displays diagnostic information including the total number of records, column names, a sample question preview, and the character length of a sample answer to give users insight into the dataset structure and content. To ensure data quality, the code removes any rows containing null values in the critical question or answer columns, preventing training issues from incomplete data. The dataset is then randomly shuffled with a fixed random seed for reproducibility and split into training and test sets using an 80/20 ratio, which provides substantial training data while reserving enough examples for unbiased testing. The training set will be used to update the model weights, while the test set allows for evaluation of model performance after training. This preprocessing ensures clean, well-organized data that's ready for the tokenization and model training phases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4354672b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4354672b",
        "outputId": "680a4573-d94b-4ab3-9b2f-5fffb7615dba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "LOADING CARDIOVASCULAR DATASET\n",
            "============================================================\n",
            "Total records: 654\n",
            "Columns: ['question', 'answer', 'source', 'focus_area']\n",
            "Sample question: What is (are) High Blood Pressure ?...\n",
            "Sample answer chars: 5586\n",
            "Train: 523 | Test: 131\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 4) Load and split dataset\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LOADING CARDIOVASCULAR DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "dataset = pd.read_csv(CSV_PATH)\n",
        "print(f\"Total records: {len(dataset)}\")\n",
        "print(f\"Columns: {list(dataset.columns)}\")\n",
        "print(f\"Sample question: {str(dataset.iloc[0]['question'])[:80]}...\")\n",
        "print(f\"Sample answer chars: {len(str(dataset.iloc[0]['answer']))}\")\n",
        "\n",
        "# Drop nulls\n",
        "dataset = dataset.dropna(subset=[\"question\", \"answer\"]).reset_index(drop=True)\n",
        "\n",
        "# Train/test split (80/20)\n",
        "dataset_shuffled = dataset.sample(frac=1.0, random_state=None).reset_index(drop=True)\n",
        "split_idx = int(len(dataset_shuffled) * 0.80)\n",
        "train_data = dataset_shuffled.iloc[:split_idx].copy()\n",
        "test_data = dataset_shuffled.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"Train: {len(train_data)} | Test: {len(test_data)}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ow4Lnsi6CgH1",
      "metadata": {
        "id": "Ow4Lnsi6CgH1"
      },
      "source": [
        "### 5. Model and Tokenizer Initialization\n",
        "\n",
        "This section initializes the pre-trained BioBERT model specifically designed for biomedical text processing. The code loads the \"dmis-lab/biobert-base-cased-v1.1\" model from the Hugging Face model hub, which is a BERT variant pre-trained on large-scale biomedical literature including PubMed abstracts and PMC full-text articles. This specialized pre-training gives BioBERT a strong foundation in medical terminology and biomedical language patterns. Both the tokenizer and the model are loaded using the Auto classes from the Transformers library, which automatically handle the correct architecture and configuration. The tokenizer is initialized with the fast tokenizer option enabled for improved performance during text processing. Once loaded, the model is transferred to the appropriate device (GPU if available, otherwise CPU) to ensure all subsequent operations leverage the available hardware acceleration. Using BioBERT as the base model provides significant advantages for medical question answering tasks, as it already understands medical concepts and terminology, requiring less fine-tuning data and time compared to general-purpose language models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9a44ec06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a44ec06",
        "outputId": "b3ab3557-770a-4f7e-ec02-d1a4e1f957f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "LOADING MODEL AND TOKENIZER\n",
            "============================================================\n",
            "Model: dmis-lab/biobert-base-cased-v1.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 5) Model and tokenizer\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LOADING MODEL AND TOKENIZER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "MODEL_NAME = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "print(\"Model:\", MODEL_NAME)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "model.to(device)\n",
        "\n",
        "print(\"Model loaded.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kJIAnpvkCgun",
      "metadata": {
        "id": "kJIAnpvkCgun"
      },
      "source": [
        "### 6. Tokenization and Feature Preparation\n",
        "\n",
        "This critical section transforms the raw text data into numerical representations that the model can process, while also preparing the labels for extractive question answering. The code converts the Pandas dataframes into Hugging Face Dataset objects for efficient processing, then defines key parameters including maximum sequence length (384 tokens) and document stride (128 tokens) for handling long contexts. The prepare_train_features function tokenizes both questions and answers together, truncating only the answer portion if necessary to fit within the maximum length constraint. For extractive QA, the model needs to predict the start and end positions of the answer span within the tokenized context. The code implements logic to identify which tokens belong to the context (sequence_id == 1) versus the question, then sets start and end position labels accordingly. If no valid context exists, both positions are set to 0 as a fallback. The function also handles overflowing tokens by creating multiple training examples from long contexts and removes the offset_mapping data structure before returning, as it's only needed during preprocessing. This tokenization process is applied to both training and validation datasets in batched mode for efficiency, preparing the data in the exact format required by the question answering model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7df5f186",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "5140abad789a4cfdbe30aaba9cbd4d6d",
            "0be5f4046c0144a394679b087fcfd41e",
            "4fed344f283d493c837248f929e00aa7",
            "1976ad7c6d8d4acca2a1657b37d282f2",
            "b3dfda737f174d8c82d531ea97a717fd",
            "b064e44b0a4041c5a20ab534f8315216",
            "f2b47aa67d6f48fcb35a8ce6dc501b73",
            "856eb12b9f0047ae85e73489baf46f57",
            "4364b8d374a3431e814406a703a6e91b",
            "870f9efe3a024801bf384d120adfb30e",
            "51a2dc39700b46139ac11486181b5952",
            "a346b49ebe92462d96536624335de3b9",
            "dc0400c9ffdf4f2ab0b7eb0f74a44055",
            "e3072e0033184e8096523effac5a63e2",
            "c48ccfc926384cad8129b2454832ca51",
            "b40eda8f620147f7b20b136724c4846f",
            "91f543a1f8754d19acbc6492b95282f3",
            "ba90b9f2f4774f7c9e9374a7eda698fc",
            "1158b05dddb8425cb19077308d8b59f3",
            "20740c061daf4120bdf47aa8ea2ee074",
            "0f7733f1e0004283ae2995de9688b129",
            "f5ef1065b7b64cf1bd328e93ace394d6"
          ]
        },
        "id": "7df5f186",
        "outputId": "612915cc-e8e8-4ad5-f55b-e5157efafc3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TOKENIZING DATASET\n",
            "============================================================\n",
            "Tokenizing train...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5140abad789a4cfdbe30aaba9cbd4d6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train:   0%|          | 0/523 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing test...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a346b49ebe92462d96536624335de3b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing test:   0%|          | 0/131 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 6) Tokenization and label prep (extractive QA)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TOKENIZING DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_data)\n",
        "test_ds = Dataset.from_pandas(test_data)\n",
        "\n",
        "MAX_LENGTH = 384\n",
        "DOC_STRIDE = 128\n",
        "\n",
        "def prepare_train_features(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"answer\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=MAX_LENGTH,\n",
        "        stride=DOC_STRIDE,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(tokenized[\"offset_mapping\"]):\n",
        "        sequence_ids = tokenized.sequence_ids(i)\n",
        "\n",
        "        context_start = None\n",
        "        context_end = None\n",
        "        for idx, seq_id in enumerate(sequence_ids):\n",
        "            if seq_id == 1:\n",
        "                if context_start is None:\n",
        "                    context_start = idx\n",
        "                context_end = idx\n",
        "\n",
        "        if context_start is None:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            answer_start = context_start\n",
        "            answer_end = min(context_start + 50, context_end)\n",
        "            start_positions.append(answer_start)\n",
        "            end_positions.append(answer_end)\n",
        "\n",
        "    tokenized[\"start_positions\"] = start_positions\n",
        "    tokenized[\"end_positions\"] = end_positions\n",
        "\n",
        "    # Drop offset_mapping so it isn't fed to the model\n",
        "    if \"offset_mapping\" in tokenized:\n",
        "        tokenized.pop(\"offset_mapping\")\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "print(\"Tokenizing train...\")\n",
        "tokenized_train = train_ds.map(\n",
        "    prepare_train_features,\n",
        "    batched=True,\n",
        "    remove_columns=train_ds.column_names,\n",
        "    desc=\"Tokenizing train\",\n",
        ")\n",
        "\n",
        "print(\"Tokenizing test...\")\n",
        "tokenized_test = test_ds.map(\n",
        "    prepare_train_features,\n",
        "    batched=True,\n",
        "    remove_columns=test_ds.column_names,\n",
        "    desc=\"Tokenizing test\",\n",
        ")\n",
        "\n",
        "print(\"Done.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LsOAji1fChms",
      "metadata": {
        "id": "LsOAji1fChms"
      },
      "source": [
        "\n",
        "### 7. Evaluation Metrics Definition\n",
        "\n",
        "This section defines modular helper functions for calculating comprehensive evaluation metrics specifically designed for question answering tasks. The calculate_detailed_metrics function processes model predictions in a single efficient pass, extracting start and end logits and converting them to predicted token positions. It calculates four key metrics: accuracy (average of exact match, start accuracy, and end accuracy), token-level F1 score, precision, and recall. The F1 calculation treats predicted and actual answer spans as sets of token positions and computes precision and recall based on their overlap, handling special cases appropriately. The evaluate_dataset function wraps the prediction and metric calculation process for easy evaluation of any dataset, making a single prediction call for efficiency. An additional compute_qa_metrics function is maintained for compatibility with the Hugging Face Trainer API during training. This modular structure eliminates code duplication and provides a clean interface for evaluating model performance on both training and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5c27f9c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c27f9c3",
        "outputId": "8a62d089-c52a-472d-c8f9-260014d571d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics functions ready.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 7) Evaluation Metrics - Modular Helper Functions\n",
        "import numpy as np\n",
        "\n",
        "def calculate_detailed_metrics(predictions):\n",
        "    \"\"\"\n",
        "    Calculate accuracy, F1, precision, and recall from model predictions.\n",
        "    This function processes predictions in a single pass for efficiency.\n",
        "    \"\"\"\n",
        "    pred_starts = np.argmax(predictions.predictions[0], axis=1)\n",
        "    pred_ends = np.argmax(predictions.predictions[1], axis=1)\n",
        "\n",
        "    true_starts = np.asarray(predictions.label_ids[0]).reshape(-1)\n",
        "    true_ends = np.asarray(predictions.label_ids[1]).reshape(-1)\n",
        "\n",
        "    # Calculate exact match and accuracy metrics\n",
        "    exact_match = np.mean((pred_starts == true_starts) & (pred_ends == true_ends))\n",
        "    start_accuracy = np.mean(pred_starts == true_starts)\n",
        "    end_accuracy = np.mean(pred_ends == true_ends)\n",
        "    accuracy = (exact_match + start_accuracy + end_accuracy) / 3\n",
        "\n",
        "    # Calculate F1, precision, and recall from token overlap\n",
        "    f1_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "\n",
        "    for ps, pe, ts, te in zip(pred_starts, pred_ends, true_starts, true_ends):\n",
        "        ps, pe, ts, te = int(ps), int(pe), int(ts), int(te)\n",
        "        pred_tokens = set(range(ps, pe + 1))\n",
        "        true_tokens = set(range(ts, te + 1))\n",
        "\n",
        "        if not pred_tokens and not true_tokens:\n",
        "            f1_scores.append(1.0)\n",
        "            precision_scores.append(1.0)\n",
        "            recall_scores.append(1.0)\n",
        "        elif not pred_tokens or not true_tokens:\n",
        "            f1_scores.append(0.0)\n",
        "            precision_scores.append(0.0)\n",
        "            recall_scores.append(0.0)\n",
        "        else:\n",
        "            common = len(pred_tokens & true_tokens)\n",
        "            if common == 0:\n",
        "                f1_scores.append(0.0)\n",
        "                precision_scores.append(0.0)\n",
        "                recall_scores.append(0.0)\n",
        "            else:\n",
        "                precision = common / len(pred_tokens)\n",
        "                recall = common / len(true_tokens)\n",
        "                f1 = 2 * (precision * recall) / (precision + recall)\n",
        "                f1_scores.append(f1)\n",
        "                precision_scores.append(precision)\n",
        "                recall_scores.append(recall)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": float(accuracy),\n",
        "        \"f1\": float(np.mean(f1_scores)) if f1_scores else 0.0,\n",
        "        \"precision\": float(np.mean(precision_scores)) if precision_scores else 0.0,\n",
        "        \"recall\": float(np.mean(recall_scores)) if recall_scores else 0.0,\n",
        "    }\n",
        "\n",
        "def evaluate_dataset(trainer, tokenized_data, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate model on a given dataset and return all metrics.\n",
        "    Makes a single prediction call for efficiency.\n",
        "    \"\"\"\n",
        "    predictions = trainer.predict(tokenized_data)\n",
        "    metrics = calculate_detailed_metrics(predictions)\n",
        "    return metrics\n",
        "\n",
        "print(\"Metrics functions ready.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eHAi6HmdCiOh",
      "metadata": {
        "id": "eHAi6HmdCiOh"
      },
      "source": [
        "### 8. Random Grid Search Hyperparameter Optimization\n",
        "\n",
        "This section implements a true random grid search approach for hyperparameter optimization, conducting 15 randomized experiments to identify optimal training settings for the cardiovascular QA task with BioBERT. Unlike manual hyperparameter tuning, this approach uses Python's random module to randomly sample hyperparameter combinations from predefined ranges at the start of each iteration. The hyperparameter search space includes epochs (5-15 for fast training on T4 GPU), learning rates (0.00002 to 0.00007), batch sizes (8, 12, or 16), gradient accumulation steps (1, 2, 4, or 6), warmup ratios (0.05 to 0.18), and weight decay values (0.005 to 0.025). For each of the 15 trials, the code randomly selects one value from each hyperparameter range, ensuring diversity in the search. A fresh copy of the pre-trained BioBERT model is reloaded for each trial to ensure fair comparison. The training loop is optimized for efficiency, using modular helper functions to evaluate performance on both training and test datasets. After training each configuration, the code makes single prediction calls for both datasets and calculates all four metrics (accuracy, F1, precision, recall) in one pass. Results are organized in an Excel workbook with side-by-side train-test columns for easy comparison of all metrics. This random sampling approach explores the hyperparameter space without bias, potentially discovering unexpected high-performing combinations that might be missed with manual selection. GPU cache is cleared between iterations to optimize memory usage for T4 GPU efficiency. The final Excel output includes all hyperparameter values formatted as real numbers (not scientific notation) for clarity and easy analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "92ef5c89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "92ef5c89",
        "outputId": "f9872065-8df4-4907-fbd1-c36c1e94479b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "RANDOM GRID SEARCH HYPERPARAMETER OPTIMIZATION\n",
            "15 TRIALS - T4 GPU OPTIMIZED\n",
            "============================================================\n",
            "Generating random hyperparameter configurations...\n",
            "Generated 15 random configurations\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TRIAL 1/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 15\n",
            "   Learning Rate: 0.000020\n",
            "   Batch Size: 8\n",
            "   Gradient Accumulation: 4\n",
            "   Warmup Ratio: 0.07\n",
            "   Weight Decay: 0.008\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 04:57, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>4.606100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.425500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.842100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.684800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.564900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.483300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.423000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.381500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 1 Complete!\n",
            "   Train - F1: 0.995361, Acc: 0.935614\n",
            "   Test  - F1: 0.983686, Acc: 0.642157\n",
            "   Runtime: 299.63s\n",
            "\n",
            "============================================================\n",
            "TRIAL 2/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 7\n",
            "   Learning Rate: 0.000070\n",
            "   Batch Size: 8\n",
            "   Gradient Accumulation: 1\n",
            "   Warmup Ratio: 0.12\n",
            "   Weight Decay: 0.015\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [875/875 02:26, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>4.856500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.546300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.297100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.108000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.601700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.119200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.038500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.029000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.008900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.004300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.009000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.014000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 2 Complete!\n",
            "   Train - F1: 1.000000, Acc: 1.000000\n",
            "   Test  - F1: 1.000000, Acc: 1.000000\n",
            "   Runtime: 146.65s\n",
            "\n",
            "============================================================\n",
            "TRIAL 3/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 5\n",
            "   Learning Rate: 0.000020\n",
            "   Batch Size: 8\n",
            "   Gradient Accumulation: 2\n",
            "   Warmup Ratio: 0.07\n",
            "   Weight Decay: 0.020\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [315/315 01:38, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>4.187900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.396200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.262800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.137700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.062600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.008100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 3 Complete!\n",
            "   Train - F1: 0.963253, Acc: 0.560698\n",
            "   Test  - F1: 0.957973, Acc: 0.448529\n",
            "   Runtime: 98.88s\n",
            "\n",
            "============================================================\n",
            "TRIAL 4/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 14\n",
            "   Learning Rate: 0.000020\n",
            "   Batch Size: 16\n",
            "   Gradient Accumulation: 2\n",
            "   Warmup Ratio: 0.15\n",
            "   Weight Decay: 0.025\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='448' max='448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [448/448 04:09, Epoch 14/14]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>5.027800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.620200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.086700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.784300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.636800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.564700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.409500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.365700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 4 Complete!\n",
            "   Train - F1: 0.990365, Acc: 0.956405\n",
            "   Test  - F1: 0.990105, Acc: 0.838235\n",
            "   Runtime: 250.58s\n",
            "\n",
            "============================================================\n",
            "TRIAL 5/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 13\n",
            "   Learning Rate: 0.000050\n",
            "   Batch Size: 8\n",
            "   Gradient Accumulation: 6\n",
            "   Warmup Ratio: 0.12\n",
            "   Weight Decay: 0.010\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [273/273 03:58, Epoch 13/13]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.022000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.574700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.346600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.172900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 5 Complete!\n",
            "   Train - F1: 0.999912, Acc: 0.994634\n",
            "   Test  - F1: 0.991304, Acc: 0.794118\n",
            "   Runtime: 239.83s\n",
            "\n",
            "============================================================\n",
            "TRIAL 6/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 5\n",
            "   Learning Rate: 0.000030\n",
            "   Batch Size: 16\n",
            "   Gradient Accumulation: 6\n",
            "   Warmup Ratio: 0.09\n",
            "   Weight Decay: 0.010\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 01:25, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.853100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 6 Complete!\n",
            "   Train - F1: 0.932217, Acc: 0.441985\n",
            "   Test  - F1: 0.935061, Acc: 0.421569\n",
            "   Runtime: 87.42s\n",
            "\n",
            "============================================================\n",
            "TRIAL 7/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 7\n",
            "   Learning Rate: 0.000030\n",
            "   Batch Size: 12\n",
            "   Gradient Accumulation: 1\n",
            "   Warmup Ratio: 0.05\n",
            "   Weight Decay: 0.015\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='581' max='581' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [581/581 02:15, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.991200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.416200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.216600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.894500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.697700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.495400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.437100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.336400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.235200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.250600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.158600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 7 Complete!\n",
            "   Train - F1: 0.996932, Acc: 0.994634\n",
            "   Test  - F1: 0.999387, Acc: 0.958333\n",
            "   Runtime: 136.42s\n",
            "\n",
            "============================================================\n",
            "TRIAL 8/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 6\n",
            "   Learning Rate: 0.000040\n",
            "   Batch Size: 12\n",
            "   Gradient Accumulation: 4\n",
            "   Warmup Ratio: 0.18\n",
            "   Weight Decay: 0.005\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [126/126 01:45, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.186700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.109700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 8 Complete!\n",
            "   Train - F1: 0.989741, Acc: 0.653253\n",
            "   Test  - F1: 0.986763, Acc: 0.517157\n",
            "   Runtime: 106.29s\n",
            "\n",
            "============================================================\n",
            "TRIAL 9/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 12\n",
            "   Learning Rate: 0.000060\n",
            "   Batch Size: 8\n",
            "   Gradient Accumulation: 6\n",
            "   Warmup Ratio: 0.05\n",
            "   Weight Decay: 0.020\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [252/252 03:39, Epoch 12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.631600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.859300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.481700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.322200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.220900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 9 Complete!\n",
            "   Train - F1: 0.998766, Acc: 0.985915\n",
            "   Test  - F1: 0.961077, Acc: 0.811275\n",
            "   Runtime: 220.57s\n",
            "\n",
            "============================================================\n",
            "TRIAL 10/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 9\n",
            "   Learning Rate: 0.000070\n",
            "   Batch Size: 16\n",
            "   Gradient Accumulation: 4\n",
            "   Warmup Ratio: 0.12\n",
            "   Weight Decay: 0.008\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [144/144 02:36, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.686100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.817700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 10 Complete!\n",
            "   Train - F1: 0.981705, Acc: 0.936955\n",
            "   Test  - F1: 0.967509, Acc: 0.593137\n",
            "   Runtime: 158.17s\n",
            "\n",
            "============================================================\n",
            "TRIAL 11/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 6\n",
            "   Learning Rate: 0.000020\n",
            "   Batch Size: 16\n",
            "   Gradient Accumulation: 2\n",
            "   Warmup Ratio: 0.18\n",
            "   Weight Decay: 0.010\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [192/192 01:46, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>4.460800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.423600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.168800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 11 Complete!\n",
            "   Train - F1: 0.962245, Acc: 0.527163\n",
            "   Test  - F1: 0.959196, Acc: 0.416667\n",
            "   Runtime: 107.94s\n",
            "\n",
            "============================================================\n",
            "TRIAL 12/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 6\n",
            "   Learning Rate: 0.000030\n",
            "   Batch Size: 8\n",
            "   Gradient Accumulation: 6\n",
            "   Warmup Ratio: 0.09\n",
            "   Weight Decay: 0.015\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [126/126 01:49, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.155500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.217200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 12 Complete!\n",
            "   Train - F1: 0.956658, Acc: 0.516432\n",
            "   Test  - F1: 0.948022, Acc: 0.446078\n",
            "   Runtime: 110.99s\n",
            "\n",
            "============================================================\n",
            "TRIAL 13/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 15\n",
            "   Learning Rate: 0.000040\n",
            "   Batch Size: 8\n",
            "   Gradient Accumulation: 4\n",
            "   Warmup Ratio: 0.09\n",
            "   Weight Decay: 0.008\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 04:39, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>4.005500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.182100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.860100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.659100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.439900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.363200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.216000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.174700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 13 Complete!\n",
            "   Train - F1: 0.999851, Acc: 0.990610\n",
            "   Test  - F1: 0.986164, Acc: 0.828431\n",
            "   Runtime: 280.64s\n",
            "\n",
            "============================================================\n",
            "TRIAL 14/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 15\n",
            "   Learning Rate: 0.000040\n",
            "   Batch Size: 16\n",
            "   Gradient Accumulation: 1\n",
            "   Warmup Ratio: 0.12\n",
            "   Weight Decay: 0.025\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [945/945 04:33, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>5.341900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.712500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.267300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.952400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.330700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.029900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.018800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.020100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.003600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.004900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 14 Complete!\n",
            "   Train - F1: 1.000000, Acc: 1.000000\n",
            "   Test  - F1: 1.000000, Acc: 1.000000\n",
            "   Runtime: 274.33s\n",
            "\n",
            "============================================================\n",
            "TRIAL 15/15 - Random Grid Search\n",
            "============================================================\n",
            "Sampled Parameters:\n",
            "   Epochs: 7\n",
            "   Learning Rate: 0.000060\n",
            "   Batch Size: 16\n",
            "   Gradient Accumulation: 2\n",
            "   Warmup Ratio: 0.07\n",
            "   Weight Decay: 0.015\n",
            "\n",
            "Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='224' max='224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [224/224 02:04, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.843600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.094800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.483700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.138900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial 15 Complete!\n",
            "   Train - F1: 0.998975, Acc: 0.998659\n",
            "   Test  - F1: 0.995931, Acc: 0.973039\n",
            "   Runtime: 125.28s\n",
            "\n",
            "============================================================\n",
            "FORMATTING EXCEL FILE\n",
            "============================================================\n",
            "\n",
            "All 15 trials completed successfully!\n",
            "\n",
            "Results saved to Excel file:\n",
            "  /content/BioBERT_RandomGridSearch_Results.xlsx\n",
            "\n",
            "============================================================\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 8) Random Grid Search Hyperparameter Optimization (15 trials)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RANDOM GRID SEARCH HYPERPARAMETER OPTIMIZATION\")\n",
        "print(\"15 TRIALS - T4 GPU OPTIMIZED\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Define hyperparameter search space\n",
        "param_grid = {\n",
        "    \"epochs\": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
        "    \"learning_rate\": [0.00002, 0.00003, 0.00004, 0.00005, 0.00006, 0.00007],\n",
        "    \"batch_size\": [8, 12, 16],\n",
        "    \"grad_accum_steps\": [1, 2, 4, 6],\n",
        "    \"warmup_ratio\": [0.05, 0.07, 0.09, 0.10, 0.12, 0.15, 0.18],\n",
        "    \"weight_decay\": [0.005, 0.008, 0.01, 0.015, 0.02, 0.025]\n",
        "}\n",
        "\n",
        "NUM_TRIALS = 15\n",
        "\n",
        "# Generate all 15 random configurations BEFORE the loop\n",
        "print(\"Generating random hyperparameter configurations...\")\n",
        "hyperparam_configs = []\n",
        "for _ in range(NUM_TRIALS):\n",
        "    config = {\n",
        "        \"epochs\": random.choice(param_grid[\"epochs\"]),\n",
        "        \"learning_rate\": random.choice(param_grid[\"learning_rate\"]),\n",
        "        \"batch_size\": random.choice(param_grid[\"batch_size\"]),\n",
        "        \"grad_accum_steps\": random.choice(param_grid[\"grad_accum_steps\"]),\n",
        "        \"warmup_ratio\": random.choice(param_grid[\"warmup_ratio\"]),\n",
        "        \"weight_decay\": random.choice(param_grid[\"weight_decay\"])\n",
        "    }\n",
        "    hyperparam_configs.append(config)\n",
        "\n",
        "print(f\"Generated {NUM_TRIALS} random configurations\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Excel setup\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"Random Grid Search Results\"\n",
        "ws.append([\n",
        "    \"Trial\", \"Epochs\", \"Learning Rate\", \"Batch Size\", \"Grad Accum\", \"Warmup Ratio\", \"Weight Decay\",\n",
        "    \"Train-Accuracy\", \"Test-Accuracy\",\n",
        "    \"Train-F1\", \"Test-F1\",\n",
        "    \"Train-Precision\", \"Test-Precision\",\n",
        "    \"Train-Recall\", \"Test-Recall\",\n",
        "    \"Runtime (s)\"\n",
        "])\n",
        "\n",
        "# Main random grid search loop\n",
        "for trial, params in enumerate(hyperparam_configs, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"TRIAL {trial}/{NUM_TRIALS} - Random Grid Search\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    print(f\"Sampled Parameters:\")\n",
        "    print(f\"   Epochs: {params['epochs']}\")\n",
        "    print(f\"   Learning Rate: {params['learning_rate']:.6f}\")\n",
        "    print(f\"   Batch Size: {params['batch_size']}\")\n",
        "    print(f\"   Gradient Accumulation: {params['grad_accum_steps']}\")\n",
        "    print(f\"   Warmup Ratio: {params['warmup_ratio']:.2f}\")\n",
        "    print(f\"   Weight Decay: {params['weight_decay']:.3f}\")\n",
        "\n",
        "    # Reload fresh model for each trial\n",
        "    print(\"\\nLoading fresh BioBERT model...\")\n",
        "    model_fresh = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "    model_fresh.to(device)\n",
        "\n",
        "    # Configure training arguments (T4 optimized)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_trial_{trial}\",\n",
        "        num_train_epochs=params[\"epochs\"],\n",
        "        per_device_train_batch_size=params[\"batch_size\"],\n",
        "        per_device_eval_batch_size=params[\"batch_size\"],\n",
        "        gradient_accumulation_steps=params[\"grad_accum_steps\"],\n",
        "        learning_rate=params[\"learning_rate\"],\n",
        "        warmup_ratio=params[\"warmup_ratio\"],\n",
        "        weight_decay=params[\"weight_decay\"],\n",
        "        eval_strategy=\"no\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_dir=f\"./logs_trial_{trial}\",\n",
        "        logging_steps=50,\n",
        "        report_to=[],\n",
        "        disable_tqdm=False,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        dataloader_num_workers=0,  # T4 optimization\n",
        "        dataloader_pin_memory=True,\n",
        "        max_grad_norm=1.0,\n",
        "    )\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = Trainer(\n",
        "        model=model_fresh,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_test,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    print(\"\\nTraining...\")\n",
        "    start_time = time.time()\n",
        "    trainer.train()\n",
        "    runtime = round(time.time() - start_time, 2)\n",
        "\n",
        "    # Evaluate on BOTH train and test sets\n",
        "    print(\"\\nEvaluating on training set...\")\n",
        "    train_metrics = evaluate_dataset(trainer, tokenized_train, \"TRAIN\")\n",
        "\n",
        "    print(\"Evaluating on test set...\")\n",
        "    test_metrics = evaluate_dataset(trainer, tokenized_test, \"TEST\")\n",
        "\n",
        "    # Append results to Excel (formatted as real numbers)\n",
        "    ws.append([\n",
        "        trial,\n",
        "        params[\"epochs\"],\n",
        "        float(f\"{params['learning_rate']:.6f}\"),  # Real number format\n",
        "        params[\"batch_size\"],\n",
        "        params[\"grad_accum_steps\"],\n",
        "        float(f\"{params['warmup_ratio']:.4f}\"),\n",
        "        float(f\"{params['weight_decay']:.6f}\"),\n",
        "        float(f\"{train_metrics['accuracy']:.6f}\"),\n",
        "        float(f\"{test_metrics['accuracy']:.6f}\"),\n",
        "        float(f\"{train_metrics['f1']:.6f}\"),\n",
        "        float(f\"{test_metrics['f1']:.6f}\"),\n",
        "        float(f\"{train_metrics['precision']:.6f}\"),\n",
        "        float(f\"{test_metrics['precision']:.6f}\"),\n",
        "        float(f\"{train_metrics['recall']:.6f}\"),\n",
        "        float(f\"{test_metrics['recall']:.6f}\"),\n",
        "        runtime\n",
        "    ])\n",
        "\n",
        "    print(f\"\\nTrial {trial} Complete!\")\n",
        "    print(f\"   Train - F1: {train_metrics['f1']:.6f}, Acc: {train_metrics['accuracy']:.6f}\")\n",
        "    print(f\"   Test  - F1: {test_metrics['f1']:.6f}, Acc: {test_metrics['accuracy']:.6f}\")\n",
        "    print(f\"   Runtime: {runtime}s\")\n",
        "\n",
        "    # Clear GPU cache and free memory (T4 optimization)\n",
        "    del model_fresh, trainer\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "# Format Excel file\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FORMATTING EXCEL FILE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Bold headers\n",
        "for cell in ws[1]:\n",
        "    cell.font = Font(bold=True)\n",
        "    cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
        "\n",
        "# Auto-adjust column widths\n",
        "for col in ws.columns:\n",
        "    max_length = 0\n",
        "    col_letter = col[0].column_letter\n",
        "    for cell in col:\n",
        "        try:\n",
        "            if len(str(cell.value)) > max_length:\n",
        "                max_length = len(str(cell.value))\n",
        "        except:\n",
        "            pass\n",
        "    adjusted_width = min((max_length + 2), 20)\n",
        "    ws.column_dimensions[col_letter].width = adjusted_width\n",
        "\n",
        "# Save Excel file\n",
        "output_excel = \"/content/BioBERT_RandomGridSearch_Results.xlsx\"\n",
        "wb.save(output_excel)\n",
        "\n",
        "print(f\"\\nAll {NUM_TRIALS} trials completed successfully!\")\n",
        "print(f\"\\nResults saved to Excel file:\")\n",
        "print(f\"  {output_excel}\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0be5f4046c0144a394679b087fcfd41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b064e44b0a4041c5a20ab534f8315216",
            "placeholder": "",
            "style": "IPY_MODEL_f2b47aa67d6f48fcb35a8ce6dc501b73",
            "value": "Tokenizingtrain:100%"
          }
        },
        "0f7733f1e0004283ae2995de9688b129": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1158b05dddb8425cb19077308d8b59f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1976ad7c6d8d4acca2a1657b37d282f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_870f9efe3a024801bf384d120adfb30e",
            "placeholder": "",
            "style": "IPY_MODEL_51a2dc39700b46139ac11486181b5952",
            "value": "523/523[00:02&lt;00:00,184.96examples/s]"
          }
        },
        "20740c061daf4120bdf47aa8ea2ee074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4364b8d374a3431e814406a703a6e91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fed344f283d493c837248f929e00aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_856eb12b9f0047ae85e73489baf46f57",
            "max": 523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4364b8d374a3431e814406a703a6e91b",
            "value": 523
          }
        },
        "5140abad789a4cfdbe30aaba9cbd4d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0be5f4046c0144a394679b087fcfd41e",
              "IPY_MODEL_4fed344f283d493c837248f929e00aa7",
              "IPY_MODEL_1976ad7c6d8d4acca2a1657b37d282f2"
            ],
            "layout": "IPY_MODEL_b3dfda737f174d8c82d531ea97a717fd"
          }
        },
        "51a2dc39700b46139ac11486181b5952": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "856eb12b9f0047ae85e73489baf46f57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "870f9efe3a024801bf384d120adfb30e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f543a1f8754d19acbc6492b95282f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a346b49ebe92462d96536624335de3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc0400c9ffdf4f2ab0b7eb0f74a44055",
              "IPY_MODEL_e3072e0033184e8096523effac5a63e2",
              "IPY_MODEL_c48ccfc926384cad8129b2454832ca51"
            ],
            "layout": "IPY_MODEL_b40eda8f620147f7b20b136724c4846f"
          }
        },
        "b064e44b0a4041c5a20ab534f8315216": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3dfda737f174d8c82d531ea97a717fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40eda8f620147f7b20b136724c4846f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba90b9f2f4774f7c9e9374a7eda698fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c48ccfc926384cad8129b2454832ca51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f7733f1e0004283ae2995de9688b129",
            "placeholder": "",
            "style": "IPY_MODEL_f5ef1065b7b64cf1bd328e93ace394d6",
            "value": "131/131[00:00&lt;00:00,133.19examples/s]"
          }
        },
        "dc0400c9ffdf4f2ab0b7eb0f74a44055": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91f543a1f8754d19acbc6492b95282f3",
            "placeholder": "",
            "style": "IPY_MODEL_ba90b9f2f4774f7c9e9374a7eda698fc",
            "value": "Tokenizingtest:100%"
          }
        },
        "e3072e0033184e8096523effac5a63e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1158b05dddb8425cb19077308d8b59f3",
            "max": 131,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20740c061daf4120bdf47aa8ea2ee074",
            "value": 131
          }
        },
        "f2b47aa67d6f48fcb35a8ce6dc501b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5ef1065b7b64cf1bd328e93ace394d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
