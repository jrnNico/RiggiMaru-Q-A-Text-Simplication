{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "28b56daa",
      "metadata": {
        "id": "28b56daa"
      },
      "source": [
        "# Cardiovascular Medical QA Fine-Tuning (BioBERT) - Grid Search\n",
        "\n",
        "This notebook fine-tunes a medical BERT QA model on cardiovascular Q&A data using a Colab GPU with **Grid Search** for hyperparameter optimization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6425125",
      "metadata": {
        "id": "f6425125"
      },
      "source": [
        "### 1. Environment Setup and Configuration\n",
        "\n",
        "This section prepares the computational environment for fine-tuning the cardiovascular QA model. The setup process begins by defining a utility function to install essential Python packages using pip, including the Transformers library (version 4.44.0 or higher) for working with pre-trained models, Datasets for efficient data handling, Accelerate for optimized training, and Evaluate for model performance metrics. After installing these core dependencies, the code performs comprehensive environment checks to verify the Python version, platform details, and PyTorch installation. Most importantly, it detects whether a GPU is available for training and displays relevant information such as the GPU model name and CUDA version. If no GPU is detected, the system alerts the user to enable GPU acceleration in Google Colab's runtime settings, as GPU support is crucial for efficient training of transformer models. This initial setup ensures that all necessary dependencies are in place and that the hardware configuration is optimal for the computationally intensive task of fine-tuning a BERT-based question answering model on medical data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2599bd50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2599bd50",
        "outputId": "b1ed7baa-2e69-4894-b982-4297add0f2dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ENVIRONMENT\n",
            "============================================================\n",
            "Python: 3.12.12 | Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "PyTorch: 2.8.0+cu126\n",
            "GPU: Tesla T4 | CUDA: 12.6\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 1) Environment setup (Colab)\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def pip_install(packages):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + packages)\n",
        "pip_install([\n",
        "    \"transformers>=4.44.0\",\n",
        "    \"datasets>=2.14.0\",\n",
        "    \"accelerate>=0.26.0\",\n",
        "    \"evaluate>=0.4.0\",\n",
        "])\n",
        "try:\n",
        "    import torch\n",
        "    import platform\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ENVIRONMENT\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Python: {sys.version.split()[0]} | Platform: {platform.platform()}\")\n",
        "    print(f\"PyTorch: {torch.__version__}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)} | CUDA: {torch.version.cuda}\")\n",
        "    else:\n",
        "        print(\"GPU not detected. Enable a GPU in Runtime > Change runtime type > T4/other.\")\n",
        "    print(\"=\" * 60)\n",
        "except Exception as e:\n",
        "    print(\"Environment check failed:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R1N_DDUdHtKp",
      "metadata": {
        "id": "R1N_DDUdHtKp"
      },
      "source": [
        "### 2. Imports and GPU Configuration\n",
        "\n",
        "Following the initial setup, the code imports all necessary libraries for the machine learning pipeline, including PyTorch for deep learning operations, NumPy for numerical computations, Pandas for data manipulation, and specific modules from the Transformers library such as AutoTokenizer and AutoModelForQuestionAnswering for handling pre-trained models. The code also imports training utilities like TrainingArguments, Trainer, and default_data_collator to streamline the fine-tuning process, along with the Datasets library for efficient data handling. Warning messages are suppressed to keep the output clean. The GPU configuration section then performs a detailed check to determine if CUDA-enabled GPU hardware is available. If a GPU is detected, the code creates a CUDA device object and displays comprehensive information including the GPU model name, CUDA version, and total available GPU memory in gigabytes. This information is critical for understanding the computational resources available and for optimizing batch sizes and memory usage during training. If no GPU is found, the system falls back to CPU mode and warns the user that training will be significantly slower, emphasizing the importance of GPU acceleration for transformer model fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "i2sPpCDv7l46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2sPpCDv7l46",
        "outputId": "5b36543d-12d6-4719-c529-1952138c8698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "GPU CONFIGURATION\n",
            "============================================================\n",
            "GPU Available: Tesla T4\n",
            "CUDA Version: 12.6\n",
            "GPU Memory: 14.74 GB\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 2) Imports and GPU config\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import default_data_collator\n",
        "from datasets import Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"GPU CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Memory: {round(torch.cuda.get_device_properties(0).total_memory / 1024**3, 2)} GB\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available; training will be slower.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6YQLEcmdHxTq",
      "metadata": {
        "id": "6YQLEcmdHxTq"
      },
      "source": [
        "### 3. Dataset Loading Options\n",
        "\n",
        "This section provides flexible options for loading the cardiovascular QA dataset in Google Colab. User can directly upload a file from their local machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "jkaUSXpn7l1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "jkaUSXpn7l1c",
        "outputId": "361d5001-7f89-4b33-af99-14b66dfa57f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fc503053-42cc-4f27-b98d-0a59fadb6749\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fc503053-42cc-4f27-b98d-0a59fadb6749\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving medquadCardiovascular.csv to medquadCardiovascular.csv\n",
            "Dataset CSV: medquadCardiovascular.csv\n"
          ]
        }
      ],
      "source": [
        "# 3) Dataset loading (Cardiovascular QA)\n",
        "USE_DRIVE = False\n",
        "USE_UPLOAD = not USE_DRIVE\n",
        "if USE_UPLOAD:\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            CSV_PATH = list(uploaded.keys())[0]\n",
        "    except Exception:\n",
        "        pass\n",
        "if not CSV_PATH:\n",
        "    raise ValueError(\"Please provide CSV_PATH via Drive or upload.\")\n",
        "\n",
        "print(\"Dataset CSV:\", CSV_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zfjoiuVKH8OR",
      "metadata": {
        "id": "zfjoiuVKH8OR"
      },
      "source": [
        "### 4. Data Loading and Preprocessing\n",
        "\n",
        "Once the dataset path is established, this section loads the cardiovascular medical QA data from the CSV file using Pandas and performs essential preprocessing steps. The code first reads the CSV and displays diagnostic information including the total number of records, column names, a sample question preview, and the character length of a sample answer to give users insight into the dataset structure and content. To ensure data quality, the code removes any rows containing null values in the critical question or answer columns, preventing training issues from incomplete data. The dataset is then randomly shuffled with a fixed random seed for reproducibility and split into training and test sets using an 80/20 ratio, which provides substantial training data while reserving enough examples for unbiased testing. The training set will be used to update the model weights, while the test set allows for evaluation of model performance after training. This preprocessing ensures clean, well-organized data that's ready for the tokenization and model training phases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5P3q4k1B7QLi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P3q4k1B7QLi",
        "outputId": "139ecaed-b30e-40aa-d6a4-3293b2de388d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "LOADING CARDIOVASCULAR DATASET\n",
            "============================================================\n",
            "Total records: 654\n",
            "Columns: ['question', 'answer', 'source', 'focus_area']\n",
            "Sample question: What is (are) High Blood Pressure ?...\n",
            "Sample answer chars: 5586\n",
            "Train: 523 | Test: 131\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 4) Data Loading and Preprocessing\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LOADING CARDIOVASCULAR DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "dataset = pd.read_csv(CSV_PATH)\n",
        "print(f\"Total records: {len(dataset)}\")\n",
        "print(f\"Columns: {list(dataset.columns)}\")\n",
        "print(f\"Sample question: {str(dataset.iloc[0]['question'])[:80]}...\")\n",
        "print(f\"Sample answer chars: {len(str(dataset.iloc[0]['answer']))}\")\n",
        "\n",
        "# Drop nulls\n",
        "dataset = dataset.dropna(subset=[\"question\", \"answer\"]).reset_index(drop=True)\n",
        "\n",
        "# Train/test split (80/20)\n",
        "dataset_shuffled = dataset.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "split_idx = int(len(dataset_shuffled) * 0.80)\n",
        "train_data = dataset_shuffled.iloc[:split_idx].copy()\n",
        "test_data = dataset_shuffled.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"Train: {len(train_data)} | Test: {len(test_data)}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KDryJ4F2H-eG",
      "metadata": {
        "id": "KDryJ4F2H-eG"
      },
      "source": [
        "### 5. Model and Tokenizer Initialization\n",
        "\n",
        "This section initializes the pre-trained BioBERT model specifically designed for biomedical text processing. The code loads the \"dmis-lab/biobert-base-cased-v1.1\" model from the Hugging Face model hub, which is a BERT variant pre-trained on large-scale biomedical literature including PubMed abstracts and PMC full-text articles. This specialized pre-training gives BioBERT a strong foundation in medical terminology and biomedical language patterns. Both the tokenizer and the model are loaded using the Auto classes from the Transformers library, which automatically handle the correct architecture and configuration. The tokenizer is initialized with the fast tokenizer option enabled for improved performance during text processing. Once loaded, the model is transferred to the appropriate device (GPU if available, otherwise CPU) to ensure all subsequent operations leverage the available hardware acceleration. Using BioBERT as the base model provides significant advantages for medical question answering tasks, as it already understands medical concepts and terminology, requiring less fine-tuning data and time compared to general-purpose language models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "D17XfaTK7QGj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "de7c7b77aec84bae8e498da5f5a106b5",
            "02f5b2a8f5234aa0a3a217ff14a2b09b",
            "ef6c23e955484bcb913e165b4e27e388",
            "9b7080833b9c44adbb3ff4d72b5d0fc1",
            "40e505f821864b34b4f7d345d39dbf03",
            "74a22c544fe541dbbd31ded4af8ca99f",
            "9e6d7b6010824386b2d50f60e4fcb0f1",
            "591f056a639a4004a7ce62e5653cb8b6",
            "0ce6c083e906407eab91e253c0586a2a",
            "57b638c9de41468fb6b14b4e389c970f",
            "e35f97d390764d2784fbe39dc8c28e5d",
            "9926156108b84086aa3d0964bae827e3",
            "c90d34cfec99431981da7fab5e3f7507",
            "570fb2519bb6495387247961d20f6fad",
            "959e915d265f4590a1d6b343fafd519f",
            "73996c365ffb4e5fb2983e311f10b984",
            "51774e7a7a294c7e84fc04a126fba059",
            "b2fab45e2d41401bb50ed191bb67a2f1",
            "eafc80dbc18c4171b60b9fccfdff3552",
            "55a6579549da40a484f873fbb5eebfa1",
            "a2bfb00213d54108ae90ddff61de84e1",
            "b0b7f0574d6d4054867a0c18366f4a9e",
            "48343d171c404f049e2230e807068626",
            "b974bac888e644e49c49db37e0e86011",
            "0a0e0a4a19ae452193a058c6a9cd48e1",
            "6f344cf5c0d247c5a6bcbe7e1be8cc2a",
            "b703cc941b354d75a8d24bffbc5da109",
            "fa52d7217ce14394941ecd57c6124e7a",
            "86c4c26599df47c58d6371b702583f28",
            "9303d6ab02564966a66959534f61598a",
            "95f4baae328d4a4db055b3f59610070e",
            "44a1bc9e4f29452d99a5114f95122e8e",
            "dd941716ea984d92a30b3166442e267b"
          ]
        },
        "id": "D17XfaTK7QGj",
        "outputId": "9fee2d79-edfd-4cdb-cde3-81d5de960ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "LOADING MODEL AND TOKENIZER\n",
            "============================================================\n",
            "Model: dmis-lab/biobert-base-cased-v1.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de7c7b77aec84bae8e498da5f5a106b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9926156108b84086aa3d0964bae827e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48343d171c404f049e2230e807068626",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 5) Model and tokenizer\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LOADING MODEL AND TOKENIZER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "MODEL_NAME = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "print(\"Model:\", MODEL_NAME)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "model.to(device)\n",
        "\n",
        "print(\"Model loaded.\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ogr_Q3uSIAy4",
      "metadata": {
        "id": "Ogr_Q3uSIAy4"
      },
      "source": [
        "This critical section transforms the raw text data into numerical representations that the model can process, while also preparing the labels for extractive question answering. The code converts the Pandas dataframes into Hugging Face Dataset objects for efficient processing, then defines key parameters including maximum sequence length (384 tokens) and document stride (128 tokens) for handling long contexts. The prepare_train_features function tokenizes both questions and answers together, truncating only the answer portion if necessary to fit within the maximum length constraint. For extractive QA, the model needs to predict the start and end positions of the answer span within the tokenized context. The code implements logic to identify which tokens belong to the context (sequence_id == 1) versus the question, then sets start and end position labels accordingly. If no valid context exists, both positions are set to 0 as a fallback. The function also handles overflowing tokens by creating multiple training examples from long contexts and removes the offset_mapping data structure before returning, as it's only needed during preprocessing. This tokenization process is applied to both training and validation datasets in batched mode for efficiency, preparing the data in the exact format required by the question answering model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "rG7gLueX7QAq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "f0a8d11ad5df42a9a1f93f059ae6c7a9",
            "3025d493d3364af39862ecd787e6fe74",
            "edf4e60148bd407788e856c41b9fc6f2",
            "c03f308eff5a49cd923744713f508adc",
            "2a6302f1f99b4a4683a73b8201dd1eaa",
            "0b0119c53b50438db1d3637467381e5c",
            "b7bf0bb4ba004842949e453f4195e413",
            "c1697bf9e1c74cda873beb4292a30ad9",
            "369eee32b6874a2dbfea8aca8c6f12b1",
            "7a6fcbdc214045588cef25705f274466",
            "d3ef5558ddd640c5aa4e428ad27a8cb0",
            "fd055bd7b5b94703afdc9daf99783d1c",
            "fda44350b136474cad9ece08346075f0",
            "90c7bb7f8f4c4d66b569c4b3b6d453b3",
            "7a6eb49b30f54428bdb51682a7101463",
            "242ed6519ba140578ff7bda8713d4dce",
            "ee274ba814124e4aa789fcee28b28491",
            "fcb0892c8d4848b79e620791023492f0",
            "c5ae9eaca76d4ec89238a0b0e8e892fa",
            "cd60e6633f2147dc9b25098ba216c0e5",
            "c1f75b4724094cb2833cd515e94a2b72",
            "b63b7738100a4003a6d889a8fd3c7a3e"
          ]
        },
        "id": "rG7gLueX7QAq",
        "outputId": "b012916d-56fb-41fe-fc15-f2201b16c3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TOKENIZING DATASET\n",
            "============================================================\n",
            "Tokenizing train...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0a8d11ad5df42a9a1f93f059ae6c7a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train:   0%|          | 0/523 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing test...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd055bd7b5b94703afdc9daf99783d1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing test:   0%|          | 0/131 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 6) Tokenization and Feature Preparation\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TOKENIZING DATASET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_data)\n",
        "test_ds = Dataset.from_pandas(test_data)\n",
        "\n",
        "MAX_LENGTH = 384\n",
        "DOC_STRIDE = 128\n",
        "\n",
        "def prepare_train_features(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"answer\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=MAX_LENGTH,\n",
        "        stride=DOC_STRIDE,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(tokenized[\"offset_mapping\"]):\n",
        "        sequence_ids = tokenized.sequence_ids(i)\n",
        "\n",
        "        context_start = None\n",
        "        context_end = None\n",
        "        for idx, seq_id in enumerate(sequence_ids):\n",
        "            if seq_id == 1:\n",
        "                if context_start is None:\n",
        "                    context_start = idx\n",
        "                context_end = idx\n",
        "\n",
        "        if context_start is None:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            answer_start = context_start\n",
        "            answer_end = min(context_start + 50, context_end)\n",
        "            start_positions.append(answer_start)\n",
        "            end_positions.append(answer_end)\n",
        "\n",
        "    tokenized[\"start_positions\"] = start_positions\n",
        "    tokenized[\"end_positions\"] = end_positions\n",
        "\n",
        "    # Drop offset_mapping so it isn't fed to the model\n",
        "    if \"offset_mapping\" in tokenized:\n",
        "        tokenized.pop(\"offset_mapping\")\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "print(\"Tokenizing train...\")\n",
        "tokenized_train = train_ds.map(\n",
        "    prepare_train_features,\n",
        "    batched=True,\n",
        "    remove_columns=train_ds.column_names,\n",
        "    desc=\"Tokenizing train\",\n",
        ")\n",
        "\n",
        "print(\"Tokenizing test...\")\n",
        "tokenized_test = test_ds.map(\n",
        "    prepare_train_features,\n",
        "    batched=True,\n",
        "    remove_columns=test_ds.column_names,\n",
        "    desc=\"Tokenizing test\",\n",
        ")\n",
        "\n",
        "print(\"Done.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PaHL8FYxIEGB",
      "metadata": {
        "id": "PaHL8FYxIEGB"
      },
      "source": [
        "### 7. Evaluation Metrics Definition\n",
        "\n",
        "This section defines modular helper functions for calculating comprehensive evaluation metrics specifically designed for question answering tasks. The calculate_detailed_metrics function processes model predictions in a single efficient pass, extracting start and end logits and converting them to predicted token positions. It calculates four key metrics: accuracy (average of exact match, start accuracy, and end accuracy), token-level F1 score, precision, and recall. The F1 calculation treats predicted and actual answer spans as sets of token positions and computes precision and recall based on their overlap, handling special cases appropriately. The evaluate_dataset function wraps the prediction and metric calculation process for easy evaluation of any dataset, making a single prediction call for efficiency. An additional compute_qa_metrics function is maintained for compatibility with the Hugging Face Trainer API during training. This modular structure eliminates code duplication and provides a clean interface for evaluating model performance on both training and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "xaCvAOT87P7i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaCvAOT87P7i",
        "outputId": "f9428851-c7e2-4024-b1fa-23afadb900e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics functions ready.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 7) Evaluation Metrics - Modular Helper Functions\n",
        "import numpy as np\n",
        "\n",
        "def calculate_detailed_metrics(predictions):\n",
        "    \"\"\"\n",
        "    Calculate accuracy, F1, precision, and recall from model predictions.\n",
        "    This function processes predictions in a single pass for efficiency.\n",
        "    \"\"\"\n",
        "    pred_starts = np.argmax(predictions.predictions[0], axis=1)\n",
        "    pred_ends = np.argmax(predictions.predictions[1], axis=1)\n",
        "\n",
        "    true_starts = np.asarray(predictions.label_ids[0]).reshape(-1)\n",
        "    true_ends = np.asarray(predictions.label_ids[1]).reshape(-1)\n",
        "\n",
        "    # Calculate exact match and accuracy metrics\n",
        "    exact_match = np.mean((pred_starts == true_starts) & (pred_ends == true_ends))\n",
        "    start_accuracy = np.mean(pred_starts == true_starts)\n",
        "    end_accuracy = np.mean(pred_ends == true_ends)\n",
        "    accuracy = (exact_match + start_accuracy + end_accuracy) / 3\n",
        "\n",
        "    # Calculate F1, precision, and recall from token overlap\n",
        "    f1_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "\n",
        "    for ps, pe, ts, te in zip(pred_starts, pred_ends, true_starts, true_ends):\n",
        "        ps, pe, ts, te = int(ps), int(pe), int(ts), int(te)\n",
        "        pred_tokens = set(range(ps, pe + 1))\n",
        "        true_tokens = set(range(ts, te + 1))\n",
        "\n",
        "        if not pred_tokens and not true_tokens:\n",
        "            f1_scores.append(1.0)\n",
        "            precision_scores.append(1.0)\n",
        "            recall_scores.append(1.0)\n",
        "        elif not pred_tokens or not true_tokens:\n",
        "            f1_scores.append(0.0)\n",
        "            precision_scores.append(0.0)\n",
        "            recall_scores.append(0.0)\n",
        "        else:\n",
        "            common = len(pred_tokens & true_tokens)\n",
        "            if common == 0:\n",
        "                f1_scores.append(0.0)\n",
        "                precision_scores.append(0.0)\n",
        "                recall_scores.append(0.0)\n",
        "            else:\n",
        "                precision = common / len(pred_tokens)\n",
        "                recall = common / len(true_tokens)\n",
        "                f1 = 2 * (precision * recall) / (precision + recall)\n",
        "                f1_scores.append(f1)\n",
        "                precision_scores.append(precision)\n",
        "                recall_scores.append(recall)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": float(accuracy),\n",
        "        \"f1\": float(np.mean(f1_scores)) if f1_scores else 0.0,\n",
        "        \"precision\": float(np.mean(precision_scores)) if precision_scores else 0.0,\n",
        "        \"recall\": float(np.mean(recall_scores)) if recall_scores else 0.0,\n",
        "    }\n",
        "\n",
        "def evaluate_dataset(trainer, tokenized_data, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate model on a given dataset and return all metrics.\n",
        "    Makes a single prediction call for efficiency.\n",
        "    \"\"\"\n",
        "    predictions = trainer.predict(tokenized_data)\n",
        "    metrics = calculate_detailed_metrics(predictions)\n",
        "    return metrics\n",
        "\n",
        "def compute_qa_metrics(eval_pred):\n",
        "    \"\"\"\n",
        "    Compute metrics for Trainer's evaluation during training.\n",
        "    Kept for compatibility with Trainer API.\n",
        "    \"\"\"\n",
        "    predictions, label_ids = eval_pred\n",
        "    start_logits, end_logits = predictions\n",
        "\n",
        "    pred_starts = np.argmax(start_logits, axis=1)\n",
        "    pred_ends = np.argmax(end_logits, axis=1)\n",
        "\n",
        "    true_starts = np.asarray(label_ids[0]).reshape(-1)\n",
        "    true_ends = np.asarray(label_ids[1]).reshape(-1)\n",
        "\n",
        "    exact_match = np.mean((pred_starts == true_starts) & (pred_ends == true_ends))\n",
        "    start_accuracy = np.mean(pred_starts == true_starts)\n",
        "    end_accuracy = np.mean(pred_ends == true_ends)\n",
        "\n",
        "    f1_scores = []\n",
        "    for ps, pe, ts, te in zip(pred_starts, pred_ends, true_starts, true_ends):\n",
        "        ps, pe, ts, te = int(ps), int(pe), int(ts), int(te)\n",
        "        pred_tokens = set(range(ps, pe + 1))\n",
        "        true_tokens = set(range(ts, te + 1))\n",
        "        if not pred_tokens and not true_tokens:\n",
        "            f1_scores.append(1.0)\n",
        "        elif not pred_tokens or not true_tokens:\n",
        "            f1_scores.append(0.0)\n",
        "        else:\n",
        "            common = len(pred_tokens & true_tokens)\n",
        "            if common == 0:\n",
        "                f1_scores.append(0.0)\n",
        "            else:\n",
        "                precision = common / len(pred_tokens)\n",
        "                recall = common / len(true_tokens)\n",
        "                f1_scores.append(2 * (precision * recall) / (precision + recall))\n",
        "\n",
        "    return {\n",
        "        \"exact_match\": float(exact_match),\n",
        "        \"start_accuracy\": float(start_accuracy),\n",
        "        \"end_accuracy\": float(end_accuracy),\n",
        "        \"f1\": float(np.mean(f1_scores)) if f1_scores else 0.0,\n",
        "    }\n",
        "\n",
        "print(\"Metrics functions ready.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wfj3DBeXIGEj",
      "metadata": {
        "id": "wfj3DBeXIGEj"
      },
      "source": [
        "### 8. Training Configuration\n",
        "\n",
        "This section configures all the hyperparameters and training settings optimized for Google Colab's T4 GPU environment. The TrainingArguments object specifies that the model will train for 3 epochs with a batch size of 16 examples per device, using gradient accumulation over 2 steps to effectively simulate a larger batch size of 32 while managing memory constraints. The learning rate is set to 0.00003, a typical value for fine-tuning pre-trained models, with 10% of training steps allocated to warmup where the learning rate gradually increases from zero. Weight decay (0.01) provides regularization to prevent overfitting, and gradient clipping (max_grad_norm=1.0) prevents exploding gradients. The configuration enables mixed-precision training (fp16) when a GPU is available, which significantly speeds up training and reduces memory usage with minimal impact on model quality. The code sets up evaluation and checkpoint saving at the end of each epoch, keeping only the best 2 checkpoints based on F1 score to conserve storage space. Data loading is optimized with pin_memory enabled and dataloader_num_workers set to 0 for T4 GPU compatibility (limited CPU cores). Logging occurs every 50 steps to track training progress, and the random seed is fixed at 42 for reproducibility. These carefully chosen settings balance training efficiency, model performance, and resource constraints typical of Colab's T4 GPU allocation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "A72rQs_57Pxc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A72rQs_57Pxc",
        "outputId": "02526ed6-74ea-42bc-df1d-e859233624ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING CONFIGURATION\n",
            "============================================================\n",
            "Configured. FP16: True\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 8) Training configuration (Colab-friendly)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_cardio_qa\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=0.00003,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    max_grad_norm=1.0,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_pin_memory=True,\n",
        "    dataloader_num_workers=2,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    logging_dir=\"./logs_cardio_qa\",\n",
        "    logging_steps=50,\n",
        "    logging_strategy=\"steps\",\n",
        "    report_to=[],\n",
        "    seed=42,\n",
        "    disable_tqdm=False,\n",
        "    remove_unused_columns=True,\n",
        ")\n",
        "\n",
        "print(\"Configured. FP16:\", training_args.fp16)\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bNFZyugNIH08",
      "metadata": {
        "id": "bNFZyugNIH08"
      },
      "source": [
        "### 9. Trainer Initialization\n",
        "\n",
        "This section instantiates the Hugging Face Trainer object, which orchestrates the entire training and evaluation process. The Trainer combines the model, training arguments, datasets, tokenizer, data collator, and metrics function into a unified training pipeline. The data collator handles the batching and padding of tokenized examples to ensure uniform tensor sizes within each batch. By providing both training and test datasets, the Trainer can automatically run evaluation at the intervals specified in the training arguments. The compute_metrics function enables automatic calculation of custom metrics during evaluation, providing real-time feedback on model performance. This high-level abstraction handles many complex aspects of the training loop including gradient computation, backpropagation, optimizer steps, learning rate scheduling, mixed-precision training, logging, checkpointing, and distributed training if multiple GPUs are available. The Trainer API simplifies what would otherwise require hundreds of lines of custom training code, while still offering extensive customization options through the training arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c0zOrhkY7PrE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0zOrhkY7PrE",
        "outputId": "4a5b60a0-27cf-4120-8845-15bb9e7c34a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "INITIALIZING TRAINER\n",
            "============================================================\n",
            "Trainer ready.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 9) Initialize Trainer\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"INITIALIZING TRAINER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        "    compute_metrics=compute_qa_metrics,\n",
        ")\n",
        "\n",
        "print(\"Trainer ready.\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hprmIT-IIJFl",
      "metadata": {
        "id": "hprmIT-IIJFl"
      },
      "source": [
        "### 10. Exhaustive Grid Search Hyperparameter Tuning\n",
        "\n",
        "This section implements a focused exhaustive Grid Search to identify optimal hyperparameters for the cardiovascular QA task with BioBERT. Unlike random search, this Grid Search tests ALL possible combinations of the two most impactful hyperparameters: number of epochs and learning rate. The grid consists of 3 epoch values (5, 10, 15) and 5 learning rate values (0.00002, 0.00003, 0.00004, 0.00005, 0.00006), resulting in exactly 15 configurations (3  5 = 15). This focused approach provides comprehensive coverage of the most important hyperparameters while keeping computational cost manageable on Google Colab's T4 GPU. Other hyperparameters are set to well-established defaults: batch size of 16 (optimal for T4 memory), gradient accumulation of 1 (simplicity), warmup ratio of 0.10 (standard practice), and weight decay of 0.01 (effective regularization). For each configuration, a fresh copy of the pre-trained BioBERT model is loaded to ensure fair comparison. All hyperparameters are displayed in real number format (e.g., 0.00003 instead of 3e-5) for clarity. The code evaluates performance on both training and test datasets using modular helper functions that calculate accuracy, F1 score, precision, and recall in a single efficient pass. Results are exported to an Excel file with columns for all hyperparameters and metrics, formatted with real numbers throughout. The grid structure ensures no parameter combination is missed, making it ideal for understanding the interaction between epochs and learning rate. GPU cache is cleared between iterations to optimize memory usage on the T4 GPU. With epochs ranging from 5-15, each configuration completes in 5-15 minutes, making the entire grid search feasible in 2-4 hours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "gf-SIve77Pm4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gf-SIve77Pm4",
        "outputId": "0b7aa555-9bf2-4cea-e873-22fe74599e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EXHAUSTIVE GRID SEARCH HYPERPARAMETER TUNING (15 CONFIGURATIONS)\n",
            "============================================================\n",
            "Grid Search Configuration:\n",
            "  Grid Parameters:\n",
            "    - Epochs: [5, 10, 15]\n",
            "    - Learning Rate: ['0.000020', '0.000030', '0.000040', '0.000050', '0.000060']\n",
            "\n",
            "  Fixed Parameters:\n",
            "    - Batch Size: 16\n",
            "    - Gradient Accumulation: 1\n",
            "    - Warmup Ratio: 0.10\n",
            "    - Weight Decay: 0.0100\n",
            "\n",
            "Generated 15 configurations (exhaustive grid)\n",
            "Calculation: 3 epochs  5 learning rates = 15\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 1/15\n",
            "Params: Epochs=5, LR=0.000020\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [315/315 01:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 1 complete!\n",
            "   Train - F1: 0.9822, Acc: 0.5902\n",
            "   Test  - F1: 0.9757, Acc: 0.4608\n",
            "   Runtime: 92.39s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 2/15\n",
            "Params: Epochs=5, LR=0.000030\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [315/315 01:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 2 complete!\n",
            "   Train - F1: 0.9811, Acc: 0.8122\n",
            "   Test  - F1: 0.9635, Acc: 0.6642\n",
            "   Runtime: 91.49s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 3/15\n",
            "Params: Epochs=5, LR=0.000040\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [315/315 01:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 3 complete!\n",
            "   Train - F1: 0.9981, Acc: 0.9396\n",
            "   Test  - F1: 0.9948, Acc: 0.8971\n",
            "   Runtime: 91.13s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 4/15\n",
            "Params: Epochs=5, LR=0.000050\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [315/315 01:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 4 complete!\n",
            "   Train - F1: 0.9962, Acc: 0.9631\n",
            "   Test  - F1: 0.9943, Acc: 0.8995\n",
            "   Runtime: 91.12s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 5/15\n",
            "Params: Epochs=5, LR=0.000060\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [315/315 01:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 5 complete!\n",
            "   Train - F1: 0.9999, Acc: 0.9906\n",
            "   Test  - F1: 0.9995, Acc: 0.9706\n",
            "   Runtime: 91.12s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 6/15\n",
            "Params: Epochs=10, LR=0.000020\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [630/630 03:01, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 6 complete!\n",
            "   Train - F1: 0.9986, Acc: 0.9752\n",
            "   Test  - F1: 0.9983, Acc: 0.9069\n",
            "   Runtime: 181.98s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 7/15\n",
            "Params: Epochs=10, LR=0.000030\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [630/630 03:01, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.063600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 7 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 0.9960, Acc: 0.9828\n",
            "   Runtime: 181.7s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 8/15\n",
            "Params: Epochs=10, LR=0.000040\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [630/630 03:00, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.929800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 8 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 1.0000, Acc: 1.0000\n",
            "   Runtime: 180.72s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 9/15\n",
            "Params: Epochs=10, LR=0.000050\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [630/630 02:59, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.905700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 9 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 0.9999, Acc: 0.9975\n",
            "   Runtime: 180.46s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 10/15\n",
            "Params: Epochs=10, LR=0.000060\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [630/630 02:58, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.710300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 10 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 1.0000, Acc: 1.0000\n",
            "   Runtime: 179.32s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 11/15\n",
            "Params: Epochs=15, LR=0.000020\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [945/945 04:30, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.450800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 11 complete!\n",
            "   Train - F1: 0.9999, Acc: 0.9940\n",
            "   Test  - F1: 0.9989, Acc: 0.9412\n",
            "   Runtime: 271.27s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 12/15\n",
            "Params: Epochs=15, LR=0.000030\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [945/945 04:30, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.322400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 12 complete!\n",
            "   Train - F1: 0.9999, Acc: 0.9906\n",
            "   Test  - F1: 0.9982, Acc: 0.8799\n",
            "   Runtime: 270.81s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 13/15\n",
            "Params: Epochs=15, LR=0.000040\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [945/945 04:26, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.940800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 13 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 1.0000, Acc: 1.0000\n",
            "   Runtime: 267.47s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 14/15\n",
            "Params: Epochs=15, LR=0.000050\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [945/945 04:25, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.873400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 14 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 1.0000, Acc: 1.0000\n",
            "   Runtime: 266.58s\n",
            "\n",
            "============================================================\n",
            " Grid Configuration 15/15\n",
            "Params: Epochs=15, LR=0.000060\n",
            "        Batch=16, GradAccum=1, Warmup=0.10, WeightDecay=0.0100\n",
            "        Effective Batch Size: 16\n",
            "============================================================\n",
            " Loading fresh BioBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='945' max='945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [945/945 04:25, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.808000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on training set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Evaluating on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Configuration 15 complete!\n",
            "   Train - F1: 1.0000, Acc: 1.0000\n",
            "   Test  - F1: 1.0000, Acc: 1.0000\n",
            "   Runtime: 266.44s\n",
            "\n",
            "============================================================\n",
            "FORMATTING EXCEL FILE\n",
            "============================================================\n",
            "\n",
            " All 15 configurations completed successfully!\n",
            " Results saved to Excel file:\n",
            " /content/salameda_QA_GridSearch_Results_BioBERT.xlsx\n",
            "\n",
            "============================================================\n",
            "EXHAUSTIVE GRID SEARCH COMPLETE\n",
            "============================================================\n",
            "   - Total configurations tested: 15\n",
            "   - Grid dimensions: 3 epochs  5 learning rates\n",
            "   - Dataset size: 654 records (Train: 523, Test: 131)\n",
            "   - Epoch range: 5-15\n",
            "   - Learning rate range: 0.000020 - 0.000060\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 10) Exhaustive Grid Search Hyperparameter Tuning\n",
        "import time\n",
        "import itertools\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.styles import Font, Alignment, numbers\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXHAUSTIVE GRID SEARCH HYPERPARAMETER TUNING (15 CONFIGURATIONS)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Define grid search space - focused on most important parameters\n",
        "# This gives exactly 15 configurations (3 epochs  5 learning rates)\n",
        "grid_params = {\n",
        "    \"epochs\": [5, 10, 15],\n",
        "    \"lr\": [0.00002, 0.00003, 0.00004, 0.00005, 0.00006],\n",
        "}\n",
        "\n",
        "# Fixed parameters (well-established defaults)\n",
        "fixed_params = {\n",
        "    \"batch\": 16,\n",
        "    \"grad_accum\": 1,\n",
        "    \"warmup\": 0.10,\n",
        "    \"weight_decay\": 0.01\n",
        "}\n",
        "\n",
        "print(\"Grid Search Configuration:\")\n",
        "print(f\"  Grid Parameters:\")\n",
        "print(f\"    - Epochs: {grid_params['epochs']}\")\n",
        "print(f\"    - Learning Rate: {[f'{lr:.6f}' for lr in grid_params['lr']]}\")\n",
        "print(f\"\\n  Fixed Parameters:\")\n",
        "print(f\"    - Batch Size: {fixed_params['batch']}\")\n",
        "print(f\"    - Gradient Accumulation: {fixed_params['grad_accum']}\")\n",
        "print(f\"    - Warmup Ratio: {fixed_params['warmup']:.2f}\")\n",
        "print(f\"    - Weight Decay: {fixed_params['weight_decay']:.4f}\")\n",
        "print()\n",
        "\n",
        "# Generate all combinations (exhaustive grid)\n",
        "hyperparam_sets = []\n",
        "for epochs, lr in itertools.product(grid_params[\"epochs\"], grid_params[\"lr\"]):\n",
        "    config = {\n",
        "        \"epochs\": epochs,\n",
        "        \"lr\": lr,\n",
        "        \"batch\": fixed_params[\"batch\"],\n",
        "        \"grad_accum\": fixed_params[\"grad_accum\"],\n",
        "        \"warmup\": fixed_params[\"warmup\"],\n",
        "        \"weight_decay\": fixed_params[\"weight_decay\"]\n",
        "    }\n",
        "    hyperparam_sets.append(config)\n",
        "\n",
        "total_iters = len(hyperparam_sets)\n",
        "\n",
        "print(f\"Generated {total_iters} configurations (exhaustive grid)\")\n",
        "print(f\"Calculation: {len(grid_params['epochs'])} epochs  {len(grid_params['lr'])} learning rates = {total_iters}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Excel setup\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"Grid Search Results\"\n",
        "ws.append([\n",
        "    \"Iteration\", \"Epochs\", \"Learning Rate\", \"Batch Size\", \"Grad Accum\", \"Effective Batch\",\n",
        "    \"Warmup Ratio\", \"Weight Decay\",\n",
        "    \"Train-Accuracy\", \"Test-Accuracy\",\n",
        "    \"Train-F1\", \"Test-F1\",\n",
        "    \"Train-Precision\", \"Test-Precision\",\n",
        "    \"Train-Recall\", \"Test-Recall\",\n",
        "    \"Runtime (s)\"\n",
        "])\n",
        "\n",
        "# Main grid search loop\n",
        "for i, params in enumerate(hyperparam_sets, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\" Grid Configuration {i}/{total_iters}\")\n",
        "    print(f\"Params: Epochs={params['epochs']}, LR={params['lr']:.6f}\")\n",
        "    print(f\"        Batch={params['batch']}, GradAccum={params['grad_accum']}, Warmup={params['warmup']:.2f}, WeightDecay={params['weight_decay']:.4f}\")\n",
        "    print(f\"        Effective Batch Size: {params['batch'] * params['grad_accum']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Reload fresh model for each iteration\n",
        "    print(\" Loading fresh BioBERT model...\")\n",
        "    model_fresh = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "    model_fresh.to(device)\n",
        "\n",
        "    # Configure training arguments (T4 optimized)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_run_{i}\",\n",
        "        num_train_epochs=params[\"epochs\"],\n",
        "        per_device_train_batch_size=params[\"batch\"],\n",
        "        per_device_eval_batch_size=params[\"batch\"],\n",
        "        gradient_accumulation_steps=params[\"grad_accum\"],\n",
        "        learning_rate=params[\"lr\"],\n",
        "        warmup_ratio=params[\"warmup\"],\n",
        "        weight_decay=params[\"weight_decay\"],\n",
        "        eval_strategy=\"no\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_dir=f\"./logs_run_{i}\",\n",
        "        report_to=[],\n",
        "        disable_tqdm=False,\n",
        "        seed=42,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        dataloader_num_workers=0,  # T4 optimization (limited CPU cores)\n",
        "        dataloader_pin_memory=True,\n",
        "    )\n",
        "\n",
        "    # Create trainer\n",
        "    trainer = Trainer(\n",
        "        model=model_fresh,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_test,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    print(\" Training...\")\n",
        "    start_time = time.time()\n",
        "    trainer.train()\n",
        "    runtime = round(time.time() - start_time, 2)\n",
        "\n",
        "    # Evaluate on BOTH train and test sets\n",
        "    print(\" Evaluating on training set...\")\n",
        "    train_metrics = evaluate_dataset(trainer, tokenized_train, \"TRAIN\")\n",
        "\n",
        "    print(\" Evaluating on test set...\")\n",
        "    test_metrics = evaluate_dataset(trainer, tokenized_test, \"TEST\")\n",
        "\n",
        "    # Calculate effective batch size\n",
        "    effective_batch = params[\"batch\"] * params[\"grad_accum\"]\n",
        "\n",
        "    # Append results to Excel (using real numbers, not scientific notation)\n",
        "    ws.append([\n",
        "        i,\n",
        "        params[\"epochs\"],\n",
        "        params[\"lr\"],  # Will be formatted as real number\n",
        "        params[\"batch\"],\n",
        "        params[\"grad_accum\"],\n",
        "        effective_batch,\n",
        "        params[\"warmup\"],\n",
        "        params[\"weight_decay\"],\n",
        "        round(train_metrics[\"accuracy\"], 4),\n",
        "        round(test_metrics[\"accuracy\"], 4),\n",
        "        round(train_metrics[\"f1\"], 4),\n",
        "        round(test_metrics[\"f1\"], 4),\n",
        "        round(train_metrics[\"precision\"], 4),\n",
        "        round(test_metrics[\"precision\"], 4),\n",
        "        round(train_metrics[\"recall\"], 4),\n",
        "        round(test_metrics[\"recall\"], 4),\n",
        "        runtime\n",
        "    ])\n",
        "\n",
        "    print(f\" Configuration {i} complete!\")\n",
        "    print(f\"   Train - F1: {train_metrics['f1']:.4f}, Acc: {train_metrics['accuracy']:.4f}\")\n",
        "    print(f\"   Test  - F1: {test_metrics['f1']:.4f}, Acc: {test_metrics['accuracy']:.4f}\")\n",
        "    print(f\"   Runtime: {runtime}s\")\n",
        "\n",
        "    # Clear GPU cache and free memory (T4 optimization)\n",
        "    del model_fresh, trainer\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "# Format Excel file\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FORMATTING EXCEL FILE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Bold headers\n",
        "for cell in ws[1]:\n",
        "    cell.font = Font(bold=True)\n",
        "    cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
        "\n",
        "# Format Learning Rate column to show real numbers (not scientific notation)\n",
        "for row in range(2, ws.max_row + 1):\n",
        "    # Learning Rate (column C)\n",
        "    ws.cell(row=row, column=3).number_format = '0.000000'\n",
        "    # Warmup Ratio (column G)\n",
        "    ws.cell(row=row, column=7).number_format = '0.00'\n",
        "    # Weight Decay (column H)\n",
        "    ws.cell(row=row, column=8).number_format = '0.0000'\n",
        "    # All metric columns (I-P)\n",
        "    for col in range(9, 17):\n",
        "        ws.cell(row=row, column=col).number_format = '0.0000'\n",
        "\n",
        "# Auto-adjust column widths\n",
        "for col in ws.columns:\n",
        "    max_length = 0\n",
        "    col_letter = col[0].column_letter\n",
        "    for cell in col:\n",
        "        try:\n",
        "            if len(str(cell.value)) > max_length:\n",
        "                max_length = len(str(cell.value))\n",
        "        except:\n",
        "            pass\n",
        "    adjusted_width = min((max_length + 2), 20)\n",
        "    ws.column_dimensions[col_letter].width = adjusted_width\n",
        "\n",
        "# Save Excel file\n",
        "output_excel = \"/content/salameda_QA_GridSearch_Results_BioBERT.xlsx\"\n",
        "wb.save(output_excel)\n",
        "\n",
        "print(f\"\\n All {total_iters} configurations completed successfully!\")\n",
        "print(\" Results saved to Excel file:\")\n",
        "print(f\" {output_excel}\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXHAUSTIVE GRID SEARCH COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"   - Total configurations tested: {total_iters}\")\n",
        "print(f\"   - Grid dimensions: {len(grid_params['epochs'])} epochs  {len(grid_params['lr'])} learning rates\")\n",
        "print(f\"   - Dataset size: {len(dataset)} records (Train: {len(train_data)}, Test: {len(test_data)})\")\n",
        "print(f\"   - Epoch range: {min(grid_params['epochs'])}-{max(grid_params['epochs'])}\")\n",
        "print(f\"   - Learning rate range: {min(grid_params['lr']):.6f} - {max(grid_params['lr']):.6f}\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02f5b2a8f5234aa0a3a217ff14a2b09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a22c544fe541dbbd31ded4af8ca99f",
            "placeholder": "",
            "style": "IPY_MODEL_9e6d7b6010824386b2d50f60e4fcb0f1",
            "value": "config.json:100%"
          }
        },
        "0a0e0a4a19ae452193a058c6a9cd48e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9303d6ab02564966a66959534f61598a",
            "max": 435780550,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95f4baae328d4a4db055b3f59610070e",
            "value": 435780550
          }
        },
        "0b0119c53b50438db1d3637467381e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ce6c083e906407eab91e253c0586a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "242ed6519ba140578ff7bda8713d4dce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a6302f1f99b4a4683a73b8201dd1eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3025d493d3364af39862ecd787e6fe74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0119c53b50438db1d3637467381e5c",
            "placeholder": "",
            "style": "IPY_MODEL_b7bf0bb4ba004842949e453f4195e413",
            "value": "Tokenizingtrain:100%"
          }
        },
        "369eee32b6874a2dbfea8aca8c6f12b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40e505f821864b34b4f7d345d39dbf03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44a1bc9e4f29452d99a5114f95122e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48343d171c404f049e2230e807068626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b974bac888e644e49c49db37e0e86011",
              "IPY_MODEL_0a0e0a4a19ae452193a058c6a9cd48e1",
              "IPY_MODEL_6f344cf5c0d247c5a6bcbe7e1be8cc2a"
            ],
            "layout": "IPY_MODEL_b703cc941b354d75a8d24bffbc5da109"
          }
        },
        "51774e7a7a294c7e84fc04a126fba059": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55a6579549da40a484f873fbb5eebfa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "570fb2519bb6495387247961d20f6fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eafc80dbc18c4171b60b9fccfdff3552",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55a6579549da40a484f873fbb5eebfa1",
            "value": 1
          }
        },
        "57b638c9de41468fb6b14b4e389c970f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "591f056a639a4004a7ce62e5653cb8b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f344cf5c0d247c5a6bcbe7e1be8cc2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44a1bc9e4f29452d99a5114f95122e8e",
            "placeholder": "",
            "style": "IPY_MODEL_dd941716ea984d92a30b3166442e267b",
            "value": "436M/436M[00:03&lt;00:00,252MB/s]"
          }
        },
        "73996c365ffb4e5fb2983e311f10b984": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a22c544fe541dbbd31ded4af8ca99f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a6eb49b30f54428bdb51682a7101463": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1f75b4724094cb2833cd515e94a2b72",
            "placeholder": "",
            "style": "IPY_MODEL_b63b7738100a4003a6d889a8fd3c7a3e",
            "value": "131/131[00:00&lt;00:00,514.97examples/s]"
          }
        },
        "7a6fcbdc214045588cef25705f274466": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c4c26599df47c58d6371b702583f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90c7bb7f8f4c4d66b569c4b3b6d453b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5ae9eaca76d4ec89238a0b0e8e892fa",
            "max": 131,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd60e6633f2147dc9b25098ba216c0e5",
            "value": 131
          }
        },
        "9303d6ab02564966a66959534f61598a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959e915d265f4590a1d6b343fafd519f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2bfb00213d54108ae90ddff61de84e1",
            "placeholder": "",
            "style": "IPY_MODEL_b0b7f0574d6d4054867a0c18366f4a9e",
            "value": "213k/?[00:00&lt;00:00,14.3MB/s]"
          }
        },
        "95f4baae328d4a4db055b3f59610070e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9926156108b84086aa3d0964bae827e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c90d34cfec99431981da7fab5e3f7507",
              "IPY_MODEL_570fb2519bb6495387247961d20f6fad",
              "IPY_MODEL_959e915d265f4590a1d6b343fafd519f"
            ],
            "layout": "IPY_MODEL_73996c365ffb4e5fb2983e311f10b984"
          }
        },
        "9b7080833b9c44adbb3ff4d72b5d0fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57b638c9de41468fb6b14b4e389c970f",
            "placeholder": "",
            "style": "IPY_MODEL_e35f97d390764d2784fbe39dc8c28e5d",
            "value": "313/313[00:00&lt;00:00,36.4kB/s]"
          }
        },
        "9e6d7b6010824386b2d50f60e4fcb0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2bfb00213d54108ae90ddff61de84e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0b7f0574d6d4054867a0c18366f4a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2fab45e2d41401bb50ed191bb67a2f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b63b7738100a4003a6d889a8fd3c7a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b703cc941b354d75a8d24bffbc5da109": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7bf0bb4ba004842949e453f4195e413": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b974bac888e644e49c49db37e0e86011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa52d7217ce14394941ecd57c6124e7a",
            "placeholder": "",
            "style": "IPY_MODEL_86c4c26599df47c58d6371b702583f28",
            "value": "pytorch_model.bin:100%"
          }
        },
        "c03f308eff5a49cd923744713f508adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a6fcbdc214045588cef25705f274466",
            "placeholder": "",
            "style": "IPY_MODEL_d3ef5558ddd640c5aa4e428ad27a8cb0",
            "value": "523/523[00:01&lt;00:00,308.29examples/s]"
          }
        },
        "c1697bf9e1c74cda873beb4292a30ad9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1f75b4724094cb2833cd515e94a2b72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ae9eaca76d4ec89238a0b0e8e892fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c90d34cfec99431981da7fab5e3f7507": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51774e7a7a294c7e84fc04a126fba059",
            "placeholder": "",
            "style": "IPY_MODEL_b2fab45e2d41401bb50ed191bb67a2f1",
            "value": "vocab.txt:"
          }
        },
        "cd60e6633f2147dc9b25098ba216c0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3ef5558ddd640c5aa4e428ad27a8cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd941716ea984d92a30b3166442e267b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de7c7b77aec84bae8e498da5f5a106b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02f5b2a8f5234aa0a3a217ff14a2b09b",
              "IPY_MODEL_ef6c23e955484bcb913e165b4e27e388",
              "IPY_MODEL_9b7080833b9c44adbb3ff4d72b5d0fc1"
            ],
            "layout": "IPY_MODEL_40e505f821864b34b4f7d345d39dbf03"
          }
        },
        "e35f97d390764d2784fbe39dc8c28e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eafc80dbc18c4171b60b9fccfdff3552": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "edf4e60148bd407788e856c41b9fc6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1697bf9e1c74cda873beb4292a30ad9",
            "max": 523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_369eee32b6874a2dbfea8aca8c6f12b1",
            "value": 523
          }
        },
        "ee274ba814124e4aa789fcee28b28491": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef6c23e955484bcb913e165b4e27e388": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_591f056a639a4004a7ce62e5653cb8b6",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ce6c083e906407eab91e253c0586a2a",
            "value": 313
          }
        },
        "f0a8d11ad5df42a9a1f93f059ae6c7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3025d493d3364af39862ecd787e6fe74",
              "IPY_MODEL_edf4e60148bd407788e856c41b9fc6f2",
              "IPY_MODEL_c03f308eff5a49cd923744713f508adc"
            ],
            "layout": "IPY_MODEL_2a6302f1f99b4a4683a73b8201dd1eaa"
          }
        },
        "fa52d7217ce14394941ecd57c6124e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb0892c8d4848b79e620791023492f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd055bd7b5b94703afdc9daf99783d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fda44350b136474cad9ece08346075f0",
              "IPY_MODEL_90c7bb7f8f4c4d66b569c4b3b6d453b3",
              "IPY_MODEL_7a6eb49b30f54428bdb51682a7101463"
            ],
            "layout": "IPY_MODEL_242ed6519ba140578ff7bda8713d4dce"
          }
        },
        "fda44350b136474cad9ece08346075f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee274ba814124e4aa789fcee28b28491",
            "placeholder": "",
            "style": "IPY_MODEL_fcb0892c8d4848b79e620791023492f0",
            "value": "Tokenizingtest:100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
